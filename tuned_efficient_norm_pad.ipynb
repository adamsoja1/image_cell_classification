{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb74ae06-2775-4bb7-841c-8e11a4b3e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005790681392562339\n",
    "batch_size = 388\n",
    "dropout_rate = 0.21647507108255604\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdce5c8-56c3-4c69-b604-58c13391dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        files = os.listdir(path)\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['filename'] = []\n",
    "        dataset_final['class'] = []\n",
    "        for filename in files:\n",
    "            dataset = pd.DataFrame()\n",
    "            if filename.endswith('.txt'):\n",
    "                files = get_images_list(f'{path}/{filename}')\n",
    "                dataset['filename'] = files\n",
    "                dataset['class'] = filename.split('_')[1][:-3]\n",
    "                dataset_final = pd.concat([dataset_final, dataset], ignore_index=True)\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"filename\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset[\"class\"].loc[idx]\n",
    "\n",
    "        if target == 'normal.':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target == 'inflamatory.':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target == 'tumor.':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target == 'other.':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "       \n",
    "     \n",
    "\n",
    "        \"\"\"To see transorms use:\n",
    "            image, target = trainset[15]\n",
    "            image = image.numpy()\n",
    "            image=np.swapaxes(image,0,1)\n",
    "            image=np.swapaxes(image,1,2)\n",
    "            plt.imshow(image)\"\"\"\n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c9ce6d-ff90-47af-9c56-b9fedb9fdef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1800: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1826: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1952: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2233)\n",
    "\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=0, std=1),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=0, std=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1a2930-151c-47fb-9dfa-049423ebc571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=4, dropout_rate=dropout_rate):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.base_model = models.efficientnet_b0(pretrained=False)\n",
    "        num_ftrs = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),  # Add dropout layer\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "model = EfficientNetB0(num_classes=4, dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abc075-67ea-4128-9aa2-bb4ee837775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8eb3155-df02-49ac-a6b2-6bbea2a732a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240804_230552-m760bf13</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/m760bf13' target=\"_blank\">efficient_net_norm_pad2024-08-04 23:05:51.146804</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/m760bf13' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/m760bf13</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0630021364249909\n",
      "train_precision: tensor([0.4490, 0.6198, 0.5131, 0.0359], device='cuda:0')\n",
      "train_recall: tensor([0.4432, 0.7248, 0.4825, 0.0012], device='cuda:0')\n",
      "val_loss: 0.9520890395931837\n",
      "val_precision: tensor([0.5432, 0.6057, 0.6496, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.4885, 0.8285, 0.5411, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.9869628292558856\n",
      "train_precision: tensor([0.5137, 0.6432, 0.5907, 0.0000], device='cuda:0')\n",
      "train_recall: tensor([0.5245, 0.7448, 0.5440, 0.0000], device='cuda:0')\n",
      "val_loss: 0.9340760139357142\n",
      "val_precision: tensor([0.5705, 0.7206, 0.5275, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.3318, 0.7190, 0.8023, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.8896084505298077\n",
      "train_precision: tensor([0.5588, 0.6899, 0.6414, 0.4472], device='cuda:0')\n",
      "train_recall: tensor([0.5659, 0.7586, 0.6324, 0.0079], device='cuda:0')\n",
      "val_loss: 0.9594440279888505\n",
      "val_precision: tensor([0.5805, 0.7001, 0.4938, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.2127, 0.7245, 0.8388, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.8319544737304592\n",
      "train_precision: tensor([0.5903, 0.7105, 0.6727, 0.5592], device='cuda:0')\n",
      "train_recall: tensor([0.5861, 0.7835, 0.6706, 0.0423], device='cuda:0')\n",
      "val_loss: 0.8048228712893334\n",
      "val_precision: tensor([0.6017, 0.7260, 0.7025, 0.4968], device='cuda:0')\n",
      "val_recall: tensor([0.6318, 0.8064, 0.6414, 0.1316], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.815623694486136\n",
      "train_precision: tensor([0.5996, 0.7173, 0.6767, 0.6367], device='cuda:0')\n",
      "train_recall: tensor([0.5870, 0.7907, 0.6818, 0.0726], device='cuda:0')\n",
      "val_loss: 0.7997565855499075\n",
      "val_precision: tensor([0.6414, 0.7009, 0.6869, 0.6743], device='cuda:0')\n",
      "val_recall: tensor([0.5633, 0.8228, 0.7036, 0.1596], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.7761761342790583\n",
      "train_precision: tensor([0.6182, 0.7375, 0.6908, 0.6866], device='cuda:0')\n",
      "train_recall: tensor([0.6052, 0.8022, 0.7004, 0.1328], device='cuda:0')\n",
      "val_loss: 0.8128192806694688\n",
      "val_precision: tensor([0.6009, 0.7086, 0.7144, 0.3806], device='cuda:0')\n",
      "val_recall: tensor([0.6174, 0.8347, 0.6012, 0.2017], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.7440217861414816\n",
      "train_precision: tensor([0.6335, 0.7480, 0.6998, 0.6131], device='cuda:0')\n",
      "train_recall: tensor([0.6149, 0.8052, 0.7125, 0.2124], device='cuda:0')\n",
      "val_loss: 0.7239300716324013\n",
      "val_precision: tensor([0.6665, 0.7475, 0.6907, 0.6479], device='cuda:0')\n",
      "val_recall: tensor([0.5798, 0.8290, 0.7433, 0.2912], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.7205921811747638\n",
      "train_precision: tensor([0.6433, 0.7568, 0.7055, 0.6190], device='cuda:0')\n",
      "train_recall: tensor([0.6227, 0.8099, 0.7165, 0.2863], device='cuda:0')\n",
      "val_loss: 0.742091739127616\n",
      "val_precision: tensor([0.6728, 0.6526, 0.7569, 0.7749], device='cuda:0')\n",
      "val_recall: tensor([0.5348, 0.9155, 0.6567, 0.2700], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.703151227765135\n",
      "train_precision: tensor([0.6561, 0.7651, 0.7134, 0.6124], device='cuda:0')\n",
      "train_recall: tensor([0.6358, 0.8138, 0.7245, 0.3176], device='cuda:0')\n",
      "val_loss: 0.7041363935260212\n",
      "val_precision: tensor([0.7077, 0.7628, 0.6597, 0.7712], device='cuda:0')\n",
      "val_recall: tensor([0.5091, 0.8294, 0.8286, 0.2872], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6905011858535588\n",
      "train_precision: tensor([0.6662, 0.7703, 0.7205, 0.6278], device='cuda:0')\n",
      "train_recall: tensor([0.6438, 0.8191, 0.7309, 0.3505], device='cuda:0')\n",
      "val_loss: 0.7174320195903298\n",
      "val_precision: tensor([0.6429, 0.7252, 0.7505, 0.6403], device='cuda:0')\n",
      "val_recall: tensor([0.6486, 0.8500, 0.6527, 0.3158], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6740646862596381\n",
      "train_precision: tensor([0.6699, 0.7742, 0.7275, 0.6549], device='cuda:0')\n",
      "train_recall: tensor([0.6511, 0.8203, 0.7347, 0.3837], device='cuda:0')\n",
      "val_loss: 0.6698781911815915\n",
      "val_precision: tensor([0.7014, 0.7936, 0.6968, 0.6159], device='cuda:0')\n",
      "val_recall: tensor([0.6046, 0.8097, 0.7970, 0.4552], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6628215415167895\n",
      "train_precision: tensor([0.6756, 0.7793, 0.7345, 0.6470], device='cuda:0')\n",
      "train_recall: tensor([0.6604, 0.8226, 0.7385, 0.3983], device='cuda:0')\n",
      "val_loss: 0.6671760982575536\n",
      "val_precision: tensor([0.6897, 0.7795, 0.7160, 0.6340], device='cuda:0')\n",
      "val_recall: tensor([0.6235, 0.8200, 0.7719, 0.4182], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6662766575167756\n",
      "train_precision: tensor([0.6744, 0.7754, 0.7330, 0.6441], device='cuda:0')\n",
      "train_recall: tensor([0.6588, 0.8188, 0.7366, 0.4014], device='cuda:0')\n",
      "val_loss: 0.6429916853163423\n",
      "val_precision: tensor([0.6921, 0.8095, 0.7156, 0.7395], device='cuda:0')\n",
      "val_recall: tensor([0.6544, 0.8082, 0.7865, 0.4215], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6428687966257226\n",
      "train_precision: tensor([0.6829, 0.7869, 0.7423, 0.6587], device='cuda:0')\n",
      "train_recall: tensor([0.6694, 0.8272, 0.7445, 0.4317], device='cuda:0')\n",
      "val_loss: 0.6591126624526096\n",
      "val_precision: tensor([0.6709, 0.8046, 0.7234, 0.6506], device='cuda:0')\n",
      "val_recall: tensor([0.6641, 0.7903, 0.7639, 0.4684], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6342089387053617\n",
      "train_precision: tensor([0.6898, 0.7904, 0.7469, 0.6608], device='cuda:0')\n",
      "train_recall: tensor([0.6755, 0.8288, 0.7508, 0.4426], device='cuda:0')\n",
      "val_loss: 0.627964472695559\n",
      "val_precision: tensor([0.6961, 0.8230, 0.7138, 0.7308], device='cuda:0')\n",
      "val_recall: tensor([0.6505, 0.7987, 0.8101, 0.4397], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6260223037929742\n",
      "train_precision: tensor([0.6917, 0.7931, 0.7525, 0.6701], device='cuda:0')\n",
      "train_recall: tensor([0.6802, 0.8308, 0.7527, 0.4616], device='cuda:0')\n",
      "val_loss: 0.6313173480394507\n",
      "val_precision: tensor([0.6647, 0.7970, 0.7925, 0.6303], device='cuda:0')\n",
      "val_recall: tensor([0.7325, 0.8192, 0.6994, 0.5522], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.627311243154512\n",
      "train_precision: tensor([0.6943, 0.7915, 0.7514, 0.6660], device='cuda:0')\n",
      "train_recall: tensor([0.6800, 0.8278, 0.7542, 0.4736], device='cuda:0')\n",
      "val_loss: 0.618433686865478\n",
      "val_precision: tensor([0.6926, 0.7807, 0.7772, 0.7188], device='cuda:0')\n",
      "val_recall: tensor([0.7018, 0.8455, 0.7249, 0.5104], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6152560985260491\n",
      "train_precision: tensor([0.6986, 0.7953, 0.7597, 0.6624], device='cuda:0')\n",
      "train_recall: tensor([0.6881, 0.8320, 0.7570, 0.4801], device='cuda:0')\n",
      "val_loss: 0.6382918543174487\n",
      "val_precision: tensor([0.7207, 0.8185, 0.6859, 0.7276], device='cuda:0')\n",
      "val_recall: tensor([0.5894, 0.8047, 0.8475, 0.4623], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6081223271060937\n",
      "train_precision: tensor([0.7025, 0.7988, 0.7591, 0.6730], device='cuda:0')\n",
      "train_recall: tensor([0.6887, 0.8337, 0.7611, 0.4932], device='cuda:0')\n",
      "val_loss: 0.6294375787011716\n",
      "val_precision: tensor([0.6622, 0.8154, 0.7673, 0.8046], device='cuda:0')\n",
      "val_recall: tensor([0.7399, 0.8018, 0.7297, 0.3896], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6027882706494968\n",
      "train_precision: tensor([0.7030, 0.8011, 0.7607, 0.6744], device='cuda:0')\n",
      "train_recall: tensor([0.6928, 0.8336, 0.7601, 0.5049], device='cuda:0')\n",
      "val_loss: 0.7311370620707504\n",
      "val_precision: tensor([0.6290, 0.7131, 0.7791, 0.5123], device='cuda:0')\n",
      "val_recall: tensor([0.6409, 0.8523, 0.6243, 0.4337], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.6032278508701049\n",
      "train_precision: tensor([0.7041, 0.8010, 0.7626, 0.6733], device='cuda:0')\n",
      "train_recall: tensor([0.6934, 0.8338, 0.7616, 0.5094], device='cuda:0')\n",
      "val_loss: 0.6085217349669513\n",
      "val_precision: tensor([0.7134, 0.8299, 0.7196, 0.7649], device='cuda:0')\n",
      "val_recall: tensor([0.6771, 0.7956, 0.8157, 0.4492], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5957584431670633\n",
      "train_precision: tensor([0.7072, 0.8024, 0.7658, 0.6812], device='cuda:0')\n",
      "train_recall: tensor([0.6970, 0.8351, 0.7628, 0.5289], device='cuda:0')\n",
      "val_loss: 0.6125153819052112\n",
      "val_precision: tensor([0.6608, 0.8580, 0.7497, 0.7547], device='cuda:0')\n",
      "val_recall: tensor([0.7446, 0.7484, 0.7772, 0.4848], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5893725309023358\n",
      "train_precision: tensor([0.7102, 0.8054, 0.7682, 0.6859], device='cuda:0')\n",
      "train_recall: tensor([0.7014, 0.8359, 0.7657, 0.5332], device='cuda:0')\n",
      "val_loss: 0.6082741943728022\n",
      "val_precision: tensor([0.6698, 0.8270, 0.7757, 0.6573], device='cuda:0')\n",
      "val_recall: tensor([0.7372, 0.7945, 0.7396, 0.5606], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5857323759406913\n",
      "train_precision: tensor([0.7124, 0.8057, 0.7714, 0.6847], device='cuda:0')\n",
      "train_recall: tensor([0.7033, 0.8375, 0.7664, 0.5456], device='cuda:0')\n",
      "val_loss: 0.6094766493354525\n",
      "val_precision: tensor([0.7347, 0.8335, 0.7033, 0.6527], device='cuda:0')\n",
      "val_recall: tensor([0.6387, 0.7922, 0.8377, 0.5815], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5805584568839641\n",
      "train_precision: tensor([0.7143, 0.8092, 0.7734, 0.6860], device='cuda:0')\n",
      "train_recall: tensor([0.7064, 0.8401, 0.7687, 0.5417], device='cuda:0')\n",
      "val_loss: 0.6346889217110241\n",
      "val_precision: tensor([0.7737, 0.7800, 0.6865, 0.8329], device='cuda:0')\n",
      "val_recall: tensor([0.5587, 0.8535, 0.8486, 0.3960], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5768253814012135\n",
      "train_precision: tensor([0.7155, 0.8109, 0.7738, 0.6885], device='cuda:0')\n",
      "train_recall: tensor([0.7075, 0.8390, 0.7704, 0.5571], device='cuda:0')\n",
      "val_loss: 0.5905541876534454\n",
      "val_precision: tensor([0.7369, 0.8104, 0.7394, 0.6999], device='cuda:0')\n",
      "val_recall: tensor([0.6559, 0.8319, 0.8163, 0.5559], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5740912938053427\n",
      "train_precision: tensor([0.7169, 0.8110, 0.7746, 0.6860], device='cuda:0')\n",
      "train_recall: tensor([0.7067, 0.8406, 0.7725, 0.5509], device='cuda:0')\n",
      "val_loss: 0.6007393936650092\n",
      "val_precision: tensor([0.7620, 0.7586, 0.7515, 0.6238], device='cuda:0')\n",
      "val_recall: tensor([0.5970, 0.8795, 0.7928, 0.6380], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5686577105565191\n",
      "train_precision: tensor([0.7196, 0.8131, 0.7769, 0.6962], device='cuda:0')\n",
      "train_recall: tensor([0.7100, 0.8417, 0.7744, 0.5661], device='cuda:0')\n",
      "val_loss: 0.5884863288462663\n",
      "val_precision: tensor([0.7286, 0.7649, 0.7795, 0.7654], device='cuda:0')\n",
      "val_recall: tensor([0.6611, 0.8833, 0.7564, 0.5175], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.566340443674838\n",
      "train_precision: tensor([0.7224, 0.8142, 0.7774, 0.6916], device='cuda:0')\n",
      "train_recall: tensor([0.7108, 0.8446, 0.7746, 0.5694], device='cuda:0')\n",
      "val_loss: 0.5856555224466724\n",
      "val_precision: tensor([0.7242, 0.7669, 0.8095, 0.6803], device='cuda:0')\n",
      "val_recall: tensor([0.6942, 0.8830, 0.7279, 0.6182], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5648447349398575\n",
      "train_precision: tensor([0.7227, 0.8139, 0.7813, 0.6897], device='cuda:0')\n",
      "train_recall: tensor([0.7139, 0.8427, 0.7762, 0.5750], device='cuda:0')\n",
      "val_loss: 0.613471338478457\n",
      "val_precision: tensor([0.6372, 0.8066, 0.8548, 0.6987], device='cuda:0')\n",
      "val_recall: tensor([0.8004, 0.8400, 0.6214, 0.5286], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.559941913838421\n",
      "train_precision: tensor([0.7246, 0.8154, 0.7821, 0.6933], device='cuda:0')\n",
      "train_recall: tensor([0.7159, 0.8445, 0.7763, 0.5799], device='cuda:0')\n",
      "val_loss: 0.5949582432498451\n",
      "val_precision: tensor([0.6616, 0.8523, 0.7948, 0.8186], device='cuda:0')\n",
      "val_recall: tensor([0.8024, 0.7894, 0.7246, 0.4040], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5579730096384076\n",
      "train_precision: tensor([0.7249, 0.8165, 0.7811, 0.7025], device='cuda:0')\n",
      "train_recall: tensor([0.7152, 0.8441, 0.7785, 0.5824], device='cuda:0')\n",
      "val_loss: 0.5959702501026523\n",
      "val_precision: tensor([0.7539, 0.8271, 0.7178, 0.5847], device='cuda:0')\n",
      "val_recall: tensor([0.6266, 0.8172, 0.8406, 0.6418], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5612131212484965\n",
      "train_precision: tensor([0.7231, 0.8133, 0.7805, 0.7003], device='cuda:0')\n",
      "train_recall: tensor([0.7134, 0.8440, 0.7744, 0.5857], device='cuda:0')\n",
      "val_loss: 0.587224517675007\n",
      "val_precision: tensor([0.7291, 0.7558, 0.8106, 0.7049], device='cuda:0')\n",
      "val_recall: tensor([0.6889, 0.8895, 0.7276, 0.5687], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5511257729698175\n",
      "train_precision: tensor([0.7301, 0.8195, 0.7842, 0.7104], device='cuda:0')\n",
      "train_recall: tensor([0.7207, 0.8467, 0.7802, 0.6020], device='cuda:0')\n",
      "val_loss: 0.5760363617113659\n",
      "val_precision: tensor([0.6734, 0.8590, 0.7901, 0.6725], device='cuda:0')\n",
      "val_recall: tensor([0.7718, 0.7715, 0.7597, 0.6327], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5555104936072973\n",
      "train_precision: tensor([0.7264, 0.8182, 0.7835, 0.6992], device='cuda:0')\n",
      "train_recall: tensor([0.7188, 0.8434, 0.7788, 0.5993], device='cuda:0')\n",
      "val_loss: 0.615205883478918\n",
      "val_precision: tensor([0.6956, 0.8319, 0.7415, 0.6453], device='cuda:0')\n",
      "val_recall: tensor([0.6880, 0.7971, 0.7918, 0.5481], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5483272223050843\n",
      "train_precision: tensor([0.7296, 0.8190, 0.7868, 0.7117], device='cuda:0')\n",
      "train_recall: tensor([0.7208, 0.8468, 0.7817, 0.6026], device='cuda:0')\n",
      "val_loss: 0.5541647732758722\n",
      "val_precision: tensor([0.7181, 0.8155, 0.8025, 0.6856], device='cuda:0')\n",
      "val_recall: tensor([0.7328, 0.8443, 0.7634, 0.6367], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5456946990872978\n",
      "train_precision: tensor([0.7326, 0.8199, 0.7895, 0.7033], device='cuda:0')\n",
      "train_recall: tensor([0.7226, 0.8483, 0.7833, 0.6105], device='cuda:0')\n",
      "val_loss: 0.5812046224830532\n",
      "val_precision: tensor([0.7762, 0.8018, 0.7186, 0.7033], device='cuda:0')\n",
      "val_recall: tensor([0.6044, 0.8519, 0.8453, 0.5801], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.543087892207428\n",
      "train_precision: tensor([0.7319, 0.8223, 0.7881, 0.7147], device='cuda:0')\n",
      "train_recall: tensor([0.7232, 0.8484, 0.7837, 0.6123], device='cuda:0')\n",
      "val_loss: 0.5598938520215139\n",
      "val_precision: tensor([0.7257, 0.7962, 0.8007, 0.7154], device='cuda:0')\n",
      "val_recall: tensor([0.7121, 0.8665, 0.7591, 0.5899], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.541092058919397\n",
      "train_precision: tensor([0.7336, 0.8225, 0.7897, 0.7148], device='cuda:0')\n",
      "train_recall: tensor([0.7254, 0.8489, 0.7845, 0.6130], device='cuda:0')\n",
      "val_loss: 0.6086092655147824\n",
      "val_precision: tensor([0.6762, 0.9010, 0.7300, 0.7244], device='cuda:0')\n",
      "val_recall: tensor([0.7517, 0.6988, 0.8248, 0.6000], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5393770199928043\n",
      "train_precision: tensor([0.7355, 0.8232, 0.7891, 0.7109], device='cuda:0')\n",
      "train_recall: tensor([0.7250, 0.8504, 0.7846, 0.6180], device='cuda:0')\n",
      "val_loss: 0.5638139519621345\n",
      "val_precision: tensor([0.7382, 0.8114, 0.7675, 0.7585], device='cuda:0')\n",
      "val_recall: tensor([0.6925, 0.8538, 0.7962, 0.5478], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5458182092715687\n",
      "train_precision: tensor([0.7317, 0.8206, 0.7888, 0.7146], device='cuda:0')\n",
      "train_recall: tensor([0.7229, 0.8479, 0.7832, 0.6124], device='cuda:0')\n",
      "val_loss: 0.5766967752901446\n",
      "val_precision: tensor([0.6939, 0.7965, 0.8350, 0.6257], device='cuda:0')\n",
      "val_recall: tensor([0.7475, 0.8573, 0.7043, 0.6438], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5635960202139637\n",
      "train_precision: tensor([0.7184, 0.8176, 0.7820, 0.6997], device='cuda:0')\n",
      "train_recall: tensor([0.7159, 0.8439, 0.7729, 0.5811], device='cuda:0')\n",
      "val_loss: 0.8793529061710134\n",
      "val_precision: tensor([0.6182, 0.6710, 0.6679, 0.5055], device='cuda:0')\n",
      "val_recall: tensor([0.4946, 0.8645, 0.6573, 0.1380], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5759304254601578\n",
      "train_precision: tensor([0.7131, 0.8125, 0.7767, 0.6883], device='cuda:0')\n",
      "train_recall: tensor([0.7091, 0.8399, 0.7690, 0.5631], device='cuda:0')\n",
      "val_loss: 0.5558754856846914\n",
      "val_precision: tensor([0.7127, 0.8233, 0.7881, 0.7848], device='cuda:0')\n",
      "val_recall: tensor([0.7398, 0.8323, 0.7742, 0.5404], device='cuda:0')\n",
      "Learning rate: 0.005790681392562339\n",
      "train_loss: 0.5360837015541883\n",
      "train_precision: tensor([0.7347, 0.8248, 0.7938, 0.7161], device='cuda:0')\n",
      "train_recall: tensor([0.7269, 0.8506, 0.7878, 0.6214], device='cuda:0')\n",
      "val_loss: 0.6738495695240357\n",
      "val_precision: tensor([0.7949, 0.8512, 0.6027, 0.8589], device='cuda:0')\n",
      "val_recall: tensor([0.4500, 0.7915, 0.9365, 0.4303], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.4967110477092034\n",
      "train_precision: tensor([0.7538, 0.8378, 0.8082, 0.7522], device='cuda:0')\n",
      "train_recall: tensor([0.7468, 0.8596, 0.8024, 0.6797], device='cuda:0')\n",
      "val_loss: 0.5141201899582598\n",
      "val_precision: tensor([0.7594, 0.8206, 0.7963, 0.7622], device='cuda:0')\n",
      "val_recall: tensor([0.7149, 0.8668, 0.8102, 0.6465], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.4837118834795074\n",
      "train_precision: tensor([0.7596, 0.8435, 0.8150, 0.7535], device='cuda:0')\n",
      "train_recall: tensor([0.7551, 0.8631, 0.8062, 0.7046], device='cuda:0')\n",
      "val_loss: 0.5115983413548029\n",
      "val_precision: tensor([0.7456, 0.8365, 0.8004, 0.7658], device='cuda:0')\n",
      "val_recall: tensor([0.7423, 0.8510, 0.8021, 0.6508], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.47853392367974085\n",
      "train_precision: tensor([0.7623, 0.8434, 0.8165, 0.7615], device='cuda:0')\n",
      "train_recall: tensor([0.7571, 0.8635, 0.8083, 0.7076], device='cuda:0')\n",
      "val_loss: 0.5151485780707928\n",
      "val_precision: tensor([0.7807, 0.8212, 0.7788, 0.7368], device='cuda:0')\n",
      "val_recall: tensor([0.6879, 0.8673, 0.8339, 0.6778], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.4768263714838544\n",
      "train_precision: tensor([0.7636, 0.8431, 0.8168, 0.7641], device='cuda:0')\n",
      "train_recall: tensor([0.7549, 0.8647, 0.8097, 0.7219], device='cuda:0')\n",
      "val_loss: 0.5123425118562555\n",
      "val_precision: tensor([0.7614, 0.8446, 0.7781, 0.7388], device='cuda:0')\n",
      "val_recall: tensor([0.7161, 0.8435, 0.8320, 0.6761], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.4724683983769227\n",
      "train_precision: tensor([0.7665, 0.8455, 0.8182, 0.7671], device='cuda:0')\n",
      "train_recall: tensor([0.7582, 0.8655, 0.8118, 0.7280], device='cuda:0')\n",
      "val_loss: 0.5196781850286892\n",
      "val_precision: tensor([0.7995, 0.8004, 0.7826, 0.7357], device='cuda:0')\n",
      "val_recall: tensor([0.6656, 0.8891, 0.8319, 0.6889], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.47059721733688875\n",
      "train_precision: tensor([0.7674, 0.8469, 0.8188, 0.7673], device='cuda:0')\n",
      "train_recall: tensor([0.7595, 0.8672, 0.8114, 0.7313], device='cuda:0')\n",
      "val_loss: 0.5134304636666754\n",
      "val_precision: tensor([0.7713, 0.8440, 0.7704, 0.7451], device='cuda:0')\n",
      "val_recall: tensor([0.7038, 0.8462, 0.8432, 0.6741], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.46709494125972156\n",
      "train_precision: tensor([0.7686, 0.8484, 0.8189, 0.7671], device='cuda:0')\n",
      "train_recall: tensor([0.7607, 0.8673, 0.8129, 0.7312], device='cuda:0')\n",
      "val_loss: 0.5046652378905722\n",
      "val_precision: tensor([0.7472, 0.8346, 0.8149, 0.7209], device='cuda:0')\n",
      "val_recall: tensor([0.7486, 0.8552, 0.7954, 0.7017], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.465962799770307\n",
      "train_precision: tensor([0.7676, 0.8483, 0.8214, 0.7670], device='cuda:0')\n",
      "train_recall: tensor([0.7628, 0.8665, 0.8134, 0.7257], device='cuda:0')\n",
      "val_loss: 0.5063852262096245\n",
      "val_precision: tensor([0.7567, 0.8335, 0.7986, 0.7325], device='cuda:0')\n",
      "val_recall: tensor([0.7301, 0.8542, 0.8112, 0.6923], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.46452806787800704\n",
      "train_precision: tensor([0.7677, 0.8486, 0.8217, 0.7758], device='cuda:0')\n",
      "train_recall: tensor([0.7619, 0.8678, 0.8132, 0.7384], device='cuda:0')\n",
      "val_loss: 0.506368606906979\n",
      "val_precision: tensor([0.7641, 0.8246, 0.8045, 0.7235], device='cuda:0')\n",
      "val_recall: tensor([0.7235, 0.8675, 0.8070, 0.7084], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.4632658635128276\n",
      "train_precision: tensor([0.7692, 0.8479, 0.8221, 0.7737], device='cuda:0')\n",
      "train_recall: tensor([0.7634, 0.8681, 0.8123, 0.7404], device='cuda:0')\n",
      "val_loss: 0.5062995320107756\n",
      "val_precision: tensor([0.7460, 0.8474, 0.8042, 0.7237], device='cuda:0')\n",
      "val_recall: tensor([0.7511, 0.8416, 0.8060, 0.7074], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.4605522692095932\n",
      "train_precision: tensor([0.7709, 0.8502, 0.8229, 0.7799], device='cuda:0')\n",
      "train_recall: tensor([0.7646, 0.8685, 0.8156, 0.7442], device='cuda:0')\n",
      "val_loss: 0.5086701444718016\n",
      "val_precision: tensor([0.7507, 0.8513, 0.7884, 0.7703], device='cuda:0')\n",
      "val_recall: tensor([0.7405, 0.8380, 0.8230, 0.6572], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.459466717518624\n",
      "train_precision: tensor([0.7699, 0.8504, 0.8209, 0.7803], device='cuda:0')\n",
      "train_recall: tensor([0.7633, 0.8693, 0.8136, 0.7437], device='cuda:0')\n",
      "val_loss: 0.5067906980754948\n",
      "val_precision: tensor([0.7288, 0.8579, 0.8156, 0.7437], device='cuda:0')\n",
      "val_recall: tensor([0.7806, 0.8270, 0.7922, 0.6966], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.45780768925962895\n",
      "train_precision: tensor([0.7700, 0.8514, 0.8235, 0.7822], device='cuda:0')\n",
      "train_recall: tensor([0.7661, 0.8684, 0.8148, 0.7488], device='cuda:0')\n",
      "val_loss: 0.5066578027580967\n",
      "val_precision: tensor([0.7600, 0.8453, 0.7916, 0.7236], device='cuda:0')\n",
      "val_recall: tensor([0.7322, 0.8445, 0.8230, 0.7071], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.4560912240175564\n",
      "train_precision: tensor([0.7729, 0.8528, 0.8250, 0.7830], device='cuda:0')\n",
      "train_recall: tensor([0.7671, 0.8697, 0.8184, 0.7491], device='cuda:0')\n",
      "val_loss: 0.5057150115485952\n",
      "val_precision: tensor([0.7621, 0.8336, 0.8020, 0.7191], device='cuda:0')\n",
      "val_recall: tensor([0.7293, 0.8606, 0.8108, 0.7162], device='cuda:0')\n",
      "Learning rate: 0.0005790681392562339\n",
      "train_loss: 0.45559386801418417\n",
      "train_precision: tensor([0.7729, 0.8521, 0.8239, 0.7810], device='cuda:0')\n",
      "train_recall: tensor([0.7668, 0.8708, 0.8157, 0.7486], device='cuda:0')\n",
      "val_loss: 0.5074648278601029\n",
      "val_precision: tensor([0.7431, 0.8473, 0.8080, 0.7353], device='cuda:0')\n",
      "val_recall: tensor([0.7558, 0.8421, 0.8024, 0.7054], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44848855485339456\n",
      "train_precision: tensor([0.7760, 0.8564, 0.8268, 0.7862], device='cuda:0')\n",
      "train_recall: tensor([0.7714, 0.8714, 0.8198, 0.7622], device='cuda:0')\n",
      "val_loss: 0.5045145681174863\n",
      "val_precision: tensor([0.7647, 0.8374, 0.7957, 0.7412], device='cuda:0')\n",
      "val_recall: tensor([0.7265, 0.8558, 0.8213, 0.7098], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.4472017917069287\n",
      "train_precision: tensor([0.7768, 0.8538, 0.8285, 0.7876], device='cuda:0')\n",
      "train_recall: tensor([0.7702, 0.8736, 0.8194, 0.7587], device='cuda:0')\n",
      "val_loss: 0.5031157089632099\n",
      "val_precision: tensor([0.7648, 0.8331, 0.8015, 0.7475], device='cuda:0')\n",
      "val_recall: tensor([0.7294, 0.8619, 0.8159, 0.7017], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44567324592318347\n",
      "train_precision: tensor([0.7775, 0.8561, 0.8290, 0.7902], device='cuda:0')\n",
      "train_recall: tensor([0.7732, 0.8728, 0.8202, 0.7646], device='cuda:0')\n",
      "val_loss: 0.503778137204026\n",
      "val_precision: tensor([0.7645, 0.8301, 0.8037, 0.7447], device='cuda:0')\n",
      "val_recall: tensor([0.7282, 0.8649, 0.8124, 0.7051], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44586207645034104\n",
      "train_precision: tensor([0.7789, 0.8545, 0.8285, 0.7876], device='cuda:0')\n",
      "train_recall: tensor([0.7708, 0.8735, 0.8210, 0.7661], device='cuda:0')\n",
      "val_loss: 0.502089342775465\n",
      "val_precision: tensor([0.7590, 0.8397, 0.8023, 0.7376], device='cuda:0')\n",
      "val_recall: tensor([0.7379, 0.8552, 0.8131, 0.7081], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.4455086795431612\n",
      "train_precision: tensor([0.7769, 0.8559, 0.8289, 0.7957], device='cuda:0')\n",
      "train_recall: tensor([0.7730, 0.8726, 0.8199, 0.7659], device='cuda:0')\n",
      "val_loss: 0.5030059594066203\n",
      "val_precision: tensor([0.7577, 0.8398, 0.8038, 0.7305], device='cuda:0')\n",
      "val_recall: tensor([0.7386, 0.8539, 0.8120, 0.7175], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44441444009865233\n",
      "train_precision: tensor([0.7789, 0.8559, 0.8292, 0.7891], device='cuda:0')\n",
      "train_recall: tensor([0.7718, 0.8740, 0.8217, 0.7652], device='cuda:0')\n",
      "val_loss: 0.5014652467074514\n",
      "val_precision: tensor([0.7580, 0.8381, 0.8073, 0.7353], device='cuda:0')\n",
      "val_recall: tensor([0.7425, 0.8569, 0.8081, 0.7145], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.4439035429743653\n",
      "train_precision: tensor([0.7783, 0.8565, 0.8302, 0.7926], device='cuda:0')\n",
      "train_recall: tensor([0.7744, 0.8726, 0.8220, 0.7633], device='cuda:0')\n",
      "val_loss: 0.5036757689814607\n",
      "val_precision: tensor([0.7641, 0.8355, 0.8010, 0.7397], device='cuda:0')\n",
      "val_recall: tensor([0.7298, 0.8599, 0.8161, 0.7165], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44446346599487624\n",
      "train_precision: tensor([0.7784, 0.8563, 0.8279, 0.7894], device='cuda:0')\n",
      "train_recall: tensor([0.7706, 0.8741, 0.8216, 0.7644], device='cuda:0')\n",
      "val_loss: 0.5021081405277011\n",
      "val_precision: tensor([0.7589, 0.8406, 0.8023, 0.7453], device='cuda:0')\n",
      "val_recall: tensor([0.7385, 0.8546, 0.8148, 0.7064], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.4448572145472365\n",
      "train_precision: tensor([0.7788, 0.8553, 0.8305, 0.7913], device='cuda:0')\n",
      "train_recall: tensor([0.7737, 0.8747, 0.8205, 0.7595], device='cuda:0')\n",
      "val_loss: 0.5028790617439928\n",
      "val_precision: tensor([0.7635, 0.8389, 0.7985, 0.7496], device='cuda:0')\n",
      "val_recall: tensor([0.7324, 0.8575, 0.8183, 0.7027], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44417997307080226\n",
      "train_precision: tensor([0.7784, 0.8562, 0.8282, 0.7926], device='cuda:0')\n",
      "train_recall: tensor([0.7730, 0.8718, 0.8215, 0.7675], device='cuda:0')\n",
      "val_loss: 0.5034999977640745\n",
      "val_precision: tensor([0.7601, 0.8409, 0.7979, 0.7422], device='cuda:0')\n",
      "val_recall: tensor([0.7347, 0.8523, 0.8173, 0.7088], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.4441527461209452\n",
      "train_precision: tensor([0.7775, 0.8567, 0.8300, 0.7935], device='cuda:0')\n",
      "train_recall: tensor([0.7733, 0.8738, 0.8211, 0.7642], device='cuda:0')\n",
      "val_loss: 0.5047027643989114\n",
      "val_precision: tensor([0.7697, 0.8386, 0.7917, 0.7322], device='cuda:0')\n",
      "val_recall: tensor([0.7213, 0.8548, 0.8278, 0.7172], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.4433112369332503\n",
      "train_precision: tensor([0.7787, 0.8568, 0.8293, 0.7929], device='cuda:0')\n",
      "train_recall: tensor([0.7722, 0.8741, 0.8220, 0.7696], device='cuda:0')\n",
      "val_loss: 0.5017724878647748\n",
      "val_precision: tensor([0.7597, 0.8401, 0.8045, 0.7352], device='cuda:0')\n",
      "val_recall: tensor([0.7398, 0.8544, 0.8137, 0.7178], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44335024790428174\n",
      "train_precision: tensor([0.7793, 0.8552, 0.8291, 0.7953], device='cuda:0')\n",
      "train_recall: tensor([0.7728, 0.8730, 0.8212, 0.7710], device='cuda:0')\n",
      "val_loss: 0.503118501115246\n",
      "val_precision: tensor([0.7651, 0.8353, 0.8008, 0.7316], device='cuda:0')\n",
      "val_recall: tensor([0.7288, 0.8602, 0.8168, 0.7148], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-05\n",
      "train_loss: 0.44318389397665914\n",
      "train_precision: tensor([0.7781, 0.8553, 0.8295, 0.7889], device='cuda:0')\n",
      "train_recall: tensor([0.7724, 0.8727, 0.8211, 0.7661], device='cuda:0')\n",
      "val_loss: 0.5030854007526606\n",
      "val_precision: tensor([0.7640, 0.8393, 0.7994, 0.7502], device='cuda:0')\n",
      "val_recall: tensor([0.7338, 0.8563, 0.8203, 0.6987], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "train_loss: 0.44263768470459464\n",
      "train_precision: tensor([0.7796, 0.8572, 0.8292, 0.7945], device='cuda:0')\n",
      "train_recall: tensor([0.7737, 0.8731, 0.8229, 0.7685], device='cuda:0')\n",
      "val_loss: 0.5022338762754152\n",
      "val_precision: tensor([0.7565, 0.8414, 0.8047, 0.7484], device='cuda:0')\n",
      "val_recall: tensor([0.7441, 0.8538, 0.8115, 0.6990], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "train_loss: 0.44158650186948395\n",
      "train_precision: tensor([0.7799, 0.8564, 0.8305, 0.7918], device='cuda:0')\n",
      "train_recall: tensor([0.7739, 0.8746, 0.8224, 0.7629], device='cuda:0')\n",
      "val_loss: 0.5024160807874022\n",
      "val_precision: tensor([0.7673, 0.8372, 0.7951, 0.7508], device='cuda:0')\n",
      "val_recall: tensor([0.7264, 0.8584, 0.8232, 0.6970], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "train_loss: 0.44346215304269687\n",
      "train_precision: tensor([0.7781, 0.8566, 0.8301, 0.7906], device='cuda:0')\n",
      "train_recall: tensor([0.7733, 0.8733, 0.8211, 0.7706], device='cuda:0')\n",
      "val_loss: 0.5041871686943439\n",
      "val_precision: tensor([0.7672, 0.8367, 0.7956, 0.7423], device='cuda:0')\n",
      "val_recall: tensor([0.7256, 0.8571, 0.8238, 0.7013], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "train_loss: 0.4422703615594857\n",
      "train_precision: tensor([0.7790, 0.8571, 0.8309, 0.7992], device='cuda:0')\n",
      "train_recall: tensor([0.7737, 0.8732, 0.8234, 0.7753], device='cuda:0')\n",
      "val_loss: 0.503383290492186\n",
      "val_precision: tensor([0.7617, 0.8432, 0.7962, 0.7436], device='cuda:0')\n",
      "val_recall: tensor([0.7333, 0.8508, 0.8225, 0.7088], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "train_loss: 0.4428027044672398\n",
      "train_precision: tensor([0.7792, 0.8570, 0.8292, 0.7956], device='cuda:0')\n",
      "train_recall: tensor([0.7738, 0.8727, 0.8229, 0.7652], device='cuda:0')\n",
      "val_loss: 0.5022700247393936\n",
      "val_precision: tensor([0.7583, 0.8449, 0.8001, 0.7348], device='cuda:0')\n",
      "val_recall: tensor([0.7402, 0.8494, 0.8174, 0.7128], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "train_loss: 0.4427433485158514\n",
      "train_precision: tensor([0.7786, 0.8571, 0.8302, 0.7939], device='cuda:0')\n",
      "train_recall: tensor([0.7736, 0.8731, 0.8225, 0.7697], device='cuda:0')\n",
      "val_loss: 0.5026760815071458\n",
      "val_precision: tensor([0.7618, 0.8430, 0.7963, 0.7468], device='cuda:0')\n",
      "val_recall: tensor([0.7349, 0.8515, 0.8209, 0.7040], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "train_loss: 0.4423341340644265\n",
      "train_precision: tensor([0.7790, 0.8565, 0.8300, 0.7928], device='cuda:0')\n",
      "train_recall: tensor([0.7732, 0.8745, 0.8220, 0.7613], device='cuda:0')\n",
      "val_loss: 0.5028770534681672\n",
      "val_precision: tensor([0.7620, 0.8376, 0.8011, 0.7373], device='cuda:0')\n",
      "val_recall: tensor([0.7330, 0.8557, 0.8166, 0.7155], device='cuda:0')\n",
      "Learning rate: 5.790681392562339e-06\n",
      "Early stopping at epoch 79 with best validation loss 0.5014652467074514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_name = f'efficient_net_norm_pad{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "set_seed(2233)\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "        \n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate)\n",
    "my_model = my_model.to('cuda')\n",
    "early_stop_patience = 15\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(my_model.state_dict(), f\"{run_path}.pt\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200427b-683b-4937-8b0d-fe7d39a3b6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d95ffee-8ed1-42d1-97f6-8d39b5e1b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[742  94 156   8]\n",
      " [ 87 873  34   6]\n",
      " [130  42 818  10]\n",
      " [  9   9   7  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      1000\n",
      "           1       0.86      0.87      0.87      1000\n",
      "           2       0.81      0.82      0.81      1000\n",
      "           3       0.76      0.75      0.75       100\n",
      "\n",
      "    accuracy                           0.81      3100\n",
      "   macro avg       0.80      0.80      0.80      3100\n",
      "weighted avg       0.81      0.81      0.81      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data', transform=transform_test, reduce=True)\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
