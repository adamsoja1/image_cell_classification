{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb74ae06-2775-4bb7-841c-8e11a4b3e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.002130450840051777\n",
    "batch_size = 312\n",
    "dropout_rate = 0.3373735453802333\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdce5c8-56c3-4c69-b604-58c13391dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        files = os.listdir(path)\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['filename'] = []\n",
    "        dataset_final['class'] = []\n",
    "        for filename in files:\n",
    "            dataset = pd.DataFrame()\n",
    "            if filename.endswith('.txt'):\n",
    "                files = get_images_list(f'{path}/{filename}')\n",
    "                dataset['filename'] = files\n",
    "                dataset['class'] = filename.split('_')[1][:-3]\n",
    "                dataset_final = pd.concat([dataset_final, dataset], ignore_index=True)\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"filename\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        #image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset[\"class\"].loc[idx]\n",
    "\n",
    "        if target == 'normal.':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target == 'inflamatory.':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target == 'tumor.':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target == 'other.':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "       \n",
    "     \n",
    "\n",
    "        \"\"\"To see transorms use:\n",
    "            image, target = trainset[15]\n",
    "            image = image.numpy()\n",
    "            image=np.swapaxes(image,0,1)\n",
    "            image=np.swapaxes(image,1,2)\n",
    "            plt.imshow(image)\"\"\"\n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c9ce6d-ff90-47af-9c56-b9fedb9fdef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1800: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1826: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1952: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2233)\n",
    "\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1a2930-151c-47fb-9dfa-049423ebc571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=4, dropout_rate=dropout_rate):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.base_model = models.efficientnet_b0(pretrained=False)\n",
    "        num_ftrs = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),  # Add dropout layer\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "model = EfficientNetB0(num_classes=4, dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abc075-67ea-4128-9aa2-bb4ee837775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8eb3155-df02-49ac-a6b2-6bbea2a732a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240804_233907-knpk7xx7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/knpk7xx7' target=\"_blank\">efficient_net_no_norm_no_pad2024-08-04 23:39:06.685997</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/knpk7xx7' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/knpk7xx7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.9350775430960302\n",
      "train_precision: tensor([0.5392, 0.6775, 0.6246, 0.1654], device='cuda:0')\n",
      "train_recall: tensor([0.5289, 0.7520, 0.6255, 0.0128], device='cuda:0')\n",
      "val_loss: 0.9296704551859482\n",
      "val_precision: tensor([0.6055, 0.6898, 0.5938, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.4121, 0.7843, 0.7615, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.8816413503080737\n",
      "train_precision: tensor([0.5616, 0.7017, 0.6607, 0.3867], device='cuda:0')\n",
      "train_recall: tensor([0.5658, 0.7673, 0.6561, 0.0227], device='cuda:0')\n",
      "val_loss: 0.8799063301569706\n",
      "val_precision: tensor([0.5616, 0.6451, 0.7209, 0.3333], device='cuda:0')\n",
      "val_recall: tensor([5.5596e-01, 8.5542e-01, 5.6519e-01, 3.3670e-04], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.8620405140912758\n",
      "train_precision: tensor([0.5721, 0.6951, 0.6625, 0.5285], device='cuda:0')\n",
      "train_recall: tensor([0.5645, 0.7692, 0.6614, 0.0442], device='cuda:0')\n",
      "val_loss: 0.7866130159110636\n",
      "val_precision: tensor([0.6466, 0.7039, 0.6608, 0.7790], device='cuda:0')\n",
      "val_recall: tensor([0.5162, 0.8073, 0.7527, 0.1222], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.8499621322435288\n",
      "train_precision: tensor([0.5814, 0.6991, 0.6620, 0.5841], device='cuda:0')\n",
      "train_recall: tensor([0.5698, 0.7713, 0.6630, 0.0877], device='cuda:0')\n",
      "val_loss: 0.8583531105840528\n",
      "val_precision: tensor([0.5477, 0.7052, 0.6732, 0.4409], device='cuda:0')\n",
      "val_recall: tensor([0.6160, 0.7616, 0.6007, 0.0138], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.8328913121507199\n",
      "train_precision: tensor([0.5837, 0.7033, 0.6708, 0.5092], device='cuda:0')\n",
      "train_recall: tensor([0.5727, 0.7717, 0.6753, 0.0758], device='cuda:0')\n",
      "val_loss: 0.7790743190090399\n",
      "val_precision: tensor([0.6284, 0.7494, 0.6642, 0.6851], device='cuda:0')\n",
      "val_recall: tensor([0.5687, 0.7634, 0.7623, 0.1963], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.7908026311324885\n",
      "train_precision: tensor([0.6105, 0.7206, 0.6856, 0.5700], device='cuda:0')\n",
      "train_recall: tensor([0.5874, 0.7844, 0.6962, 0.1928], device='cuda:0')\n",
      "val_loss: 0.7590706873987172\n",
      "val_precision: tensor([0.6535, 0.7274, 0.6772, 0.7764], device='cuda:0')\n",
      "val_recall: tensor([0.5679, 0.8031, 0.7471, 0.1835], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.78047256978399\n",
      "train_precision: tensor([0.6201, 0.7282, 0.6848, 0.5616], device='cuda:0')\n",
      "train_recall: tensor([0.5915, 0.7895, 0.6988, 0.2322], device='cuda:0')\n",
      "val_loss: 0.814257828166356\n",
      "val_precision: tensor([0.5996, 0.7637, 0.7001, 0.7350], device='cuda:0')\n",
      "val_recall: tensor([0.6480, 0.7517, 0.7022, 0.2354], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.7581482161112205\n",
      "train_precision: tensor([0.6296, 0.7391, 0.6927, 0.5815], device='cuda:0')\n",
      "train_recall: tensor([0.6013, 0.7947, 0.7090, 0.2687], device='cuda:0')\n",
      "val_loss: 1.261573827548607\n",
      "val_precision: tensor([0.5953, 0.8032, 0.6263, 0.7125], device='cuda:0')\n",
      "val_recall: tensor([0.5478, 0.7107, 0.7905, 0.2337], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.7688201509297153\n",
      "train_precision: tensor([0.6263, 0.7352, 0.6894, 0.5875], device='cuda:0')\n",
      "train_recall: tensor([0.5934, 0.7944, 0.7102, 0.2462], device='cuda:0')\n",
      "val_loss: 0.7350908628589398\n",
      "val_precision: tensor([0.6614, 0.7593, 0.6721, 0.8005], device='cuda:0')\n",
      "val_recall: tensor([0.5504, 0.8005, 0.7965, 0.2283], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.7431421437353458\n",
      "train_precision: tensor([0.6383, 0.7451, 0.6913, 0.5949], device='cuda:0')\n",
      "train_recall: tensor([0.5962, 0.8008, 0.7213, 0.2841], device='cuda:0')\n",
      "val_loss: 0.7981642223894596\n",
      "val_precision: tensor([0.5974, 0.7067, 0.7032, 0.6377], device='cuda:0')\n",
      "val_recall: tensor([0.6171, 0.8044, 0.6320, 0.1926], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.7315829771696569\n",
      "train_precision: tensor([0.6438, 0.7477, 0.7033, 0.6038], device='cuda:0')\n",
      "train_recall: tensor([0.6102, 0.8039, 0.7208, 0.3143], device='cuda:0')\n",
      "val_loss: 0.692861620336771\n",
      "val_precision: tensor([0.6762, 0.7787, 0.6909, 0.6509], device='cuda:0')\n",
      "val_recall: tensor([0.5879, 0.7896, 0.7957, 0.4212], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6891425131713358\n",
      "train_precision: tensor([0.6631, 0.7670, 0.7234, 0.6286], device='cuda:0')\n",
      "train_recall: tensor([0.6367, 0.8140, 0.7367, 0.3776], device='cuda:0')\n",
      "val_loss: 0.6780024086301392\n",
      "val_precision: tensor([0.6621, 0.7906, 0.7164, 0.6751], device='cuda:0')\n",
      "val_recall: tensor([0.6356, 0.7932, 0.7706, 0.4121], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6731421573760721\n",
      "train_precision: tensor([0.6696, 0.7723, 0.7298, 0.6405], device='cuda:0')\n",
      "train_recall: tensor([0.6428, 0.8177, 0.7424, 0.4104], device='cuda:0')\n",
      "val_loss: 0.653097841284565\n",
      "val_precision: tensor([0.6804, 0.7777, 0.7372, 0.6926], device='cuda:0')\n",
      "val_recall: tensor([0.6480, 0.8293, 0.7474, 0.4680], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6585195678757998\n",
      "train_precision: tensor([0.6756, 0.7775, 0.7374, 0.6456], device='cuda:0')\n",
      "train_recall: tensor([0.6529, 0.8209, 0.7446, 0.4395], device='cuda:0')\n",
      "val_loss: 0.6782068087643868\n",
      "val_precision: tensor([0.6754, 0.8462, 0.6687, 0.6149], device='cuda:0')\n",
      "val_recall: tensor([0.6166, 0.7202, 0.8357, 0.5306], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6487736578257579\n",
      "train_precision: tensor([0.6791, 0.7820, 0.7414, 0.6580], device='cuda:0')\n",
      "train_recall: tensor([0.6609, 0.8211, 0.7468, 0.4561], device='cuda:0')\n",
      "val_loss: 0.639244055123748\n",
      "val_precision: tensor([0.6495, 0.8173, 0.7555, 0.7733], device='cuda:0')\n",
      "val_recall: tensor([0.7237, 0.7826, 0.7345, 0.4306], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.662708854986725\n",
      "train_precision: tensor([0.6765, 0.7728, 0.7367, 0.6602], device='cuda:0')\n",
      "train_recall: tensor([0.6505, 0.8201, 0.7452, 0.4332], device='cuda:0')\n",
      "val_loss: 0.6297133140064575\n",
      "val_precision: tensor([0.6956, 0.8068, 0.7326, 0.6128], device='cuda:0')\n",
      "val_recall: tensor([0.6462, 0.8044, 0.7915, 0.5734], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6318088396194192\n",
      "train_precision: tensor([0.6882, 0.7880, 0.7498, 0.6651], device='cuda:0')\n",
      "train_recall: tensor([0.6676, 0.8268, 0.7554, 0.4872], device='cuda:0')\n",
      "val_loss: 0.6258851900898121\n",
      "val_precision: tensor([0.6844, 0.7813, 0.7788, 0.6462], device='cuda:0')\n",
      "val_recall: tensor([0.6949, 0.8488, 0.7138, 0.5283], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6315462525247316\n",
      "train_precision: tensor([0.6885, 0.7886, 0.7491, 0.6723], device='cuda:0')\n",
      "train_recall: tensor([0.6672, 0.8294, 0.7542, 0.4864], device='cuda:0')\n",
      "val_loss: 0.6186368429177517\n",
      "val_precision: tensor([0.7306, 0.8109, 0.6915, 0.7713], device='cuda:0')\n",
      "val_recall: tensor([0.5828, 0.8189, 0.8514, 0.4724], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6168387124777186\n",
      "train_precision: tensor([0.6964, 0.7917, 0.7562, 0.6695], device='cuda:0')\n",
      "train_recall: tensor([0.6750, 0.8314, 0.7603, 0.5033], device='cuda:0')\n",
      "val_loss: 0.6039089401428764\n",
      "val_precision: tensor([0.7082, 0.7963, 0.7461, 0.7627], device='cuda:0')\n",
      "val_recall: tensor([0.6634, 0.8328, 0.7908, 0.4384], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6154753573574072\n",
      "train_precision: tensor([0.6955, 0.7936, 0.7546, 0.6752], device='cuda:0')\n",
      "train_recall: tensor([0.6750, 0.8305, 0.7600, 0.5117], device='cuda:0')\n",
      "val_loss: 0.607548034573729\n",
      "val_precision: tensor([0.7191, 0.7861, 0.7479, 0.6824], device='cuda:0')\n",
      "val_recall: tensor([0.6452, 0.8436, 0.7823, 0.5707], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6216787311785107\n",
      "train_precision: tensor([0.6918, 0.7904, 0.7546, 0.6680], device='cuda:0')\n",
      "train_recall: tensor([0.6731, 0.8273, 0.7587, 0.5009], device='cuda:0')\n",
      "val_loss: 0.5910707962875431\n",
      "val_precision: tensor([0.7287, 0.8033, 0.7403, 0.7641], device='cuda:0')\n",
      "val_recall: tensor([0.6581, 0.8393, 0.8037, 0.5071], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.6067866713716953\n",
      "train_precision: tensor([0.7003, 0.7946, 0.7618, 0.6816], device='cuda:0')\n",
      "train_recall: tensor([0.6818, 0.8318, 0.7629, 0.5323], device='cuda:0')\n",
      "val_loss: 0.5963855197502149\n",
      "val_precision: tensor([0.7078, 0.8262, 0.7319, 0.7888], device='cuda:0')\n",
      "val_recall: tensor([0.6687, 0.8037, 0.8210, 0.4778], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5942608194617643\n",
      "train_precision: tensor([0.7072, 0.7994, 0.7673, 0.6931], device='cuda:0')\n",
      "train_recall: tensor([0.6883, 0.8352, 0.7691, 0.5514], device='cuda:0')\n",
      "val_loss: 0.5943212882691139\n",
      "val_precision: tensor([0.6984, 0.7944, 0.7821, 0.7222], device='cuda:0')\n",
      "val_recall: tensor([0.7022, 0.8380, 0.7509, 0.5734], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5906169667991394\n",
      "train_precision: tensor([0.7088, 0.8015, 0.7698, 0.6892], device='cuda:0')\n",
      "train_recall: tensor([0.6905, 0.8357, 0.7718, 0.5556], device='cuda:0')\n",
      "val_loss: 0.6086953829067785\n",
      "val_precision: tensor([0.7052, 0.8547, 0.7038, 0.7027], device='cuda:0')\n",
      "val_recall: tensor([0.6458, 0.7623, 0.8496, 0.5976], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5842287104863387\n",
      "train_precision: tensor([0.7100, 0.8042, 0.7709, 0.6872], device='cuda:0')\n",
      "train_recall: tensor([0.6951, 0.8361, 0.7702, 0.5646], device='cuda:0')\n",
      "val_loss: 0.574660900376133\n",
      "val_precision: tensor([0.7302, 0.7991, 0.7737, 0.6354], device='cuda:0')\n",
      "val_recall: tensor([0.6759, 0.8476, 0.7814, 0.6589], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5775623548619114\n",
      "train_precision: tensor([0.7108, 0.8074, 0.7752, 0.6872], device='cuda:0')\n",
      "train_recall: tensor([0.6983, 0.8388, 0.7723, 0.5681], device='cuda:0')\n",
      "val_loss: 0.6099596575305268\n",
      "val_precision: tensor([0.7339, 0.8272, 0.6974, 0.7070], device='cuda:0')\n",
      "val_recall: tensor([0.6114, 0.8015, 0.8513, 0.5451], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5737481819700953\n",
      "train_precision: tensor([0.7125, 0.8084, 0.7771, 0.6913], device='cuda:0')\n",
      "train_recall: tensor([0.7015, 0.8389, 0.7731, 0.5730], device='cuda:0')\n",
      "val_loss: 0.5780167624958463\n",
      "val_precision: tensor([0.7551, 0.8031, 0.7352, 0.7127], device='cuda:0')\n",
      "val_recall: tensor([0.6277, 0.8495, 0.8280, 0.6030], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.576789732811586\n",
      "train_precision: tensor([0.7121, 0.8055, 0.7767, 0.7009], device='cuda:0')\n",
      "train_recall: tensor([0.7003, 0.8373, 0.7721, 0.5824], device='cuda:0')\n",
      "val_loss: 0.5803359743912477\n",
      "val_precision: tensor([0.7313, 0.8101, 0.7473, 0.7185], device='cuda:0')\n",
      "val_recall: tensor([0.6590, 0.8352, 0.8120, 0.5845], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5781076315179445\n",
      "train_precision: tensor([0.7144, 0.8033, 0.7756, 0.6956], device='cuda:0')\n",
      "train_recall: tensor([0.6973, 0.8391, 0.7735, 0.5704], device='cuda:0')\n",
      "val_loss: 0.585002080914942\n",
      "val_precision: tensor([0.7150, 0.7968, 0.7744, 0.6898], device='cuda:0')\n",
      "val_recall: tensor([0.6985, 0.8415, 0.7681, 0.5182], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5632422867032371\n",
      "train_precision: tensor([0.7177, 0.8118, 0.7829, 0.6973], device='cuda:0')\n",
      "train_recall: tensor([0.7086, 0.8423, 0.7756, 0.5883], device='cuda:0')\n",
      "val_loss: 0.5625677399740026\n",
      "val_precision: tensor([0.7147, 0.8164, 0.7782, 0.7207], device='cuda:0')\n",
      "val_recall: tensor([0.7058, 0.8385, 0.7801, 0.5987], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5570445107877341\n",
      "train_precision: tensor([0.7216, 0.8132, 0.7851, 0.7065], device='cuda:0')\n",
      "train_recall: tensor([0.7113, 0.8425, 0.7798, 0.6001], device='cuda:0')\n",
      "val_loss: 0.563993313626663\n",
      "val_precision: tensor([0.7036, 0.8083, 0.7941, 0.8154], device='cuda:0')\n",
      "val_recall: tensor([0.7340, 0.8472, 0.7505, 0.5175], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5731114810454309\n",
      "train_precision: tensor([0.7174, 0.8074, 0.7800, 0.6985], device='cuda:0')\n",
      "train_recall: tensor([0.7059, 0.8395, 0.7755, 0.5733], device='cuda:0')\n",
      "val_loss: 0.5686078944520371\n",
      "val_precision: tensor([0.7362, 0.8162, 0.7494, 0.7227], device='cuda:0')\n",
      "val_recall: tensor([0.6663, 0.8304, 0.8238, 0.5660], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5694715352553241\n",
      "train_precision: tensor([0.7202, 0.8053, 0.7814, 0.6935], device='cuda:0')\n",
      "train_recall: tensor([0.7048, 0.8406, 0.7763, 0.5825], device='cuda:0')\n",
      "val_loss: 0.6088699800138538\n",
      "val_precision: tensor([0.7201, 0.8011, 0.7344, 0.7791], device='cuda:0')\n",
      "val_recall: tensor([0.6509, 0.8179, 0.8228, 0.4263], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5597436173733848\n",
      "train_precision: tensor([0.7238, 0.8109, 0.7861, 0.7063], device='cuda:0')\n",
      "train_recall: tensor([0.7129, 0.8432, 0.7794, 0.5909], device='cuda:0')\n",
      "val_loss: 0.563687269349356\n",
      "val_precision: tensor([0.6828, 0.8797, 0.7731, 0.7066], device='cuda:0')\n",
      "val_recall: tensor([0.7641, 0.7541, 0.7992, 0.6357], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5466172716787142\n",
      "train_precision: tensor([0.7268, 0.8173, 0.7906, 0.7136], device='cuda:0')\n",
      "train_recall: tensor([0.7181, 0.8442, 0.7841, 0.6227], device='cuda:0')\n",
      "val_loss: 0.5563070187093438\n",
      "val_precision: tensor([0.7225, 0.8297, 0.7714, 0.7590], device='cuda:0')\n",
      "val_recall: tensor([0.7170, 0.8216, 0.8064, 0.5461], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5420116732013243\n",
      "train_precision: tensor([0.7293, 0.8190, 0.7924, 0.7208], device='cuda:0')\n",
      "train_recall: tensor([0.7199, 0.8470, 0.7855, 0.6297], device='cuda:0')\n",
      "val_loss: 0.543001726068355\n",
      "val_precision: tensor([0.7115, 0.8364, 0.7926, 0.7456], device='cuda:0')\n",
      "val_recall: tensor([0.7390, 0.8249, 0.7853, 0.6296], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5392509023233145\n",
      "train_precision: tensor([0.7300, 0.8204, 0.7931, 0.7150], device='cuda:0')\n",
      "train_recall: tensor([0.7214, 0.8464, 0.7867, 0.6303], device='cuda:0')\n",
      "val_loss: 0.5491625974709923\n",
      "val_precision: tensor([0.7267, 0.8189, 0.7752, 0.7766], device='cuda:0')\n",
      "val_recall: tensor([0.7085, 0.8345, 0.8028, 0.5455], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5362353807177357\n",
      "train_precision: tensor([0.7314, 0.8211, 0.7946, 0.7137], device='cuda:0')\n",
      "train_recall: tensor([0.7244, 0.8464, 0.7873, 0.6267], device='cuda:0')\n",
      "val_loss: 0.5649373757879477\n",
      "val_precision: tensor([0.7299, 0.8113, 0.7681, 0.7400], device='cuda:0')\n",
      "val_recall: tensor([0.6945, 0.8363, 0.7970, 0.5912], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5538251217460078\n",
      "train_precision: tensor([0.7239, 0.8129, 0.7889, 0.7074], device='cuda:0')\n",
      "train_recall: tensor([0.7129, 0.8438, 0.7807, 0.6185], device='cuda:0')\n",
      "val_loss: 0.6725899109969268\n",
      "val_precision: tensor([0.6332, 0.8449, 0.7419, 0.6560], device='cuda:0')\n",
      "val_recall: tensor([0.7423, 0.7251, 0.7316, 0.5471], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5550984911977466\n",
      "train_precision: tensor([0.7221, 0.8154, 0.7867, 0.7090], device='cuda:0')\n",
      "train_recall: tensor([0.7141, 0.8430, 0.7801, 0.6076], device='cuda:0')\n",
      "val_loss: 0.5410087321054291\n",
      "val_precision: tensor([0.7479, 0.8172, 0.7754, 0.7297], device='cuda:0')\n",
      "val_recall: tensor([0.6903, 0.8492, 0.8139, 0.6428], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5291670312556196\n",
      "train_precision: tensor([0.7347, 0.8240, 0.7959, 0.7179], device='cuda:0')\n",
      "train_recall: tensor([0.7253, 0.8484, 0.7904, 0.6462], device='cuda:0')\n",
      "val_loss: 0.5621577499283327\n",
      "val_precision: tensor([0.7280, 0.7992, 0.7875, 0.7248], device='cuda:0')\n",
      "val_recall: tensor([0.6909, 0.8592, 0.7819, 0.6003], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5313662447586807\n",
      "train_precision: tensor([0.7321, 0.8233, 0.7983, 0.7118], device='cuda:0')\n",
      "train_recall: tensor([0.7279, 0.8467, 0.7879, 0.6433], device='cuda:0')\n",
      "val_loss: 0.548692062698506\n",
      "val_precision: tensor([0.7185, 0.8033, 0.8095, 0.7761], device='cuda:0')\n",
      "val_recall: tensor([0.7292, 0.8607, 0.7644, 0.5391], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.52526984120488\n",
      "train_precision: tensor([0.7351, 0.8267, 0.8005, 0.7212], device='cuda:0')\n",
      "train_recall: tensor([0.7299, 0.8499, 0.7917, 0.6483], device='cuda:0')\n",
      "val_loss: 0.5428771537703436\n",
      "val_precision: tensor([0.7319, 0.8400, 0.7705, 0.7559], device='cuda:0')\n",
      "val_recall: tensor([0.7139, 0.8181, 0.8249, 0.6047], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5470387782085098\n",
      "train_precision: tensor([0.7220, 0.8204, 0.7950, 0.7068], device='cuda:0')\n",
      "train_recall: tensor([0.7231, 0.8437, 0.7808, 0.6221], device='cuda:0')\n",
      "val_loss: 0.5466374639119651\n",
      "val_precision: tensor([0.7514, 0.8179, 0.7610, 0.7787], device='cuda:0')\n",
      "val_recall: tensor([0.6726, 0.8475, 0.8340, 0.5650], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5232205651754565\n",
      "train_precision: tensor([0.7384, 0.8266, 0.8011, 0.7289], device='cuda:0')\n",
      "train_recall: tensor([0.7324, 0.8510, 0.7919, 0.6571], device='cuda:0')\n",
      "val_loss: 0.5352411188587949\n",
      "val_precision: tensor([0.7352, 0.8014, 0.8209, 0.6978], device='cuda:0')\n",
      "val_recall: tensor([0.7251, 0.8699, 0.7627, 0.6926], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5200295576768966\n",
      "train_precision: tensor([0.7392, 0.8270, 0.8031, 0.7277], device='cuda:0')\n",
      "train_recall: tensor([0.7336, 0.8510, 0.7933, 0.6599], device='cuda:0')\n",
      "val_loss: 0.5441703854783161\n",
      "val_precision: tensor([0.7244, 0.8346, 0.7869, 0.7107], device='cuda:0')\n",
      "val_recall: tensor([0.7256, 0.8288, 0.7964, 0.6626], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5160763352806579\n",
      "train_precision: tensor([0.7413, 0.8277, 0.8054, 0.7253], device='cuda:0')\n",
      "train_recall: tensor([0.7351, 0.8535, 0.7937, 0.6651], device='cuda:0')\n",
      "val_loss: 0.542661610084611\n",
      "val_precision: tensor([0.7305, 0.8518, 0.7609, 0.7830], device='cuda:0')\n",
      "val_recall: tensor([0.7092, 0.8100, 0.8367, 0.6158], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.512977143979384\n",
      "train_precision: tensor([0.7425, 0.8292, 0.8065, 0.7320], device='cuda:0')\n",
      "train_recall: tensor([0.7385, 0.8524, 0.7953, 0.6684], device='cuda:0')\n",
      "val_loss: 0.5371041459006232\n",
      "val_precision: tensor([0.7295, 0.8319, 0.7889, 0.7807], device='cuda:0')\n",
      "val_recall: tensor([0.7313, 0.8376, 0.8020, 0.5778], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5125910106435396\n",
      "train_precision: tensor([0.7423, 0.8313, 0.8065, 0.7286], device='cuda:0')\n",
      "train_recall: tensor([0.7405, 0.8522, 0.7954, 0.6636], device='cuda:0')\n",
      "val_loss: 0.5563483225131357\n",
      "val_precision: tensor([0.7425, 0.8053, 0.7770, 0.7349], device='cuda:0')\n",
      "val_recall: tensor([0.6809, 0.8504, 0.8073, 0.6458], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5158482882125284\n",
      "train_precision: tensor([0.7431, 0.8301, 0.8047, 0.7234], device='cuda:0')\n",
      "train_recall: tensor([0.7370, 0.8527, 0.7961, 0.6639], device='cuda:0')\n",
      "val_loss: 0.5393035818596144\n",
      "val_precision: tensor([0.7344, 0.8533, 0.7591, 0.7486], device='cuda:0')\n",
      "val_recall: tensor([0.7154, 0.8110, 0.8322, 0.5926], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5172860909615615\n",
      "train_precision: tensor([0.7423, 0.8264, 0.8035, 0.7273], device='cuda:0')\n",
      "train_recall: tensor([0.7349, 0.8509, 0.7942, 0.6681], device='cuda:0')\n",
      "val_loss: 0.5586436236830982\n",
      "val_precision: tensor([0.7136, 0.8172, 0.7888, 0.7677], device='cuda:0')\n",
      "val_recall: tensor([0.7268, 0.8329, 0.7812, 0.5519], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5157650948781926\n",
      "train_precision: tensor([0.7411, 0.8256, 0.8060, 0.7363], device='cuda:0')\n",
      "train_recall: tensor([0.7344, 0.8532, 0.7938, 0.6684], device='cuda:0')\n",
      "val_loss: 0.529445335973759\n",
      "val_precision: tensor([0.7478, 0.8070, 0.8125, 0.6772], device='cuda:0')\n",
      "val_recall: tensor([0.7155, 0.8690, 0.7792, 0.7263], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5033635378143438\n",
      "train_precision: tensor([0.7455, 0.8333, 0.8092, 0.7307], device='cuda:0')\n",
      "train_recall: tensor([0.7413, 0.8542, 0.7990, 0.6801], device='cuda:0')\n",
      "val_loss: 0.5229834144985354\n",
      "val_precision: tensor([0.7394, 0.8182, 0.8071, 0.7784], device='cuda:0')\n",
      "val_recall: tensor([0.7324, 0.8619, 0.7856, 0.6444], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5126606366976945\n",
      "train_precision: tensor([0.7456, 0.8269, 0.8072, 0.7315], device='cuda:0')\n",
      "train_recall: tensor([0.7371, 0.8538, 0.7966, 0.6732], device='cuda:0')\n",
      "val_loss: 0.5518984085804707\n",
      "val_precision: tensor([0.7102, 0.8591, 0.7651, 0.7660], device='cuda:0')\n",
      "val_recall: tensor([0.7259, 0.7896, 0.8273, 0.5953], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5167972764705885\n",
      "train_precision: tensor([0.7419, 0.8261, 0.8039, 0.7309], device='cuda:0')\n",
      "train_recall: tensor([0.7318, 0.8533, 0.7944, 0.6752], device='cuda:0')\n",
      "val_loss: 0.5285039832060402\n",
      "val_precision: tensor([0.7537, 0.8257, 0.7801, 0.7547], device='cuda:0')\n",
      "val_recall: tensor([0.6968, 0.8538, 0.8234, 0.6495], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5045638215905177\n",
      "train_precision: tensor([0.7468, 0.8308, 0.8085, 0.7402], device='cuda:0')\n",
      "train_recall: tensor([0.7415, 0.8544, 0.7973, 0.6848], device='cuda:0')\n",
      "val_loss: 0.527460296009038\n",
      "val_precision: tensor([0.7374, 0.8373, 0.7826, 0.7696], device='cuda:0')\n",
      "val_recall: tensor([0.7251, 0.8361, 0.8147, 0.5949], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.5155758743535278\n",
      "train_precision: tensor([0.7431, 0.8256, 0.8054, 0.7300], device='cuda:0')\n",
      "train_recall: tensor([0.7355, 0.8528, 0.7942, 0.6662], device='cuda:0')\n",
      "val_loss: 0.5284255279882534\n",
      "val_precision: tensor([0.7376, 0.8478, 0.7798, 0.7355], device='cuda:0')\n",
      "val_recall: tensor([0.7286, 0.8263, 0.8200, 0.6320], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.49475859929584454\n",
      "train_precision: tensor([0.7525, 0.8348, 0.8128, 0.7417], device='cuda:0')\n",
      "train_recall: tensor([0.7455, 0.8578, 0.8027, 0.6977], device='cuda:0')\n",
      "val_loss: 0.5212875701285697\n",
      "val_precision: tensor([0.7154, 0.8566, 0.8066, 0.7800], device='cuda:0')\n",
      "val_recall: tensor([0.7741, 0.8174, 0.7940, 0.6172], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.49054846210818853\n",
      "train_precision: tensor([0.7514, 0.8365, 0.8156, 0.7499], device='cuda:0')\n",
      "train_recall: tensor([0.7492, 0.8577, 0.8024, 0.7030], device='cuda:0')\n",
      "val_loss: 0.5390923314199254\n",
      "val_precision: tensor([0.7656, 0.8345, 0.7451, 0.8174], device='cuda:0')\n",
      "val_recall: tensor([0.6648, 0.8415, 0.8614, 0.5485], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.4890470894915964\n",
      "train_precision: tensor([0.7540, 0.8363, 0.8155, 0.7424], device='cuda:0')\n",
      "train_recall: tensor([0.7497, 0.8582, 0.8029, 0.7045], device='cuda:0')\n",
      "val_loss: 0.5497622867492405\n",
      "val_precision: tensor([0.7215, 0.8784, 0.7499, 0.8234], device='cuda:0')\n",
      "val_recall: tensor([0.7319, 0.7757, 0.8504, 0.5653], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.48749387852512355\n",
      "train_precision: tensor([0.7538, 0.8391, 0.8174, 0.7493], device='cuda:0')\n",
      "train_recall: tensor([0.7524, 0.8570, 0.8060, 0.7068], device='cuda:0')\n",
      "val_loss: 0.5341615175475946\n",
      "val_precision: tensor([0.7265, 0.8525, 0.7814, 0.6913], device='cuda:0')\n",
      "val_recall: tensor([0.7335, 0.8130, 0.8098, 0.6936], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.4872191720500221\n",
      "train_precision: tensor([0.7552, 0.8380, 0.8153, 0.7469], device='cuda:0')\n",
      "train_recall: tensor([0.7502, 0.8598, 0.8041, 0.7049], device='cuda:0')\n",
      "val_loss: 0.5121944080534819\n",
      "val_precision: tensor([0.7644, 0.8458, 0.7748, 0.7397], device='cuda:0')\n",
      "val_recall: tensor([0.7087, 0.8367, 0.8443, 0.6946], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.48381455430790715\n",
      "train_precision: tensor([0.7543, 0.8396, 0.8171, 0.7538], device='cuda:0')\n",
      "train_recall: tensor([0.7513, 0.8586, 0.8060, 0.7150], device='cuda:0')\n",
      "val_loss: 0.5259677175734494\n",
      "val_precision: tensor([0.7700, 0.8256, 0.7683, 0.7659], device='cuda:0')\n",
      "val_recall: tensor([0.6833, 0.8546, 0.8418, 0.6269], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.48202134303326877\n",
      "train_precision: tensor([0.7569, 0.8399, 0.8174, 0.7537], device='cuda:0')\n",
      "train_recall: tensor([0.7531, 0.8604, 0.8059, 0.7128], device='cuda:0')\n",
      "val_loss: 0.5201232910558984\n",
      "val_precision: tensor([0.7752, 0.8320, 0.7687, 0.6514], device='cuda:0')\n",
      "val_recall: tensor([0.6695, 0.8525, 0.8431, 0.7495], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.48023850521605316\n",
      "train_precision: tensor([0.7566, 0.8404, 0.8174, 0.7582], device='cuda:0')\n",
      "train_recall: tensor([0.7537, 0.8600, 0.8065, 0.7117], device='cuda:0')\n",
      "val_loss: 0.5199754393181285\n",
      "val_precision: tensor([0.7545, 0.8068, 0.8037, 0.7688], device='cuda:0')\n",
      "val_recall: tensor([0.7092, 0.8763, 0.7976, 0.6269], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.4780972840910553\n",
      "train_precision: tensor([0.7588, 0.8411, 0.8195, 0.7525], device='cuda:0')\n",
      "train_recall: tensor([0.7542, 0.8613, 0.8088, 0.7160], device='cuda:0')\n",
      "val_loss: 0.5198321594177066\n",
      "val_precision: tensor([0.7615, 0.8262, 0.7818, 0.7387], device='cuda:0')\n",
      "val_recall: tensor([0.6989, 0.8578, 0.8248, 0.6576], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.476767061151164\n",
      "train_precision: tensor([0.7593, 0.8429, 0.8202, 0.7533], device='cuda:0')\n",
      "train_recall: tensor([0.7572, 0.8615, 0.8082, 0.7169], device='cuda:0')\n",
      "val_loss: 0.5151446649955737\n",
      "val_precision: tensor([0.7202, 0.8369, 0.8265, 0.7287], device='cuda:0')\n",
      "val_recall: tensor([0.7712, 0.8385, 0.7694, 0.7017], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.47460344624104106\n",
      "train_precision: tensor([0.7605, 0.8418, 0.8211, 0.7539], device='cuda:0')\n",
      "train_recall: tensor([0.7559, 0.8620, 0.8093, 0.7274], device='cuda:0')\n",
      "val_loss: 0.5247450839426067\n",
      "val_precision: tensor([0.7285, 0.8131, 0.8306, 0.7826], device='cuda:0')\n",
      "val_recall: tensor([0.7585, 0.8623, 0.7623, 0.6316], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.47431996148971756\n",
      "train_precision: tensor([0.7608, 0.8423, 0.8190, 0.7606], device='cuda:0')\n",
      "train_recall: tensor([0.7560, 0.8618, 0.8103, 0.7133], device='cuda:0')\n",
      "val_loss: 0.5177552751391321\n",
      "val_precision: tensor([0.7628, 0.8346, 0.7776, 0.7492], device='cuda:0')\n",
      "val_recall: tensor([0.7006, 0.8482, 0.8362, 0.6737], device='cuda:0')\n",
      "Learning rate: 0.002130450840051777\n",
      "train_loss: 0.4809219455251846\n",
      "train_precision: tensor([0.7577, 0.8396, 0.8171, 0.7559], device='cuda:0')\n",
      "train_recall: tensor([0.7508, 0.8602, 0.8086, 0.7172], device='cuda:0')\n",
      "val_loss: 0.5593170668627765\n",
      "val_precision: tensor([0.6536, 0.8619, 0.8656, 0.8068], device='cuda:0')\n",
      "val_recall: tensor([0.8531, 0.8002, 0.6859, 0.5976], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.43482966727546063\n",
      "train_precision: tensor([0.7787, 0.8553, 0.8373, 0.7967], device='cuda:0')\n",
      "train_recall: tensor([0.7773, 0.8724, 0.8243, 0.7763], device='cuda:0')\n",
      "val_loss: 0.48922493016800367\n",
      "val_precision: tensor([0.7607, 0.8511, 0.8039, 0.7756], device='cuda:0')\n",
      "val_recall: tensor([0.7465, 0.8475, 0.8305, 0.6970], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.42310700248737637\n",
      "train_precision: tensor([0.7858, 0.8609, 0.8402, 0.8043], device='cuda:0')\n",
      "train_recall: tensor([0.7812, 0.8769, 0.8307, 0.7935], device='cuda:0')\n",
      "val_loss: 0.4881595538274662\n",
      "val_precision: tensor([0.7610, 0.8363, 0.8249, 0.7509], device='cuda:0')\n",
      "val_recall: tensor([0.7530, 0.8657, 0.8072, 0.7276], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.4195979798134249\n",
      "train_precision: tensor([0.7870, 0.8610, 0.8437, 0.8119], device='cuda:0')\n",
      "train_recall: tensor([0.7851, 0.8777, 0.8308, 0.7978], device='cuda:0')\n",
      "val_loss: 0.48879121626551086\n",
      "val_precision: tensor([0.7693, 0.8429, 0.8093, 0.7599], device='cuda:0')\n",
      "val_recall: tensor([0.7415, 0.8607, 0.8264, 0.7128], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.41607659112213313\n",
      "train_precision: tensor([0.7889, 0.8618, 0.8446, 0.8111], device='cuda:0')\n",
      "train_recall: tensor([0.7851, 0.8797, 0.8318, 0.8045], device='cuda:0')\n",
      "val_loss: 0.48917554832390836\n",
      "val_precision: tensor([0.7574, 0.8504, 0.8115, 0.7840], device='cuda:0')\n",
      "val_recall: tensor([0.7579, 0.8482, 0.8222, 0.6953], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.4111298532029195\n",
      "train_precision: tensor([0.7904, 0.8637, 0.8458, 0.8121], device='cuda:0')\n",
      "train_recall: tensor([0.7874, 0.8792, 0.8344, 0.8059], device='cuda:0')\n",
      "val_loss: 0.4907026343248986\n",
      "val_precision: tensor([0.7662, 0.8434, 0.8065, 0.7936], device='cuda:0')\n",
      "val_recall: tensor([0.7409, 0.8589, 0.8289, 0.6899], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.41070925095084787\n",
      "train_precision: tensor([0.7915, 0.8641, 0.8471, 0.8153], device='cuda:0')\n",
      "train_recall: tensor([0.7882, 0.8802, 0.8356, 0.8076], device='cuda:0')\n",
      "val_loss: 0.4907053333480616\n",
      "val_precision: tensor([0.7699, 0.8400, 0.8105, 0.7815], device='cuda:0')\n",
      "val_recall: tensor([0.7401, 0.8625, 0.8279, 0.7071], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.40918544652846106\n",
      "train_precision: tensor([0.7914, 0.8634, 0.8462, 0.8158], device='cuda:0')\n",
      "train_recall: tensor([0.7879, 0.8807, 0.8334, 0.8118], device='cuda:0')\n",
      "val_loss: 0.48964344619496447\n",
      "val_precision: tensor([0.7592, 0.8499, 0.8113, 0.7714], device='cuda:0')\n",
      "val_recall: tensor([0.7531, 0.8516, 0.8225, 0.7111], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.4066616739261306\n",
      "train_precision: tensor([0.7949, 0.8644, 0.8477, 0.8158], device='cuda:0')\n",
      "train_recall: tensor([0.7899, 0.8814, 0.8366, 0.8130], device='cuda:0')\n",
      "val_loss: 0.48987694739087206\n",
      "val_precision: tensor([0.7631, 0.8451, 0.8120, 0.7645], device='cuda:0')\n",
      "val_recall: tensor([0.7469, 0.8565, 0.8227, 0.7215], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.40485343224597425\n",
      "train_precision: tensor([0.7945, 0.8656, 0.8481, 0.8165], device='cuda:0')\n",
      "train_recall: tensor([0.7906, 0.8820, 0.8371, 0.8084], device='cuda:0')\n",
      "val_loss: 0.48837114608771093\n",
      "val_precision: tensor([0.7649, 0.8424, 0.8125, 0.7742], device='cuda:0')\n",
      "val_recall: tensor([0.7448, 0.8580, 0.8238, 0.7263], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.40588881795568976\n",
      "train_precision: tensor([0.7952, 0.8653, 0.8482, 0.8179], device='cuda:0')\n",
      "train_recall: tensor([0.7910, 0.8838, 0.8356, 0.8082], device='cuda:0')\n",
      "val_loss: 0.48765929758146004\n",
      "val_precision: tensor([0.7675, 0.8439, 0.8148, 0.7528], device='cuda:0')\n",
      "val_recall: tensor([0.7460, 0.8606, 0.8234, 0.7364], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.40235097163474437\n",
      "train_precision: tensor([0.7947, 0.8663, 0.8498, 0.8249], device='cuda:0')\n",
      "train_recall: tensor([0.7921, 0.8827, 0.8369, 0.8208], device='cuda:0')\n",
      "val_loss: 0.4890090532198146\n",
      "val_precision: tensor([0.7616, 0.8503, 0.8103, 0.7875], device='cuda:0')\n",
      "val_recall: tensor([0.7538, 0.8525, 0.8256, 0.6987], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.4005885921386226\n",
      "train_precision: tensor([0.7960, 0.8671, 0.8512, 0.8236], device='cuda:0')\n",
      "train_recall: tensor([0.7928, 0.8841, 0.8389, 0.8143], device='cuda:0')\n",
      "val_loss: 0.49196542457148834\n",
      "val_precision: tensor([0.7602, 0.8514, 0.8082, 0.7802], device='cuda:0')\n",
      "val_recall: tensor([0.7535, 0.8480, 0.8266, 0.7017], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.39753088117164864\n",
      "train_precision: tensor([0.7970, 0.8667, 0.8509, 0.8286], device='cuda:0')\n",
      "train_recall: tensor([0.7936, 0.8835, 0.8386, 0.8238], device='cuda:0')\n",
      "val_loss: 0.49045300795822533\n",
      "val_precision: tensor([0.7629, 0.8431, 0.8169, 0.7667], device='cuda:0')\n",
      "val_recall: tensor([0.7503, 0.8594, 0.8190, 0.7259], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.39832457770283924\n",
      "train_precision: tensor([0.7963, 0.8669, 0.8521, 0.8262], device='cuda:0')\n",
      "train_recall: tensor([0.7943, 0.8831, 0.8387, 0.8219], device='cuda:0')\n",
      "val_loss: 0.4917226970397137\n",
      "val_precision: tensor([0.7724, 0.8457, 0.8007, 0.7831], device='cuda:0')\n",
      "val_recall: tensor([0.7325, 0.8573, 0.8386, 0.7098], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.39681566246016103\n",
      "train_precision: tensor([0.7969, 0.8686, 0.8498, 0.8268], device='cuda:0')\n",
      "train_recall: tensor([0.7943, 0.8841, 0.8376, 0.8247], device='cuda:0')\n",
      "val_loss: 0.4915202628519084\n",
      "val_precision: tensor([0.7657, 0.8398, 0.8168, 0.7884], device='cuda:0')\n",
      "val_recall: tensor([0.7504, 0.8645, 0.8189, 0.6936], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.39554682598923735\n",
      "train_precision: tensor([0.7990, 0.8688, 0.8522, 0.8283], device='cuda:0')\n",
      "train_recall: tensor([0.7956, 0.8854, 0.8398, 0.8263], device='cuda:0')\n",
      "val_loss: 0.4946051941731492\n",
      "val_precision: tensor([0.7642, 0.8412, 0.8163, 0.7703], device='cuda:0')\n",
      "val_recall: tensor([0.7489, 0.8619, 0.8183, 0.7172], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.394291792967842\n",
      "train_precision: tensor([0.7996, 0.8689, 0.8524, 0.8284], device='cuda:0')\n",
      "train_recall: tensor([0.7961, 0.8866, 0.8394, 0.8234], device='cuda:0')\n",
      "val_loss: 0.49195674041638504\n",
      "val_precision: tensor([0.7631, 0.8503, 0.8090, 0.7891], device='cuda:0')\n",
      "val_recall: tensor([0.7520, 0.8501, 0.8291, 0.7104], device='cuda:0')\n",
      "Learning rate: 0.00021304508400517774\n",
      "train_loss: 0.3922766838952661\n",
      "train_precision: tensor([0.8004, 0.8694, 0.8529, 0.8278], device='cuda:0')\n",
      "train_recall: tensor([0.7975, 0.8844, 0.8415, 0.8248], device='cuda:0')\n",
      "val_loss: 0.49411620743371343\n",
      "val_precision: tensor([0.7637, 0.8426, 0.8172, 0.7942], device='cuda:0')\n",
      "val_recall: tensor([0.7515, 0.8628, 0.8206, 0.6976], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "train_loss: 0.3871991290063401\n",
      "train_precision: tensor([0.8048, 0.8700, 0.8557, 0.8326], device='cuda:0')\n",
      "train_recall: tensor([0.7973, 0.8887, 0.8449, 0.8361], device='cuda:0')\n",
      "val_loss: 0.49236453717222084\n",
      "val_precision: tensor([0.7594, 0.8513, 0.8122, 0.7885], device='cuda:0')\n",
      "val_recall: tensor([0.7553, 0.8503, 0.8257, 0.7091], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "train_loss: 0.38651983511292193\n",
      "train_precision: tensor([0.8023, 0.8712, 0.8562, 0.8379], device='cuda:0')\n",
      "train_recall: tensor([0.8002, 0.8873, 0.8431, 0.8329], device='cuda:0')\n",
      "val_loss: 0.4944735945680657\n",
      "val_precision: tensor([0.7708, 0.8439, 0.8080, 0.7781], device='cuda:0')\n",
      "val_recall: tensor([0.7390, 0.8602, 0.8319, 0.7192], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "train_loss: 0.38587121031799926\n",
      "train_precision: tensor([0.8009, 0.8736, 0.8566, 0.8379], device='cuda:0')\n",
      "train_recall: tensor([0.8009, 0.8875, 0.8426, 0.8404], device='cuda:0')\n",
      "val_loss: 0.4933721270110156\n",
      "val_precision: tensor([0.7613, 0.8503, 0.8106, 0.7951], device='cuda:0')\n",
      "val_recall: tensor([0.7529, 0.8521, 0.8269, 0.7057], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "train_loss: 0.38419792281006865\n",
      "train_precision: tensor([0.8035, 0.8719, 0.8533, 0.8387], device='cuda:0')\n",
      "train_recall: tensor([0.7973, 0.8878, 0.8446, 0.8356], device='cuda:0')\n",
      "val_loss: 0.49336912785027476\n",
      "val_precision: tensor([0.7688, 0.8496, 0.8062, 0.7712], device='cuda:0')\n",
      "val_recall: tensor([0.7436, 0.8529, 0.8335, 0.7333], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "train_loss: 0.38386302329978333\n",
      "train_precision: tensor([0.8042, 0.8725, 0.8569, 0.8364], device='cuda:0')\n",
      "train_recall: tensor([0.8016, 0.8886, 0.8438, 0.8371], device='cuda:0')\n",
      "val_loss: 0.4938882183585618\n",
      "val_precision: tensor([0.7681, 0.8493, 0.8052, 0.7891], device='cuda:0')\n",
      "val_recall: tensor([0.7439, 0.8535, 0.8343, 0.7141], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "train_loss: 0.38433200860577155\n",
      "train_precision: tensor([0.8047, 0.8716, 0.8577, 0.8431], device='cuda:0')\n",
      "train_recall: tensor([0.8003, 0.8892, 0.8460, 0.8351], device='cuda:0')\n",
      "val_loss: 0.49500871419503883\n",
      "val_precision: tensor([0.7690, 0.8493, 0.8048, 0.7872], device='cuda:0')\n",
      "val_recall: tensor([0.7420, 0.8535, 0.8360, 0.7185], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "train_loss: 0.38504737057602806\n",
      "train_precision: tensor([0.8040, 0.8732, 0.8559, 0.8378], device='cuda:0')\n",
      "train_recall: tensor([0.8016, 0.8882, 0.8439, 0.8358], device='cuda:0')\n",
      "val_loss: 0.493949221698819\n",
      "val_precision: tensor([0.7667, 0.8491, 0.8070, 0.7833], device='cuda:0')\n",
      "val_recall: tensor([0.7452, 0.8534, 0.8326, 0.7158], device='cuda:0')\n",
      "Learning rate: 2.1304508400517775e-05\n",
      "Early stopping at epoch 94 with best validation loss 0.48765929758146004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_name = f'efficient_net_no_norm_no_pad{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "set_seed(2233)\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "        \n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate)\n",
    "my_model = my_model.to('cuda')\n",
    "early_stop_patience = 15\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(my_model.state_dict(), f\"{run_path}.pt\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d95ffee-8ed1-42d1-97f6-8d39b5e1b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[740  89 159  12]\n",
      " [ 77 875  45   3]\n",
      " [128  37 828   7]\n",
      " [  8   5   6  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.87      0.88      0.87      1000\n",
      "           2       0.80      0.83      0.81      1000\n",
      "           3       0.79      0.81      0.80       100\n",
      "\n",
      "    accuracy                           0.81      3100\n",
      "   macro avg       0.81      0.81      0.81      3100\n",
      "weighted avg       0.81      0.81      0.81      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data')\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
