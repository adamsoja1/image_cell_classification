{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3dc9e67-0431-40f2-b3bc-ce857f88bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 465\n",
    "learning_rate = 0.0098388848049504\n",
    "dropout_rate = 0.28932744984147474\n",
    "kernel_size = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5105a2-d608-456c-bd07-4fbca6a15b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        files = os.listdir(path)\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['filename'] = []\n",
    "        dataset_final['class'] = []\n",
    "        for filename in files:\n",
    "            dataset = pd.DataFrame()\n",
    "            if filename.endswith('.txt'):\n",
    "                files = get_images_list(f'{path}/{filename}')\n",
    "                dataset['filename'] = files\n",
    "                dataset['class'] = filename.split('_')[1][:-3]\n",
    "                dataset_final = pd.concat([dataset_final, dataset], ignore_index=True)\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"filename\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        #image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset[\"class\"].loc[idx]\n",
    "\n",
    "        if target == 'normal.':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target == 'inflamatory.':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target == 'tumor.':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target == 'other.':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "       \n",
    "     \n",
    "\n",
    "        \"\"\"To see transorms use:\n",
    "            image, target = trainset[15]\n",
    "            image = image.numpy()\n",
    "            image=np.swapaxes(image,0,1)\n",
    "            image=np.swapaxes(image,1,2)\n",
    "            plt.imshow(image)\"\"\"\n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c0dcac-1c09-4caf-b1ed-d357112031ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:2587: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2233)\n",
    "\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc76746-e31d-4264-86e1-0c4941c3208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23508548"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model setup\n",
    "model = resnet50()\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(kernel_size, kernel_size), stride=(1, 1), padding=(kernel_size // 2, kernel_size // 2), bias=False)\n",
    "num_classes = 4\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(model.fc.in_features, num_classes)\n",
    ")\n",
    "model = model.to('cuda')\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1220283-65c6-4476-a8e4-084f05a2f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240824_202214-r6i9xwul</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/r6i9xwul' target=\"_blank\">resnet50 final_no_norm_no_pad_final2024-08-24 20:22:13.223419</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/r6i9xwul' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/r6i9xwul</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.090859903143598\n",
      "train_precision: tensor([0.5075, 0.6435, 0.5901, 0.1406], device='cuda:0')\n",
      "train_recall: tensor([0.5007, 0.7340, 0.5734, 0.0013], device='cuda:0')\n",
      "val_loss: 1.816566498291613\n",
      "val_precision: tensor([0.6282, 0.6499, 0.5370, 0.2253], device='cuda:0')\n",
      "val_recall: tensor([0.2390, 0.8174, 0.7566, 0.1189], device='cuda:0')\n",
      "Learning rate: 0.0098388848049504\n",
      "train_loss: 0.904168513301131\n",
      "train_precision: tensor([0.5666, 0.6917, 0.6530, 0.5948], device='cuda:0')\n",
      "train_recall: tensor([0.5586, 0.7689, 0.6501, 0.0430], device='cuda:0')\n",
      "val_loss: 0.945518312430141\n",
      "val_precision: tensor([0.5844, 0.6909, 0.5177, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.3100, 0.7371, 0.7779, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.0098388848049504\n",
      "train_loss: 0.9446292047376756\n",
      "train_precision: tensor([0.5329, 0.6740, 0.6030, 0.3803], device='cuda:0')\n",
      "train_recall: tensor([0.5143, 0.7507, 0.6143, 0.0078], device='cuda:0')\n",
      "val_loss: 0.8722502026293013\n",
      "val_precision: tensor([0.6236, 0.7101, 0.5950, 0.8400], device='cuda:0')\n",
      "val_recall: tensor([0.4455, 0.7656, 0.7775, 0.0071], device='cuda:0')\n",
      "Learning rate: 0.0098388848049504\n",
      "train_loss: 0.8370070374889291\n",
      "train_precision: tensor([0.5868, 0.7027, 0.6705, 0.6000], device='cuda:0')\n",
      "train_recall: tensor([0.5784, 0.7752, 0.6695, 0.0758], device='cuda:0')\n",
      "val_loss: 1.5119678098896536\n",
      "val_precision: tensor([0.7101, 0.8766, 0.3766, 0.2616], device='cuda:0')\n",
      "val_recall: tensor([0.1561, 0.2515, 0.9456, 0.2158], device='cuda:0')\n",
      "Learning rate: 0.0098388848049504\n",
      "train_loss: 0.7997750330280948\n",
      "train_precision: tensor([0.6025, 0.7174, 0.6841, 0.6474], device='cuda:0')\n",
      "train_recall: tensor([0.5888, 0.7844, 0.6906, 0.1280], device='cuda:0')\n",
      "val_loss: 0.9997659470095779\n",
      "val_precision: tensor([0.5866, 0.8692, 0.5043, 0.4904], device='cuda:0')\n",
      "val_recall: tensor([0.3687, 0.5202, 0.9208, 0.2320], device='cuda:0')\n",
      "Learning rate: 0.0098388848049504\n",
      "train_loss: 0.7807462939194271\n",
      "train_precision: tensor([0.6132, 0.7268, 0.6881, 0.6301], device='cuda:0')\n",
      "train_recall: tensor([0.5928, 0.7927, 0.6979, 0.1782], device='cuda:0')\n",
      "val_loss: 1.2217229086943346\n",
      "val_precision: tensor([0.5457, 0.5871, 0.8217, 0.9292], device='cuda:0')\n",
      "val_recall: tensor([0.6614, 0.8720, 0.3189, 0.1370], device='cuda:0')\n",
      "Learning rate: 0.0098388848049504\n",
      "train_loss: 0.7494172282291182\n",
      "train_precision: tensor([0.6292, 0.7393, 0.6997, 0.6312], device='cuda:0')\n",
      "train_recall: tensor([0.6067, 0.7975, 0.7111, 0.2566], device='cuda:0')\n",
      "val_loss: 1.0152427922896665\n",
      "val_precision: tensor([0.6058, 0.8732, 0.4785, 0.4608], device='cuda:0')\n",
      "val_recall: tensor([0.3695, 0.4703, 0.9044, 0.2832], device='cuda:0')\n",
      "Learning rate: 0.0098388848049504\n",
      "train_loss: 0.7303043638730978\n",
      "train_precision: tensor([0.6393, 0.7473, 0.7062, 0.6443], device='cuda:0')\n",
      "train_recall: tensor([0.6156, 0.8018, 0.7186, 0.2993], device='cuda:0')\n",
      "val_loss: 0.990810527795493\n",
      "val_precision: tensor([0.6304, 0.8485, 0.4874, 0.2664], device='cuda:0')\n",
      "val_recall: tensor([0.3512, 0.5362, 0.8608, 0.3862], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6771004843763458\n",
      "train_precision: tensor([0.6665, 0.7656, 0.7277, 0.6686], device='cuda:0')\n",
      "train_recall: tensor([0.6378, 0.8170, 0.7410, 0.3854], device='cuda:0')\n",
      "val_loss: 0.6895126942733322\n",
      "val_precision: tensor([0.6826, 0.8176, 0.6552, 0.7201], device='cuda:0')\n",
      "val_recall: tensor([0.5812, 0.7500, 0.8368, 0.3889], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6621305528399232\n",
      "train_precision: tensor([0.6757, 0.7727, 0.7345, 0.6815], device='cuda:0')\n",
      "train_recall: tensor([0.6486, 0.8223, 0.7469, 0.4020], device='cuda:0')\n",
      "val_loss: 0.7233137974534372\n",
      "val_precision: tensor([0.6717, 0.8345, 0.6205, 0.7116], device='cuda:0')\n",
      "val_recall: tensor([0.5316, 0.7220, 0.8606, 0.4020], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6541366302347803\n",
      "train_precision: tensor([0.6767, 0.7745, 0.7367, 0.6873], device='cuda:0')\n",
      "train_recall: tensor([0.6493, 0.8232, 0.7488, 0.4206], device='cuda:0')\n",
      "val_loss: 0.6450480108309273\n",
      "val_precision: tensor([0.7137, 0.7619, 0.7234, 0.7184], device='cuda:0')\n",
      "val_recall: tensor([0.6019, 0.8469, 0.7860, 0.4209], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6474767738864535\n",
      "train_precision: tensor([0.6804, 0.7800, 0.7418, 0.6813], device='cuda:0')\n",
      "train_recall: tensor([0.6590, 0.8234, 0.7509, 0.4328], device='cuda:0')\n",
      "val_loss: 0.7814153845262046\n",
      "val_precision: tensor([0.6240, 0.6662, 0.8299, 0.7578], device='cuda:0')\n",
      "val_recall: tensor([0.6605, 0.8990, 0.5334, 0.3741], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.641175061593324\n",
      "train_precision: tensor([0.6822, 0.7805, 0.7465, 0.6939], device='cuda:0')\n",
      "train_recall: tensor([0.6623, 0.8245, 0.7526, 0.4488], device='cuda:0')\n",
      "val_loss: 0.758451155791379\n",
      "val_precision: tensor([0.6171, 0.8659, 0.6394, 0.6430], device='cuda:0')\n",
      "val_recall: tensor([0.6228, 0.6460, 0.8180, 0.4202], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6343904417572599\n",
      "train_precision: tensor([0.6847, 0.7846, 0.7481, 0.6920], device='cuda:0')\n",
      "train_recall: tensor([0.6671, 0.8261, 0.7525, 0.4631], device='cuda:0')\n",
      "val_loss: 0.6365780812321287\n",
      "val_precision: tensor([0.6915, 0.8279, 0.7036, 0.7521], device='cuda:0')\n",
      "val_recall: tensor([0.6444, 0.7736, 0.8254, 0.4556], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6262241728378065\n",
      "train_precision: tensor([0.6894, 0.7884, 0.7506, 0.7014], device='cuda:0')\n",
      "train_recall: tensor([0.6716, 0.8282, 0.7559, 0.4786], device='cuda:0')\n",
      "val_loss: 0.6160010356794704\n",
      "val_precision: tensor([0.6882, 0.7768, 0.7799, 0.7224], device='cuda:0')\n",
      "val_recall: tensor([0.6875, 0.8474, 0.7332, 0.5047], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6196814949636336\n",
      "train_precision: tensor([0.6909, 0.7913, 0.7547, 0.6878], device='cuda:0')\n",
      "train_recall: tensor([0.6749, 0.8292, 0.7579, 0.4867], device='cuda:0')\n",
      "val_loss: 0.6324057460132272\n",
      "val_precision: tensor([0.7001, 0.8020, 0.7186, 0.8045], device='cuda:0')\n",
      "val_recall: tensor([0.6270, 0.8182, 0.8124, 0.4323], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6132589382526679\n",
      "train_precision: tensor([0.6959, 0.7934, 0.7574, 0.6952], device='cuda:0')\n",
      "train_recall: tensor([0.6785, 0.8318, 0.7604, 0.5042], device='cuda:0')\n",
      "val_loss: 0.6432316343892704\n",
      "val_precision: tensor([0.6787, 0.8552, 0.6847, 0.7807], device='cuda:0')\n",
      "val_recall: tensor([0.6525, 0.7412, 0.8339, 0.4219], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.6057637906693792\n",
      "train_precision: tensor([0.6981, 0.7966, 0.7607, 0.7082], device='cuda:0')\n",
      "train_recall: tensor([0.6833, 0.8330, 0.7622, 0.5203], device='cuda:0')\n",
      "val_loss: 0.6165263588079298\n",
      "val_precision: tensor([0.7264, 0.7866, 0.7265, 0.7710], device='cuda:0')\n",
      "val_recall: tensor([0.6129, 0.8492, 0.8099, 0.4785], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.5987084374412314\n",
      "train_precision: tensor([0.7013, 0.7995, 0.7608, 0.7046], device='cuda:0')\n",
      "train_recall: tensor([0.6866, 0.8328, 0.7644, 0.5263], device='cuda:0')\n",
      "val_loss: 0.6931907278720779\n",
      "val_precision: tensor([0.6601, 0.8088, 0.7076, 0.6965], device='cuda:0')\n",
      "val_recall: tensor([0.6487, 0.7975, 0.7563, 0.4343], device='cuda:0')\n",
      "Learning rate: 0.00098388848049504\n",
      "train_loss: 0.5931506607181583\n",
      "train_precision: tensor([0.7054, 0.8008, 0.7658, 0.7105], device='cuda:0')\n",
      "train_recall: tensor([0.6905, 0.8352, 0.7678, 0.5375], device='cuda:0')\n",
      "val_loss: 0.631556996793458\n",
      "val_precision: tensor([0.6938, 0.8285, 0.7082, 0.6455], device='cuda:0')\n",
      "val_recall: tensor([0.6415, 0.7769, 0.8212, 0.5034], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5668417450798539\n",
      "train_precision: tensor([0.7172, 0.8094, 0.7769, 0.7257], device='cuda:0')\n",
      "train_recall: tensor([0.7030, 0.8437, 0.7754, 0.5758], device='cuda:0')\n",
      "val_loss: 0.5937162106386339\n",
      "val_precision: tensor([0.7238, 0.8440, 0.7165, 0.7039], device='cuda:0')\n",
      "val_recall: tensor([0.6539, 0.7898, 0.8457, 0.5667], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5603673033642046\n",
      "train_precision: tensor([0.7200, 0.8133, 0.7794, 0.7282], device='cuda:0')\n",
      "train_recall: tensor([0.7075, 0.8435, 0.7792, 0.5861], device='cuda:0')\n",
      "val_loss: 0.5724898040896714\n",
      "val_precision: tensor([0.7345, 0.8182, 0.7510, 0.7217], device='cuda:0')\n",
      "val_recall: tensor([0.6727, 0.8321, 0.8168, 0.5737], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5576483234440609\n",
      "train_precision: tensor([0.7215, 0.8138, 0.7804, 0.7294], device='cuda:0')\n",
      "train_recall: tensor([0.7074, 0.8446, 0.7808, 0.5919], device='cuda:0')\n",
      "val_loss: 0.5687891712995491\n",
      "val_precision: tensor([0.7249, 0.8061, 0.7714, 0.7412], device='cuda:0')\n",
      "val_recall: tensor([0.6907, 0.8442, 0.7899, 0.5623], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5546387148883952\n",
      "train_precision: tensor([0.7230, 0.8160, 0.7835, 0.7341], device='cuda:0')\n",
      "train_recall: tensor([0.7124, 0.8452, 0.7810, 0.6030], device='cuda:0')\n",
      "val_loss: 0.5677628998804574\n",
      "val_precision: tensor([0.7367, 0.8076, 0.7622, 0.7236], device='cuda:0')\n",
      "val_recall: tensor([0.6715, 0.8479, 0.8075, 0.5731], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5519375241809077\n",
      "train_precision: tensor([0.7247, 0.8171, 0.7821, 0.7318], device='cuda:0')\n",
      "train_recall: tensor([0.7117, 0.8464, 0.7813, 0.6084], device='cuda:0')\n",
      "val_loss: 0.5652248854890014\n",
      "val_precision: tensor([0.7324, 0.8206, 0.7586, 0.7203], device='cuda:0')\n",
      "val_recall: tensor([0.6829, 0.8351, 0.8109, 0.5828], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5486704178831794\n",
      "train_precision: tensor([0.7261, 0.8177, 0.7852, 0.7268], device='cuda:0')\n",
      "train_recall: tensor([0.7150, 0.8470, 0.7821, 0.6068], device='cuda:0')\n",
      "val_loss: 0.570462113980091\n",
      "val_precision: tensor([0.7246, 0.8334, 0.7459, 0.7404], device='cuda:0')\n",
      "val_recall: tensor([0.6828, 0.8134, 0.8235, 0.5751], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.546619883218369\n",
      "train_precision: tensor([0.7267, 0.8202, 0.7852, 0.7292], device='cuda:0')\n",
      "train_recall: tensor([0.7158, 0.8477, 0.7829, 0.6150], device='cuda:0')\n",
      "val_loss: 0.5642781271175905\n",
      "val_precision: tensor([0.7253, 0.8120, 0.7738, 0.7607], device='cuda:0')\n",
      "val_recall: tensor([0.6981, 0.8436, 0.7939, 0.5512], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5447575442847752\n",
      "train_precision: tensor([0.7274, 0.8193, 0.7873, 0.7407], device='cuda:0')\n",
      "train_recall: tensor([0.7176, 0.8486, 0.7831, 0.6147], device='cuda:0')\n",
      "val_loss: 0.5774078316459752\n",
      "val_precision: tensor([0.7282, 0.8430, 0.7330, 0.7202], device='cuda:0')\n",
      "val_recall: tensor([0.6776, 0.8004, 0.8356, 0.5764], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5414175235089802\n",
      "train_precision: tensor([0.7277, 0.8195, 0.7860, 0.7320], device='cuda:0')\n",
      "train_recall: tensor([0.7156, 0.8483, 0.7835, 0.6193], device='cuda:0')\n",
      "val_loss: 0.5728926441886208\n",
      "val_precision: tensor([0.7295, 0.8350, 0.7397, 0.7272], device='cuda:0')\n",
      "val_recall: tensor([0.6734, 0.8163, 0.8276, 0.5842], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5410184092593916\n",
      "train_precision: tensor([0.7312, 0.8215, 0.7893, 0.7379], device='cuda:0')\n",
      "train_recall: tensor([0.7226, 0.8494, 0.7841, 0.6228], device='cuda:0')\n",
      "val_loss: 0.5711155711400389\n",
      "val_precision: tensor([0.7281, 0.8379, 0.7419, 0.7196], device='cuda:0')\n",
      "val_recall: tensor([0.6841, 0.8092, 0.8261, 0.5848], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5379971100009365\n",
      "train_precision: tensor([0.7299, 0.8215, 0.7878, 0.7459], device='cuda:0')\n",
      "train_recall: tensor([0.7190, 0.8488, 0.7860, 0.6253], device='cuda:0')\n",
      "val_loss: 0.5600619472638525\n",
      "val_precision: tensor([0.7268, 0.8084, 0.7827, 0.7497], device='cuda:0')\n",
      "val_recall: tensor([0.7027, 0.8510, 0.7859, 0.5737], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5363255930153322\n",
      "train_precision: tensor([0.7302, 0.8216, 0.7896, 0.7466], device='cuda:0')\n",
      "train_recall: tensor([0.7211, 0.8482, 0.7859, 0.6326], device='cuda:0')\n",
      "val_loss: 0.5586030650319476\n",
      "val_precision: tensor([0.7251, 0.8195, 0.7774, 0.7177], device='cuda:0')\n",
      "val_recall: tensor([0.7063, 0.8390, 0.7924, 0.5949], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5353530111250939\n",
      "train_precision: tensor([0.7332, 0.8222, 0.7899, 0.7399], device='cuda:0')\n",
      "train_recall: tensor([0.7218, 0.8507, 0.7868, 0.6277], device='cuda:0')\n",
      "val_loss: 0.558259436277428\n",
      "val_precision: tensor([0.7258, 0.8135, 0.7827, 0.7497], device='cuda:0')\n",
      "val_recall: tensor([0.7079, 0.8478, 0.7868, 0.5778], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5314410384986308\n",
      "train_precision: tensor([0.7342, 0.8244, 0.7925, 0.7465], device='cuda:0')\n",
      "train_recall: tensor([0.7247, 0.8515, 0.7881, 0.6384], device='cuda:0')\n",
      "val_loss: 0.5596254243694171\n",
      "val_precision: tensor([0.7264, 0.8253, 0.7699, 0.7179], device='cuda:0')\n",
      "val_recall: tensor([0.7021, 0.8326, 0.8007, 0.6067], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5291148898921487\n",
      "train_precision: tensor([0.7337, 0.8257, 0.7912, 0.7468], device='cuda:0')\n",
      "train_recall: tensor([0.7255, 0.8509, 0.7874, 0.6391], device='cuda:0')\n",
      "val_loss: 0.5598262691437595\n",
      "val_precision: tensor([0.7177, 0.8092, 0.7899, 0.7570], device='cuda:0')\n",
      "val_recall: tensor([0.7167, 0.8484, 0.7720, 0.5737], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5273552965292166\n",
      "train_precision: tensor([0.7365, 0.8255, 0.7928, 0.7444], device='cuda:0')\n",
      "train_recall: tensor([0.7254, 0.8526, 0.7901, 0.6372], device='cuda:0')\n",
      "val_loss: 0.5578387959135903\n",
      "val_precision: tensor([0.7319, 0.8296, 0.7625, 0.7384], device='cuda:0')\n",
      "val_recall: tensor([0.6959, 0.8310, 0.8131, 0.5976], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5256746624197278\n",
      "train_precision: tensor([0.7365, 0.8263, 0.7933, 0.7497], device='cuda:0')\n",
      "train_recall: tensor([0.7261, 0.8530, 0.7901, 0.6443], device='cuda:0')\n",
      "val_loss: 0.5560753711245277\n",
      "val_precision: tensor([0.7304, 0.8147, 0.7784, 0.7508], device='cuda:0')\n",
      "val_recall: tensor([0.7022, 0.8461, 0.7957, 0.5852], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.521994668877486\n",
      "train_precision: tensor([0.7397, 0.8274, 0.7950, 0.7495], device='cuda:0')\n",
      "train_recall: tensor([0.7296, 0.8535, 0.7914, 0.6485], device='cuda:0')\n",
      "val_loss: 0.561776080366337\n",
      "val_precision: tensor([0.7300, 0.8312, 0.7582, 0.7339], device='cuda:0')\n",
      "val_recall: tensor([0.6949, 0.8242, 0.8159, 0.5896], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5211462206912764\n",
      "train_precision: tensor([0.7384, 0.8278, 0.7960, 0.7481], device='cuda:0')\n",
      "train_recall: tensor([0.7296, 0.8543, 0.7908, 0.6476], device='cuda:0')\n",
      "val_loss: 0.5521173311604394\n",
      "val_precision: tensor([0.7217, 0.8170, 0.7883, 0.7442], device='cuda:0')\n",
      "val_recall: tensor([0.7187, 0.8457, 0.7802, 0.5906], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5191715721573148\n",
      "train_precision: tensor([0.7405, 0.8292, 0.7971, 0.7581], device='cuda:0')\n",
      "train_recall: tensor([0.7331, 0.8549, 0.7912, 0.6550], device='cuda:0')\n",
      "val_loss: 0.5752154149190344\n",
      "val_precision: tensor([0.7232, 0.8484, 0.7357, 0.7061], device='cuda:0')\n",
      "val_recall: tensor([0.6800, 0.7970, 0.8346, 0.6067], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5178342471907149\n",
      "train_precision: tensor([0.7410, 0.8301, 0.7962, 0.7469], device='cuda:0')\n",
      "train_recall: tensor([0.7315, 0.8548, 0.7927, 0.6534], device='cuda:0')\n",
      "val_loss: 0.5571548569985111\n",
      "val_precision: tensor([0.7272, 0.8117, 0.7813, 0.7426], device='cuda:0')\n",
      "val_recall: tensor([0.7051, 0.8467, 0.7876, 0.5896], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5144224706150237\n",
      "train_precision: tensor([0.7434, 0.8304, 0.7990, 0.7537], device='cuda:0')\n",
      "train_recall: tensor([0.7327, 0.8577, 0.7937, 0.6645], device='cuda:0')\n",
      "val_loss: 0.5723841711126193\n",
      "val_precision: tensor([0.7304, 0.8517, 0.7315, 0.7351], device='cuda:0')\n",
      "val_recall: tensor([0.6820, 0.7978, 0.8411, 0.5859], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5107686147416309\n",
      "train_precision: tensor([0.7432, 0.8332, 0.7996, 0.7624], device='cuda:0')\n",
      "train_recall: tensor([0.7365, 0.8576, 0.7936, 0.6658], device='cuda:0')\n",
      "val_loss: 0.5544665875759992\n",
      "val_precision: tensor([0.7346, 0.8150, 0.7787, 0.7206], device='cuda:0')\n",
      "val_recall: tensor([0.6999, 0.8472, 0.7958, 0.6182], device='cuda:0')\n",
      "Learning rate: 9.838884804950401e-05\n",
      "train_loss: 0.5082697714820053\n",
      "train_precision: tensor([0.7469, 0.8332, 0.8022, 0.7552], device='cuda:0')\n",
      "train_recall: tensor([0.7377, 0.8590, 0.7964, 0.6697], device='cuda:0')\n",
      "val_loss: 0.5579279882438255\n",
      "val_precision: tensor([0.7379, 0.8327, 0.7569, 0.7169], device='cuda:0')\n",
      "val_recall: tensor([0.6860, 0.8277, 0.8244, 0.6242], device='cuda:0')\n",
      "Learning rate: 9.838884804950402e-06\n",
      "train_loss: 0.5032999598102652\n",
      "train_precision: tensor([0.7474, 0.8364, 0.7990, 0.7546], device='cuda:0')\n",
      "train_recall: tensor([0.7366, 0.8572, 0.7985, 0.6797], device='cuda:0')\n",
      "val_loss: 0.5524237863343171\n",
      "val_precision: tensor([0.7364, 0.8257, 0.7673, 0.7526], device='cuda:0')\n",
      "val_recall: tensor([0.6953, 0.8388, 0.8141, 0.5939], device='cuda:0')\n",
      "Learning rate: 9.838884804950402e-06\n",
      "train_loss: 0.5002075550489096\n",
      "train_precision: tensor([0.7486, 0.8357, 0.8035, 0.7591], device='cuda:0')\n",
      "train_recall: tensor([0.7401, 0.8610, 0.7969, 0.6776], device='cuda:0')\n",
      "val_loss: 0.5530130107595463\n",
      "val_precision: tensor([0.7337, 0.8253, 0.7731, 0.7323], device='cuda:0')\n",
      "val_recall: tensor([0.7037, 0.8373, 0.8060, 0.6145], device='cuda:0')\n",
      "Learning rate: 9.838884804950402e-06\n",
      "train_loss: 0.500747092810028\n",
      "train_precision: tensor([0.7477, 0.8360, 0.8025, 0.7656], device='cuda:0')\n",
      "train_recall: tensor([0.7397, 0.8602, 0.7966, 0.6830], device='cuda:0')\n",
      "val_loss: 0.5523476490769723\n",
      "val_precision: tensor([0.7362, 0.8250, 0.7722, 0.7380], device='cuda:0')\n",
      "val_recall: tensor([0.7012, 0.8402, 0.8080, 0.6098], device='cuda:0')\n",
      "Learning rate: 9.838884804950402e-06\n",
      "train_loss: 0.5005105949970551\n",
      "train_precision: tensor([0.7500, 0.8358, 0.8035, 0.7667], device='cuda:0')\n",
      "train_recall: tensor([0.7404, 0.8612, 0.7985, 0.6797], device='cuda:0')\n",
      "val_loss: 0.5524381007811036\n",
      "val_precision: tensor([0.7341, 0.8311, 0.7675, 0.7367], device='cuda:0')\n",
      "val_recall: tensor([0.7022, 0.8323, 0.8126, 0.6131], device='cuda:0')\n",
      "Learning rate: 9.838884804950402e-06\n",
      "train_loss: 0.5001338617110149\n",
      "train_precision: tensor([0.7504, 0.8356, 0.8037, 0.7677], device='cuda:0')\n",
      "train_recall: tensor([0.7409, 0.8612, 0.7983, 0.6818], device='cuda:0')\n",
      "val_loss: 0.5529243616443692\n",
      "val_precision: tensor([0.7316, 0.8305, 0.7703, 0.7340], device='cuda:0')\n",
      "val_recall: tensor([0.7055, 0.8328, 0.8088, 0.6094], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.497825232870651\n",
      "train_precision: tensor([0.7507, 0.8367, 0.8071, 0.7618], device='cuda:0')\n",
      "train_recall: tensor([0.7447, 0.8616, 0.7974, 0.6872], device='cuda:0')\n",
      "val_loss: 0.5515067730889176\n",
      "val_precision: tensor([0.7305, 0.8283, 0.7761, 0.7410], device='cuda:0')\n",
      "val_recall: tensor([0.7111, 0.8356, 0.8032, 0.6128], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.4999539355436961\n",
      "train_precision: tensor([0.7513, 0.8361, 0.8029, 0.7608], device='cuda:0')\n",
      "train_recall: tensor([0.7415, 0.8608, 0.7980, 0.6811], device='cuda:0')\n",
      "val_loss: 0.5535357704367301\n",
      "val_precision: tensor([0.7366, 0.8286, 0.7677, 0.7376], device='cuda:0')\n",
      "val_recall: tensor([0.6997, 0.8352, 0.8134, 0.6094], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.49824511030793706\n",
      "train_precision: tensor([0.7495, 0.8354, 0.8056, 0.7561], device='cuda:0')\n",
      "train_recall: tensor([0.7416, 0.8597, 0.7983, 0.6838], device='cuda:0')\n",
      "val_loss: 0.5515435270287774\n",
      "val_precision: tensor([0.7332, 0.8267, 0.7755, 0.7313], device='cuda:0')\n",
      "val_recall: tensor([0.7067, 0.8378, 0.8050, 0.6195], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.49814723186936727\n",
      "train_precision: tensor([0.7515, 0.8374, 0.8036, 0.7591], device='cuda:0')\n",
      "train_recall: tensor([0.7406, 0.8622, 0.7998, 0.6797], device='cuda:0')\n",
      "val_loss: 0.552967297759923\n",
      "val_precision: tensor([0.7271, 0.8311, 0.7755, 0.7435], device='cuda:0')\n",
      "val_recall: tensor([0.7145, 0.8320, 0.8025, 0.6061], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.49738028464895306\n",
      "train_precision: tensor([0.7508, 0.8374, 0.8040, 0.7591], device='cuda:0')\n",
      "train_recall: tensor([0.7406, 0.8620, 0.7992, 0.6838], device='cuda:0')\n",
      "val_loss: 0.5516450474358569\n",
      "val_precision: tensor([0.7351, 0.8287, 0.7700, 0.7349], device='cuda:0')\n",
      "val_recall: tensor([0.7016, 0.8360, 0.8108, 0.6152], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.49757761866241307\n",
      "train_precision: tensor([0.7512, 0.8361, 0.8061, 0.7603], device='cuda:0')\n",
      "train_recall: tensor([0.7418, 0.8629, 0.7986, 0.6828], device='cuda:0')\n",
      "val_loss: 0.5523414039852643\n",
      "val_precision: tensor([0.7339, 0.8258, 0.7735, 0.7361], device='cuda:0')\n",
      "val_recall: tensor([0.7042, 0.8387, 0.8055, 0.6141], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.49741131763953667\n",
      "train_precision: tensor([0.7492, 0.8363, 0.8033, 0.7663], device='cuda:0')\n",
      "train_recall: tensor([0.7407, 0.8616, 0.7967, 0.6846], device='cuda:0')\n",
      "val_loss: 0.5542472513637158\n",
      "val_precision: tensor([0.7339, 0.8324, 0.7656, 0.7356], device='cuda:0')\n",
      "val_recall: tensor([0.7016, 0.8302, 0.8139, 0.6155], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.4972155448291209\n",
      "train_precision: tensor([0.7505, 0.8366, 0.8049, 0.7643], device='cuda:0')\n",
      "train_recall: tensor([0.7416, 0.8608, 0.8001, 0.6807], device='cuda:0')\n",
      "val_loss: 0.550958739085631\n",
      "val_precision: tensor([0.7365, 0.8206, 0.7776, 0.7302], device='cuda:0')\n",
      "val_recall: tensor([0.7019, 0.8444, 0.8032, 0.6215], device='cuda:0')\n",
      "Learning rate: 5e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_name = f'resnet50 final_no_norm_no_pad_final{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "set_seed(2233)\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=4, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "        \n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "set_seed(2233)\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate)\n",
    "my_model = my_model.to('cuda')\n",
    "early_stop_patience = 15\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(my_model.state_dict(), f\"{run_path}.pt\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed3b8e-94f7-4113-a37c-486e41c4e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data', transform=transform_test, reduce=True)\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
