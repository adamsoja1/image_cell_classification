{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4942a50-4bb7-4e24-9f15-35fcddd3415c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5xlzty7m) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vit_normalize2024-04-24 16:13:09.041926</strong> at: <a href='https://wandb.ai/adamsoja/cells/runs/5xlzty7m' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/5xlzty7m</a><br/> View project at: <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240424_161310-5xlzty7m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5xlzty7m). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240424_161459-b9wgtwvc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/b9wgtwvc' target=\"_blank\">vit_normalize2024-04-24 16:14:59.984991</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/b9wgtwvc' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/b9wgtwvc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.9406822317412922\n",
      "train_precision: tensor([0.5391, 0.6158, 0.6138, 0.6140], device='cuda:0')\n",
      "train_recall: tensor([0.4669, 0.7659, 0.6063, 0.0152], device='cuda:0')\n",
      "val_loss: 0.8241679271890058\n",
      "val_precision: tensor([0.6271, 0.7019, 0.6405, 0.5725], device='cuda:0')\n",
      "val_recall: tensor([0.4810, 0.7957, 0.7530, 0.1343], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  1.7802085266999996\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.8464674494096212\n",
      "train_precision: tensor([0.5789, 0.6816, 0.6682, 0.5748], device='cuda:0')\n",
      "train_recall: tensor([0.5568, 0.7725, 0.6608, 0.0915], device='cuda:0')\n",
      "val_loss: 0.7929320111870766\n",
      "val_precision: tensor([0.6245, 0.7587, 0.6471, 0.6459], device='cuda:0')\n",
      "val_recall: tensor([0.5250, 0.7615, 0.7814, 0.3108], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  1.4376506366166666\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.820299957763581\n",
      "train_precision: tensor([0.5935, 0.6952, 0.6750, 0.5776], device='cuda:0')\n",
      "train_recall: tensor([0.5706, 0.7775, 0.6688, 0.1691], device='cuda:0')\n",
      "val_loss: 0.7458917386829853\n",
      "val_precision: tensor([0.6544, 0.7527, 0.6959, 0.5946], device='cuda:0')\n",
      "val_recall: tensor([0.5859, 0.7964, 0.7547, 0.3694], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  1.4385563531000003\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.7992280694700423\n",
      "train_precision: tensor([0.6038, 0.7059, 0.6836, 0.5599], device='cuda:0')\n",
      "train_recall: tensor([0.5819, 0.7799, 0.6802, 0.2043], device='cuda:0')\n",
      "val_loss: 0.7554072769151794\n",
      "val_precision: tensor([0.6430, 0.7640, 0.7089, 0.5425], device='cuda:0')\n",
      "val_recall: tensor([0.6197, 0.7833, 0.7436, 0.3377], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  1.4374299022666681\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.7864117190241814\n",
      "train_precision: tensor([0.6145, 0.7107, 0.6870, 0.5854], device='cuda:0')\n",
      "train_recall: tensor([0.5870, 0.7826, 0.6890, 0.2380], device='cuda:0')\n",
      "val_loss: 0.7288014724850654\n",
      "val_precision: tensor([0.6355, 0.7520, 0.7338, 0.6970], device='cuda:0')\n",
      "val_recall: tensor([0.6458, 0.8118, 0.7027, 0.3246], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  1.4341113957999994\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.7761792430565471\n",
      "train_precision: tensor([0.6209, 0.7141, 0.6906, 0.5969], device='cuda:0')\n",
      "train_recall: tensor([0.5914, 0.7868, 0.6937, 0.2468], device='cuda:0')\n",
      "val_loss: 0.7537905756798056\n",
      "val_precision: tensor([0.6367, 0.7645, 0.7062, 0.6743], device='cuda:0')\n",
      "val_recall: tensor([0.6073, 0.7901, 0.7483, 0.3569], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  1.433699810566668\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.7661046544001215\n",
      "train_precision: tensor([0.6274, 0.7197, 0.6940, 0.5974], device='cuda:0')\n",
      "train_recall: tensor([0.5983, 0.7896, 0.6977, 0.2628], device='cuda:0')\n",
      "val_loss: 0.7437254066268603\n",
      "val_precision: tensor([0.6568, 0.7790, 0.6944, 0.6552], device='cuda:0')\n",
      "val_recall: tensor([0.6107, 0.7858, 0.7637, 0.4037], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  1.4328535073166677\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.75704480246419\n",
      "train_precision: tensor([0.6313, 0.7232, 0.6993, 0.6080], device='cuda:0')\n",
      "train_recall: tensor([0.6039, 0.7904, 0.7030, 0.2750], device='cuda:0')\n",
      "val_loss: 0.7223603371944692\n",
      "val_precision: tensor([0.6519, 0.7709, 0.7340, 0.6265], device='cuda:0')\n",
      "val_recall: tensor([0.6511, 0.7979, 0.7429, 0.3377], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  1.4337775994166653\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.7495221563038372\n",
      "train_precision: tensor([0.6337, 0.7267, 0.7021, 0.6069], device='cuda:0')\n",
      "train_recall: tensor([0.6077, 0.7930, 0.7037, 0.2889], device='cuda:0')\n",
      "val_loss: 0.7125991370115016\n",
      "val_precision: tensor([0.6587, 0.7285, 0.7640, 0.7580], device='cuda:0')\n",
      "val_recall: tensor([0.6498, 0.8419, 0.6947, 0.3670], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  1.433533568216664\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.7410989487455004\n",
      "train_precision: tensor([0.6389, 0.7285, 0.7066, 0.6143], device='cuda:0')\n",
      "train_recall: tensor([0.6106, 0.7957, 0.7086, 0.3017], device='cuda:0')\n",
      "val_loss: 0.7179168528152837\n",
      "val_precision: tensor([0.6786, 0.7543, 0.7375, 0.7361], device='cuda:0')\n",
      "val_recall: tensor([0.6368, 0.8281, 0.7444, 0.4010], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  1.4333420847333362\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.7366467309849603\n",
      "train_precision: tensor([0.6440, 0.7319, 0.7063, 0.6141], device='cuda:0')\n",
      "train_recall: tensor([0.6144, 0.7963, 0.7123, 0.3038], device='cuda:0')\n",
      "val_loss: 0.7156830454038249\n",
      "val_precision: tensor([0.6922, 0.7764, 0.7135, 0.6898], device='cuda:0')\n",
      "val_recall: tensor([0.6127, 0.8182, 0.7878, 0.3923], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  1.433584069533333\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.7286185105641683\n",
      "train_precision: tensor([0.6462, 0.7344, 0.7097, 0.6380], device='cuda:0')\n",
      "train_recall: tensor([0.6174, 0.7978, 0.7139, 0.3322], device='cuda:0')\n",
      "val_loss: 0.7785176580978764\n",
      "val_precision: tensor([0.7400, 0.6928, 0.7313, 0.7936], device='cuda:0')\n",
      "val_recall: tensor([0.5359, 0.8947, 0.7686, 0.2653], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 11 time:  1.4339087986833305\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.6983887306991078\n",
      "train_precision: tensor([0.6643, 0.7470, 0.7227, 0.6724], device='cuda:0')\n",
      "train_recall: tensor([0.6352, 0.8077, 0.7299, 0.3531], device='cuda:0')\n",
      "val_loss: 0.688132716053062\n",
      "val_precision: tensor([0.7129, 0.7717, 0.7341, 0.6903], device='cuda:0')\n",
      "val_recall: tensor([0.6277, 0.8373, 0.7878, 0.4232], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 12 time:  1.4337014634833356\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.6899042774524008\n",
      "train_precision: tensor([0.6687, 0.7524, 0.7235, 0.6647], device='cuda:0')\n",
      "train_recall: tensor([0.6384, 0.8095, 0.7323, 0.3811], device='cuda:0')\n",
      "val_loss: 0.686208521326383\n",
      "val_precision: tensor([0.7145, 0.7658, 0.7406, 0.6959], device='cuda:0')\n",
      "val_recall: tensor([0.6281, 0.8443, 0.7805, 0.4492], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 13 time:  1.4335030987166684\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.688317127100059\n",
      "train_precision: tensor([0.6683, 0.7525, 0.7242, 0.6571], device='cuda:0')\n",
      "train_recall: tensor([0.6382, 0.8088, 0.7321, 0.3890], device='cuda:0')\n",
      "val_loss: 0.6840434259838528\n",
      "val_precision: tensor([0.7189, 0.7591, 0.7453, 0.7008], device='cuda:0')\n",
      "val_recall: tensor([0.6237, 0.8543, 0.7772, 0.4495], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 14 time:  1.4331134509499974\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.6863335232649531\n",
      "train_precision: tensor([0.6695, 0.7530, 0.7256, 0.6692], device='cuda:0')\n",
      "train_recall: tensor([0.6406, 0.8081, 0.7328, 0.4029], device='cuda:0')\n",
      "val_loss: 0.67860185843375\n",
      "val_precision: tensor([0.7132, 0.7716, 0.7416, 0.7067], device='cuda:0')\n",
      "val_recall: tensor([0.6364, 0.8409, 0.7834, 0.4340], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 15 time:  1.434568122733333\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.6842042704423269\n",
      "train_precision: tensor([0.6714, 0.7542, 0.7261, 0.6610], device='cuda:0')\n",
      "train_recall: tensor([0.6413, 0.8113, 0.7328, 0.3945], device='cuda:0')\n",
      "val_loss: 0.6815481359759966\n",
      "val_precision: tensor([0.7223, 0.7613, 0.7451, 0.7017], device='cuda:0')\n",
      "val_recall: tensor([0.6266, 0.8533, 0.7822, 0.4340], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 16 time:  1.4335592150333316\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.6823267733766919\n",
      "train_precision: tensor([0.6721, 0.7540, 0.7275, 0.6718], device='cuda:0')\n",
      "train_recall: tensor([0.6430, 0.8098, 0.7344, 0.4014], device='cuda:0')\n",
      "val_loss: 0.6735233893824948\n",
      "val_precision: tensor([0.7141, 0.7684, 0.7461, 0.7018], device='cuda:0')\n",
      "val_recall: tensor([0.6375, 0.8426, 0.7809, 0.4502], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 17 time:  1.4337848309666659\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.6827798721336183\n",
      "train_precision: tensor([0.6722, 0.7548, 0.7274, 0.6477], device='cuda:0')\n",
      "train_recall: tensor([0.6427, 0.8106, 0.7345, 0.3895], device='cuda:0')\n",
      "val_loss: 0.6744144178099103\n",
      "val_precision: tensor([0.7055, 0.7624, 0.7606, 0.6881], device='cuda:0')\n",
      "val_recall: tensor([0.6523, 0.8451, 0.7610, 0.4569], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 18 time:  1.4338421555333336\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.6789777957967349\n",
      "train_precision: tensor([0.6740, 0.7565, 0.7295, 0.6732], device='cuda:0')\n",
      "train_recall: tensor([0.6469, 0.8104, 0.7359, 0.4045], device='cuda:0')\n",
      "val_loss: 0.6763978174991078\n",
      "val_precision: tensor([0.7085, 0.7682, 0.7545, 0.6852], device='cuda:0')\n",
      "val_recall: tensor([0.6498, 0.8444, 0.7679, 0.4515], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 19 time:  1.4338195739666655\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.6781806766986846\n",
      "train_precision: tensor([0.6732, 0.7573, 0.7298, 0.6644], device='cuda:0')\n",
      "train_recall: tensor([0.6464, 0.8110, 0.7348, 0.4120], device='cuda:0')\n",
      "val_loss: 0.676921274430222\n",
      "val_precision: tensor([0.7177, 0.7604, 0.7540, 0.6987], device='cuda:0')\n",
      "val_recall: tensor([0.6401, 0.8523, 0.7722, 0.4411], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 20 time:  1.433724776149999\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.6772651069930622\n",
      "train_precision: tensor([0.6765, 0.7570, 0.7285, 0.6673], device='cuda:0')\n",
      "train_recall: tensor([0.6460, 0.8116, 0.7382, 0.3980], device='cuda:0')\n",
      "val_loss: 0.6755264680418703\n",
      "val_precision: tensor([0.7156, 0.7645, 0.7512, 0.6914], device='cuda:0')\n",
      "val_recall: tensor([0.6392, 0.8484, 0.7746, 0.4549], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 21 time:  1.4339505861333388\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.6766205767790476\n",
      "train_precision: tensor([0.6766, 0.7558, 0.7310, 0.6726], device='cuda:0')\n",
      "train_recall: tensor([0.6480, 0.8110, 0.7378, 0.4032], device='cuda:0')\n",
      "val_loss: 0.6760854087769985\n",
      "val_precision: tensor([0.7138, 0.7641, 0.7546, 0.6909], device='cuda:0')\n",
      "val_recall: tensor([0.6434, 0.8490, 0.7708, 0.4552], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 22 time:  1.4335873031666704\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.6767807172877448\n",
      "train_precision: tensor([0.6736, 0.7574, 0.7294, 0.6623], device='cuda:0')\n",
      "train_recall: tensor([0.6462, 0.8104, 0.7368, 0.4013], device='cuda:0')\n",
      "val_loss: 0.6742674344115787\n",
      "val_precision: tensor([0.7153, 0.7676, 0.7497, 0.6872], device='cuda:0')\n",
      "val_recall: tensor([0.6392, 0.8462, 0.7777, 0.4579], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 23 time:  1.433606408866664\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.6763758682778903\n",
      "train_precision: tensor([0.6755, 0.7573, 0.7282, 0.6555], device='cuda:0')\n",
      "train_recall: tensor([0.6459, 0.8111, 0.7364, 0.4042], device='cuda:0')\n",
      "val_loss: 0.672478940586249\n",
      "val_precision: tensor([0.7121, 0.7746, 0.7483, 0.6910], device='cuda:0')\n",
      "val_recall: tensor([0.6464, 0.8389, 0.7807, 0.4556], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 24 time:  1.4337295754333355\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.67575501984074\n",
      "train_precision: tensor([0.6741, 0.7574, 0.7315, 0.6600], device='cuda:0')\n",
      "train_recall: tensor([0.6476, 0.8114, 0.7361, 0.4075], device='cuda:0')\n",
      "val_loss: 0.6743902520173126\n",
      "val_precision: tensor([0.7128, 0.7731, 0.7491, 0.6848], device='cuda:0')\n",
      "val_recall: tensor([0.6447, 0.8405, 0.7810, 0.4498], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 25 time:  1.4335841045999966\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.6769936433150655\n",
      "train_precision: tensor([0.6753, 0.7576, 0.7297, 0.6515], device='cuda:0')\n",
      "train_recall: tensor([0.6472, 0.8117, 0.7356, 0.4046], device='cuda:0')\n",
      "val_loss: 0.6757539357576106\n",
      "val_precision: tensor([0.7151, 0.7641, 0.7528, 0.6883], device='cuda:0')\n",
      "val_recall: tensor([0.6400, 0.8477, 0.7741, 0.4640], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 26 time:  1.4339341977833329\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.6747919838343348\n",
      "train_precision: tensor([0.6759, 0.7589, 0.7298, 0.6666], device='cuda:0')\n",
      "train_recall: tensor([0.6477, 0.8115, 0.7378, 0.4102], device='cuda:0')\n",
      "val_loss: 0.6746754984060923\n",
      "val_precision: tensor([0.7143, 0.7632, 0.7553, 0.6906], device='cuda:0')\n",
      "val_recall: tensor([0.6424, 0.8487, 0.7719, 0.4606], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 27 time:  1.4342107667333341\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.6765086866560437\n",
      "train_precision: tensor([0.6747, 0.7565, 0.7319, 0.6618], device='cuda:0')\n",
      "train_recall: tensor([0.6477, 0.8106, 0.7372, 0.4063], device='cuda:0')\n",
      "val_loss: 0.6747145359714826\n",
      "val_precision: tensor([0.7163, 0.7639, 0.7538, 0.6875], device='cuda:0')\n",
      "val_recall: tensor([0.6400, 0.8485, 0.7747, 0.4667], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 28 time:  1.43474764865\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.6777241941009249\n",
      "train_precision: tensor([0.6754, 0.7569, 0.7302, 0.6614], device='cuda:0')\n",
      "train_recall: tensor([0.6461, 0.8103, 0.7384, 0.4069], device='cuda:0')\n",
      "val_loss: 0.6756950520806843\n",
      "val_precision: tensor([0.7101, 0.7637, 0.7615, 0.6938], device='cuda:0')\n",
      "val_recall: tensor([0.6534, 0.8486, 0.7647, 0.4471], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 29 time:  1.4337812662666694\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.6749341638315292\n",
      "train_precision: tensor([0.6747, 0.7581, 0.7307, 0.6718], device='cuda:0')\n",
      "train_recall: tensor([0.6469, 0.8119, 0.7375, 0.4102], device='cuda:0')\n",
      "val_loss: 0.6781451755927669\n",
      "val_precision: tensor([0.7140, 0.7626, 0.7551, 0.6898], device='cuda:0')\n",
      "val_recall: tensor([0.6423, 0.8501, 0.7699, 0.4552], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 30 time:  1.4334605833499987\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 0.6753411830890746\n",
      "train_precision: tensor([0.6765, 0.7587, 0.7311, 0.6563], device='cuda:0')\n",
      "train_recall: tensor([0.6489, 0.8117, 0.7375, 0.4072], device='cuda:0')\n",
      "val_loss: 0.6776183588637246\n",
      "val_precision: tensor([0.7136, 0.7677, 0.7511, 0.6901], device='cuda:0')\n",
      "val_recall: tensor([0.6421, 0.8447, 0.7770, 0.4522], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 31 time:  1.4346018863333332\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 0.6746214699887094\n",
      "train_precision: tensor([0.6770, 0.7583, 0.7308, 0.6573], device='cuda:0')\n",
      "train_recall: tensor([0.6470, 0.8120, 0.7388, 0.4107], device='cuda:0')\n",
      "val_loss: 0.6779111288487911\n",
      "val_precision: tensor([0.7132, 0.7659, 0.7532, 0.6917], device='cuda:0')\n",
      "val_recall: tensor([0.6432, 0.8469, 0.7744, 0.4441], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 32 time:  1.4341808527000013\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 0.6761509874037334\n",
      "train_precision: tensor([0.6745, 0.7569, 0.7290, 0.6629], device='cuda:0')\n",
      "train_recall: tensor([0.6459, 0.8103, 0.7363, 0.4108], device='cuda:0')\n",
      "val_loss: 0.6761358110441102\n",
      "val_precision: tensor([0.7168, 0.7631, 0.7542, 0.6900], device='cuda:0')\n",
      "val_recall: tensor([0.6399, 0.8499, 0.7754, 0.4505], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 33 time:  1.4343607411666652\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 34\n",
      "train_loss: 0.6747274761398633\n",
      "train_precision: tensor([0.6754, 0.7572, 0.7316, 0.6750], device='cuda:0')\n",
      "train_recall: tensor([0.6463, 0.8117, 0.7385, 0.4160], device='cuda:0')\n",
      "val_loss: 0.6764125466346741\n",
      "val_precision: tensor([0.7130, 0.7669, 0.7554, 0.6828], device='cuda:0')\n",
      "val_recall: tensor([0.6466, 0.8470, 0.7718, 0.4566], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "Early stopping at epoch 34 with best validation loss 0.672478940586249\n",
      "training_checkpoints/vit_normalize2024-04-24 16:14:59.984991.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "from vit.vit import VisionTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'vit_normalize{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.05, patience=2, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00005\n",
    "\n",
    "model = VisionTransformer(image_size=32, in_channels=3, num_classes=4, hidden_dims=[128, 128], dropout_rate=0.6)\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch/60}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a92ded-2dbe-4aa3-9244-fee3987cfccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
