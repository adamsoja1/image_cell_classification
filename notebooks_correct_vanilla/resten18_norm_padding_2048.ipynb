{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf6c233-238b-441b-b0db-1d72f21e4cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240425_105250-qi3oyev5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/qi3oyev5' target=\"_blank\">resnet18_base_norm_padding_resize_minlr0.0001_2048_batch_2024-04-25 10:52:50.015624</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/qi3oyev5' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/qi3oyev5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.9679535317988622\n",
      "train_precision: tensor([0.5286, 0.6285, 0.6037, 0.1618], device='cuda:0')\n",
      "train_recall: tensor([0.5287, 0.7355, 0.5592, 0.0056], device='cuda:0')\n",
      "val_loss: 0.8388377732700771\n",
      "val_precision: tensor([0.5789, 0.7561, 0.6293, 0.4674], device='cuda:0')\n",
      "val_recall: tensor([0.5548, 0.7071, 0.7391, 0.1495], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  21.11943453099957\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.8365299730073839\n",
      "train_precision: tensor([0.5916, 0.6889, 0.6625, 0.5332], device='cuda:0')\n",
      "train_recall: tensor([0.5846, 0.7784, 0.6390, 0.0926], device='cuda:0')\n",
      "val_loss: 0.7679295145803028\n",
      "val_precision: tensor([0.6440, 0.6948, 0.6891, 0.7930], device='cuda:0')\n",
      "val_recall: tensor([0.5382, 0.8474, 0.7087, 0.1290], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  22.261284987005638\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.7995374245303017\n",
      "train_precision: tensor([0.6175, 0.7044, 0.6750, 0.5607], device='cuda:0')\n",
      "train_recall: tensor([0.5937, 0.7903, 0.6655, 0.1720], device='cuda:0')\n",
      "val_loss: 0.7415993471940359\n",
      "val_precision: tensor([0.6709, 0.7179, 0.6944, 0.6432], device='cuda:0')\n",
      "val_recall: tensor([0.5708, 0.8413, 0.7210, 0.2519], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  22.406558681002934\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.77639101204418\n",
      "train_precision: tensor([0.6284, 0.7153, 0.6830, 0.5974], device='cuda:0')\n",
      "train_recall: tensor([0.6023, 0.7944, 0.6791, 0.2199], device='cuda:0')\n",
      "val_loss: 0.7292600492636363\n",
      "val_precision: tensor([0.6630, 0.7618, 0.6799, 0.6164], device='cuda:0')\n",
      "val_recall: tensor([0.6012, 0.7863, 0.7569, 0.2943], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  22.36681264299841\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.7595240164370763\n",
      "train_precision: tensor([0.6391, 0.7227, 0.6877, 0.6117], device='cuda:0')\n",
      "train_recall: tensor([0.6105, 0.7980, 0.6876, 0.2496], device='cuda:0')\n",
      "val_loss: 0.7392921613322364\n",
      "val_precision: tensor([0.6733, 0.7871, 0.6495, 0.5800], device='cuda:0')\n",
      "val_recall: tensor([0.6095, 0.7356, 0.7819, 0.3269], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  21.454466948998743\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.7445150798275357\n",
      "train_precision: tensor([0.6474, 0.7275, 0.6958, 0.6230], device='cuda:0')\n",
      "train_recall: tensor([0.6161, 0.8049, 0.6948, 0.2704], device='cuda:0')\n",
      "val_loss: 0.6754914787080553\n",
      "val_precision: tensor([0.6602, 0.7868, 0.7241, 0.6996], device='cuda:0')\n",
      "val_recall: tensor([0.6729, 0.7951, 0.7360, 0.3764], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  22.470920608997403\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.733267263003758\n",
      "train_precision: tensor([0.6525, 0.7323, 0.7024, 0.6244], device='cuda:0')\n",
      "train_recall: tensor([0.6248, 0.8030, 0.7022, 0.2883], device='cuda:0')\n",
      "val_loss: 0.6772464801867802\n",
      "val_precision: tensor([0.6625, 0.7532, 0.7620, 0.5767], device='cuda:0')\n",
      "val_recall: tensor([0.6675, 0.8398, 0.6848, 0.4545], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  21.30528692000371\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.7244972001938593\n",
      "train_precision: tensor([0.6567, 0.7362, 0.7082, 0.6211], device='cuda:0')\n",
      "train_recall: tensor([0.6290, 0.8073, 0.7055, 0.3075], device='cuda:0')\n",
      "val_loss: 0.6726133637958103\n",
      "val_precision: tensor([0.6862, 0.7696, 0.7209, 0.7113], device='cuda:0')\n",
      "val_recall: tensor([0.6474, 0.8270, 0.7449, 0.3451], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  22.48218893000012\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.7150786907899948\n",
      "train_precision: tensor([0.6632, 0.7398, 0.7094, 0.6374], device='cuda:0')\n",
      "train_recall: tensor([0.6317, 0.8097, 0.7106, 0.3263], device='cuda:0')\n",
      "val_loss: 0.6678753743569056\n",
      "val_precision: tensor([0.6711, 0.8250, 0.6956, 0.6073], device='cuda:0')\n",
      "val_recall: tensor([0.6474, 0.7635, 0.7914, 0.4384], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  22.331004676001612\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.7067136781556266\n",
      "train_precision: tensor([0.6664, 0.7431, 0.7123, 0.6379], device='cuda:0')\n",
      "train_recall: tensor([0.6348, 0.8097, 0.7149, 0.3455], device='cuda:0')\n",
      "val_loss: 0.6882906857464048\n",
      "val_precision: tensor([0.7462, 0.7344, 0.6913, 0.6210], device='cuda:0')\n",
      "val_recall: tensor([0.5212, 0.8659, 0.7985, 0.4182], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  21.246113850000256\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.6972051294077011\n",
      "train_precision: tensor([0.6706, 0.7455, 0.7199, 0.6352], device='cuda:0')\n",
      "train_recall: tensor([0.6428, 0.8144, 0.7147, 0.3563], device='cuda:0')\n",
      "val_loss: 0.6613933099640741\n",
      "val_precision: tensor([0.6958, 0.8314, 0.6856, 0.6756], device='cuda:0')\n",
      "val_recall: tensor([0.6371, 0.7568, 0.8253, 0.4768], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  22.304091009005788\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.690039572829292\n",
      "train_precision: tensor([0.6751, 0.7505, 0.7216, 0.6496], device='cuda:0')\n",
      "train_recall: tensor([0.6460, 0.8170, 0.7191, 0.3775], device='cuda:0')\n",
      "val_loss: 0.6822068807151582\n",
      "val_precision: tensor([0.6723, 0.7228, 0.8147, 0.6311], device='cuda:0')\n",
      "val_recall: tensor([0.7034, 0.8752, 0.6290, 0.4465], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  21.273760229996697\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.6821643431981405\n",
      "train_precision: tensor([0.6787, 0.7504, 0.7293, 0.6557], device='cuda:0')\n",
      "train_recall: tensor([0.6542, 0.8192, 0.7193, 0.3817], device='cuda:0')\n",
      "val_loss: 0.6285476780600018\n",
      "val_precision: tensor([0.6681, 0.7926, 0.7888, 0.6430], device='cuda:0')\n",
      "val_recall: tensor([0.7294, 0.8236, 0.6986, 0.5367], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  22.321553793997737\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.6757402811731611\n",
      "train_precision: tensor([0.6811, 0.7548, 0.7295, 0.6517], device='cuda:0')\n",
      "train_recall: tensor([0.6539, 0.8212, 0.7235, 0.3918], device='cuda:0')\n",
      "val_loss: 0.6531460109684203\n",
      "val_precision: tensor([0.6883, 0.7451, 0.7902, 0.7139], device='cuda:0')\n",
      "val_recall: tensor([0.6965, 0.8644, 0.6833, 0.4529], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 13 time:  21.217479671002366\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.6708105144046602\n",
      "train_precision: tensor([0.6853, 0.7565, 0.7314, 0.6579], device='cuda:0')\n",
      "train_recall: tensor([0.6553, 0.8214, 0.7286, 0.4068], device='cuda:0')\n",
      "val_loss: 0.6253362715244293\n",
      "val_precision: tensor([0.6964, 0.7853, 0.7551, 0.7301], device='cuda:0')\n",
      "val_recall: tensor([0.6905, 0.8286, 0.7466, 0.4727], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 14 time:  22.24943319400336\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.6624915060542879\n",
      "train_precision: tensor([0.6885, 0.7592, 0.7345, 0.6710], device='cuda:0')\n",
      "train_recall: tensor([0.6601, 0.8227, 0.7302, 0.4258], device='cuda:0')\n",
      "val_loss: 0.6156571129957835\n",
      "val_precision: tensor([0.7247, 0.7683, 0.7739, 0.5981], device='cuda:0')\n",
      "val_recall: tensor([0.6619, 0.8618, 0.7487, 0.5832], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 15 time:  22.440206564999244\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.6556457641578856\n",
      "train_precision: tensor([0.6914, 0.7619, 0.7387, 0.6681], device='cuda:0')\n",
      "train_recall: tensor([0.6663, 0.8223, 0.7336, 0.4270], device='cuda:0')\n",
      "val_loss: 0.6275709946950276\n",
      "val_precision: tensor([0.7128, 0.7843, 0.7577, 0.5683], device='cuda:0')\n",
      "val_recall: tensor([0.6682, 0.8321, 0.7547, 0.6007], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 16 time:  21.15119788699667\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.6509459291185652\n",
      "train_precision: tensor([0.6954, 0.7634, 0.7404, 0.6668], device='cuda:0')\n",
      "train_recall: tensor([0.6666, 0.8262, 0.7349, 0.4444], device='cuda:0')\n",
      "val_loss: 0.6261187291807598\n",
      "val_precision: tensor([0.6696, 0.7780, 0.8090, 0.7016], device='cuda:0')\n",
      "val_recall: tensor([0.7361, 0.8468, 0.6824, 0.4828], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 17 time:  21.13386448500387\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.6444967496962775\n",
      "train_precision: tensor([0.6957, 0.7651, 0.7413, 0.6666], device='cuda:0')\n",
      "train_recall: tensor([0.6674, 0.8270, 0.7350, 0.4547], device='cuda:0')\n",
      "val_loss: 0.6064389804999034\n",
      "val_precision: tensor([0.7118, 0.7922, 0.7552, 0.7219], device='cuda:0')\n",
      "val_recall: tensor([0.6741, 0.8474, 0.7644, 0.5131], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 18 time:  22.158577761001652\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.6384794652462006\n",
      "train_precision: tensor([0.7010, 0.7673, 0.7481, 0.6767], device='cuda:0')\n",
      "train_recall: tensor([0.6758, 0.8275, 0.7395, 0.4657], device='cuda:0')\n",
      "val_loss: 0.6268294251627392\n",
      "val_precision: tensor([0.7440, 0.7884, 0.7247, 0.6282], device='cuda:0')\n",
      "val_recall: tensor([0.6179, 0.8448, 0.7996, 0.5946], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 19 time:  21.14490423600364\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.6311017428125654\n",
      "train_precision: tensor([0.7017, 0.7718, 0.7496, 0.6836], device='cuda:0')\n",
      "train_recall: tensor([0.6784, 0.8301, 0.7416, 0.4658], device='cuda:0')\n",
      "val_loss: 0.601171569691764\n",
      "val_precision: tensor([0.7013, 0.7936, 0.7819, 0.6322], device='cuda:0')\n",
      "val_recall: tensor([0.7006, 0.8440, 0.7364, 0.6047], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 20 time:  22.197665627994866\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.6273354723339989\n",
      "train_precision: tensor([0.7034, 0.7721, 0.7513, 0.6812], device='cuda:0')\n",
      "train_recall: tensor([0.6793, 0.8306, 0.7415, 0.4872], device='cuda:0')\n",
      "val_loss: 0.5994405842489666\n",
      "val_precision: tensor([0.7397, 0.8042, 0.7276, 0.7014], device='cuda:0')\n",
      "val_recall: tensor([0.6315, 0.8398, 0.8162, 0.5623], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 21 time:  22.274711858000956\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.6200890702860696\n",
      "train_precision: tensor([0.7076, 0.7737, 0.7582, 0.6904], device='cuda:0')\n",
      "train_recall: tensor([0.6863, 0.8327, 0.7436, 0.5043], device='cuda:0')\n",
      "val_loss: 0.5887467977073457\n",
      "val_precision: tensor([0.7068, 0.8049, 0.7804, 0.6527], device='cuda:0')\n",
      "val_recall: tensor([0.7115, 0.8372, 0.7492, 0.6074], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 22 time:  22.372488713001076\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.612300363608769\n",
      "train_precision: tensor([0.7105, 0.7763, 0.7585, 0.6915], device='cuda:0')\n",
      "train_recall: tensor([0.6875, 0.8341, 0.7467, 0.5088], device='cuda:0')\n",
      "val_loss: 0.6022258559862773\n",
      "val_precision: tensor([0.7099, 0.8126, 0.7526, 0.7015], device='cuda:0')\n",
      "val_recall: tensor([0.6913, 0.8156, 0.7861, 0.5475], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 23 time:  21.35103166600311\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.6070254124346234\n",
      "train_precision: tensor([0.7144, 0.7773, 0.7599, 0.7021], device='cuda:0')\n",
      "train_recall: tensor([0.6885, 0.8365, 0.7490, 0.5224], device='cuda:0')\n",
      "val_loss: 0.5983385168843799\n",
      "val_precision: tensor([0.7039, 0.7914, 0.7840, 0.7430], device='cuda:0')\n",
      "val_recall: tensor([0.7099, 0.8447, 0.7486, 0.5148], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 24 time:  21.370847606005555\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.6014928156421298\n",
      "train_precision: tensor([0.7159, 0.7794, 0.7636, 0.7076], device='cuda:0')\n",
      "train_recall: tensor([0.6944, 0.8363, 0.7499, 0.5300], device='cuda:0')\n",
      "val_loss: 0.6014013191064199\n",
      "val_precision: tensor([0.7208, 0.8166, 0.7488, 0.7324], device='cuda:0')\n",
      "val_recall: tensor([0.6813, 0.8209, 0.8059, 0.5364], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 25 time:  21.366909021999163\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.5940502226352692\n",
      "train_precision: tensor([0.7188, 0.7854, 0.7661, 0.7045], device='cuda:0')\n",
      "train_recall: tensor([0.7005, 0.8346, 0.7552, 0.5424], device='cuda:0')\n",
      "val_loss: 0.6029575381014082\n",
      "val_precision: tensor([0.7103, 0.8040, 0.7642, 0.6975], device='cuda:0')\n",
      "val_recall: tensor([0.6974, 0.8239, 0.7744, 0.5582], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 26 time:  21.44271117199969\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.5541004735799063\n",
      "train_precision: tensor([0.7387, 0.7965, 0.7845, 0.7482], device='cuda:0')\n",
      "train_recall: tensor([0.7190, 0.8495, 0.7680, 0.6072], device='cuda:0')\n",
      "val_loss: 0.5565256562497881\n",
      "val_precision: tensor([0.7245, 0.8252, 0.7868, 0.7244], device='cuda:0')\n",
      "val_recall: tensor([0.7271, 0.8377, 0.7840, 0.6152], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 27 time:  22.396040767998784\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.5405742770149594\n",
      "train_precision: tensor([0.7465, 0.8024, 0.7885, 0.7510], device='cuda:0')\n",
      "train_recall: tensor([0.7252, 0.8527, 0.7747, 0.6257], device='cuda:0')\n",
      "val_loss: 0.5560699707931942\n",
      "val_precision: tensor([0.7382, 0.8228, 0.7753, 0.7378], device='cuda:0')\n",
      "val_recall: tensor([0.7060, 0.8421, 0.8036, 0.6168], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 28 time:  22.599464020997402\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.5323788068124227\n",
      "train_precision: tensor([0.7504, 0.8046, 0.7922, 0.7581], device='cuda:0')\n",
      "train_recall: tensor([0.7292, 0.8522, 0.7796, 0.6447], device='cuda:0')\n",
      "val_loss: 0.5568988442420959\n",
      "val_precision: tensor([0.7399, 0.8263, 0.7712, 0.7230], device='cuda:0')\n",
      "val_recall: tensor([0.7077, 0.8367, 0.8050, 0.6293], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 29 time:  21.462541018001502\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.5264819244543711\n",
      "train_precision: tensor([0.7535, 0.8075, 0.7948, 0.7623], device='cuda:0')\n",
      "train_recall: tensor([0.7306, 0.8578, 0.7808, 0.6528], device='cuda:0')\n",
      "val_loss: 0.5579203357299168\n",
      "val_precision: tensor([0.7421, 0.8177, 0.7813, 0.7216], device='cuda:0')\n",
      "val_recall: tensor([0.7031, 0.8497, 0.8008, 0.6387], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 30 time:  21.334961756998382\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 0.5214806321121398\n",
      "train_precision: tensor([0.7557, 0.8090, 0.7979, 0.7746], device='cuda:0')\n",
      "train_recall: tensor([0.7338, 0.8586, 0.7837, 0.6631], device='cuda:0')\n",
      "val_loss: 0.5593141512738333\n",
      "val_precision: tensor([0.7422, 0.8248, 0.7746, 0.7548], device='cuda:0')\n",
      "val_recall: tensor([0.7079, 0.8434, 0.8080, 0.6084], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 31 time:  21.441607544998988\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 0.5175666807662873\n",
      "train_precision: tensor([0.7582, 0.8103, 0.7984, 0.7833], device='cuda:0')\n",
      "train_recall: tensor([0.7356, 0.8600, 0.7854, 0.6645], device='cuda:0')\n",
      "val_loss: 0.5577108273903529\n",
      "val_precision: tensor([0.7419, 0.8108, 0.7880, 0.7386], device='cuda:0')\n",
      "val_recall: tensor([0.7062, 0.8597, 0.7899, 0.6306], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 32 time:  21.29529201600235\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 0.5142381907928557\n",
      "train_precision: tensor([0.7582, 0.8113, 0.8010, 0.7793], device='cuda:0')\n",
      "train_recall: tensor([0.7369, 0.8588, 0.7878, 0.6700], device='cuda:0')\n",
      "val_loss: 0.5580979079008103\n",
      "val_precision: tensor([0.7425, 0.8161, 0.7834, 0.7221], device='cuda:0')\n",
      "val_recall: tensor([0.7079, 0.8496, 0.7966, 0.6404], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 33 time:  21.323514431001968\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 34\n",
      "train_loss: 0.5091405007101241\n",
      "train_precision: tensor([0.7621, 0.8139, 0.8007, 0.7850], device='cuda:0')\n",
      "train_recall: tensor([0.7411, 0.8611, 0.7871, 0.6786], device='cuda:0')\n",
      "val_loss: 0.5602165699005127\n",
      "val_precision: tensor([0.7403, 0.8247, 0.7770, 0.7125], device='cuda:0')\n",
      "val_recall: tensor([0.7082, 0.8428, 0.8023, 0.6333], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 34 time:  21.372556397000153\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 35\n",
      "train_loss: 0.5049186932189124\n",
      "train_precision: tensor([0.7645, 0.8155, 0.8030, 0.7874], device='cuda:0')\n",
      "train_recall: tensor([0.7440, 0.8618, 0.7897, 0.6824], device='cuda:0')\n",
      "val_loss: 0.5582414276070065\n",
      "val_precision: tensor([0.7389, 0.8253, 0.7831, 0.7279], device='cuda:0')\n",
      "val_recall: tensor([0.7149, 0.8453, 0.7980, 0.6495], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 35 time:  21.21531745300308\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 36\n",
      "train_loss: 0.501109798749288\n",
      "train_precision: tensor([0.7651, 0.8163, 0.8048, 0.7892], device='cuda:0')\n",
      "train_recall: tensor([0.7469, 0.8610, 0.7903, 0.6854], device='cuda:0')\n",
      "val_loss: 0.5646191285716162\n",
      "val_precision: tensor([0.7421, 0.8151, 0.7795, 0.7384], device='cuda:0')\n",
      "val_recall: tensor([0.7004, 0.8536, 0.7979, 0.6293], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 36 time:  21.234985201997915\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 37\n",
      "train_loss: 0.497822668438866\n",
      "train_precision: tensor([0.7683, 0.8171, 0.8092, 0.7900], device='cuda:0')\n",
      "train_recall: tensor([0.7487, 0.8659, 0.7923, 0.6838], device='cuda:0')\n",
      "val_loss: 0.5611722926298778\n",
      "val_precision: tensor([0.7322, 0.8308, 0.7830, 0.7255], device='cuda:0')\n",
      "val_recall: tensor([0.7225, 0.8370, 0.7963, 0.6451], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 37 time:  21.27689602200553\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 38\n",
      "train_loss: 0.4938059477579026\n",
      "train_precision: tensor([0.7723, 0.8177, 0.8068, 0.7939], device='cuda:0')\n",
      "train_recall: tensor([0.7457, 0.8682, 0.7947, 0.6948], device='cuda:0')\n",
      "val_loss: 0.5648828417062759\n",
      "val_precision: tensor([0.7443, 0.8180, 0.7815, 0.7070], device='cuda:0')\n",
      "val_recall: tensor([0.7032, 0.8504, 0.7988, 0.6623], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "Early stopping at epoch 38 with best validation loss 0.5560699707931942\n",
      "training_checkpoints/resnet18_base_norm_padding_resize_minlr0.0001_2048_batch_2024-04-25 10:52:50.015624.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'resnet18_base_norm_padding_resize_minlr0.0001_2048_batch_{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.01, patience=3, min_lr=0.0001, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 1024\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "num_classes = 4\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 15\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6042c6b-7e5c-4157-b026-6983ad5cfc87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
