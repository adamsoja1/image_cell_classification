{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35bf0f4-2d28-4896-be8d-64d5401a8bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240423_204942-817h1re8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/817h1re8' target=\"_blank\">resnet18_1024_weighted_4_4_4_1_drop0.4_2024-04-23 20:49:41.507774</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/817h1re8' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/817h1re8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 3.2398423456010366\n",
      "train_precision: tensor([0.5408, 0.6840, 0.6316, 0.3869], device='cuda:0')\n",
      "train_recall: tensor([0.5361, 0.7530, 0.6353, 0.0076], device='cuda:0')\n",
      "val_loss: 3.0929934170511033\n",
      "val_precision: tensor([0.5853, 0.8054, 0.5824, 1.0000], device='cuda:0')\n",
      "val_recall: tensor([0.4990, 0.6708, 0.8232, 0.0108], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  1.5212432962333329\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 2.8971364736557006\n",
      "train_precision: tensor([0.5975, 0.7178, 0.6818, 0.8977], device='cuda:0')\n",
      "train_recall: tensor([0.5911, 0.7878, 0.6865, 0.0570], device='cuda:0')\n",
      "val_loss: 2.7863238440619575\n",
      "val_precision: tensor([0.5921, 0.8059, 0.6799, 0.8407], device='cuda:0')\n",
      "val_recall: tensor([0.6797, 0.7069, 0.7190, 0.1475], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  0.34238800958333304\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 2.790306169646127\n",
      "train_precision: tensor([0.6118, 0.7280, 0.6958, 0.8926], device='cuda:0')\n",
      "train_recall: tensor([0.6077, 0.7950, 0.6982, 0.0996], device='cuda:0')\n",
      "val_loss: 2.6693317890167236\n",
      "val_precision: tensor([0.6283, 0.7637, 0.6956, 0.9580], device='cuda:0')\n",
      "val_recall: tensor([0.6114, 0.7903, 0.7490, 0.1458], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  0.33491514406666645\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 2.706770320165725\n",
      "train_precision: tensor([0.6253, 0.7377, 0.7066, 0.8717], device='cuda:0')\n",
      "train_recall: tensor([0.6215, 0.8029, 0.7080, 0.1382], device='cuda:0')\n",
      "val_loss: 2.7012452681859336\n",
      "val_precision: tensor([0.5991, 0.7939, 0.7029, 0.9316], device='cuda:0')\n",
      "val_recall: tensor([0.6825, 0.7246, 0.7217, 0.1973], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  0.31646044026666686\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 2.636516811734154\n",
      "train_precision: tensor([0.6341, 0.7489, 0.7137, 0.8685], device='cuda:0')\n",
      "train_recall: tensor([0.6359, 0.8041, 0.7169, 0.1649], device='cuda:0')\n",
      "val_loss: 2.550273495250278\n",
      "val_precision: tensor([0.6828, 0.7325, 0.7157, 0.9004], device='cuda:0')\n",
      "val_recall: tensor([0.5967, 0.8404, 0.7522, 0.2495], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  0.33534703779999975\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 2.5699395895004273\n",
      "train_precision: tensor([0.6466, 0.7567, 0.7217, 0.8615], device='cuda:0')\n",
      "train_recall: tensor([0.6450, 0.8127, 0.7259, 0.1948], device='cuda:0')\n",
      "val_loss: 2.6827262110180325\n",
      "val_precision: tensor([0.7031, 0.6704, 0.7313, 0.8131], device='cuda:0')\n",
      "val_recall: tensor([0.5037, 0.9052, 0.7316, 0.2680], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  0.31658686711666634\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 2.516141789300101\n",
      "train_precision: tensor([0.6542, 0.7618, 0.7289, 0.8664], device='cuda:0')\n",
      "train_recall: tensor([0.6509, 0.8191, 0.7328, 0.2143], device='cuda:0')\n",
      "val_loss: 2.9277111649513246\n",
      "val_precision: tensor([0.6163, 0.8397, 0.6029, 0.8499], device='cuda:0')\n",
      "val_recall: tensor([0.5257, 0.6735, 0.8540, 0.2441], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  0.3163117783500013\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 2.469818260556176\n",
      "train_precision: tensor([0.6611, 0.7665, 0.7340, 0.8752], device='cuda:0')\n",
      "train_recall: tensor([0.6604, 0.8213, 0.7367, 0.2267], device='cuda:0')\n",
      "val_loss: 2.4444774521721735\n",
      "val_precision: tensor([0.6891, 0.8076, 0.6863, 0.8577], device='cuda:0')\n",
      "val_recall: tensor([0.6191, 0.7904, 0.8169, 0.2801], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  0.33432141494999995\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 2.4350444975353422\n",
      "train_precision: tensor([0.6679, 0.7714, 0.7368, 0.8835], device='cuda:0')\n",
      "train_recall: tensor([0.6639, 0.8257, 0.7427, 0.2450], device='cuda:0')\n",
      "val_loss: 2.8218221876356337\n",
      "val_precision: tensor([0.6530, 0.8174, 0.6203, 0.9199], device='cuda:0')\n",
      "val_recall: tensor([0.5205, 0.7324, 0.8583, 0.2128], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  0.31618557896666555\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 2.391033093134562\n",
      "train_precision: tensor([0.6775, 0.7742, 0.7419, 0.8815], device='cuda:0')\n",
      "train_recall: tensor([0.6696, 0.8293, 0.7502, 0.2576], device='cuda:0')\n",
      "val_loss: 2.517450804180569\n",
      "val_precision: tensor([0.6747, 0.8087, 0.6687, 0.9327], device='cuda:0')\n",
      "val_recall: tensor([0.6000, 0.7826, 0.8161, 0.2101], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  0.31592590763333417\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 2.35135406766619\n",
      "train_precision: tensor([0.6801, 0.7787, 0.7475, 0.8849], device='cuda:0')\n",
      "train_recall: tensor([0.6764, 0.8317, 0.7525, 0.2719], device='cuda:0')\n",
      "val_loss: 2.4825483640034993\n",
      "val_precision: tensor([0.6957, 0.7197, 0.7562, 0.8837], device='cuda:0')\n",
      "val_recall: tensor([0.6087, 0.8965, 0.7154, 0.2966], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  0.3157799264833348\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 2.3158728826613655\n",
      "train_precision: tensor([0.6843, 0.7829, 0.7512, 0.8728], device='cuda:0')\n",
      "train_recall: tensor([0.6817, 0.8352, 0.7551, 0.2772], device='cuda:0')\n",
      "val_loss: 2.4604690300093757\n",
      "val_precision: tensor([0.6863, 0.7556, 0.7115, 0.9544], device='cuda:0')\n",
      "val_recall: tensor([0.6013, 0.8413, 0.7727, 0.2327], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 11 time:  0.3158003281499987\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 2.161096721603757\n",
      "train_precision: tensor([0.7070, 0.7992, 0.7707, 0.8973], device='cuda:0')\n",
      "train_recall: tensor([0.7057, 0.8474, 0.7760, 0.3101], device='cuda:0')\n",
      "val_loss: 2.1628875679439967\n",
      "val_precision: tensor([0.6965, 0.8242, 0.7623, 0.9127], device='cuda:0')\n",
      "val_recall: tensor([0.7159, 0.8224, 0.7907, 0.3380], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 12 time:  0.33500106344999947\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 2.1009876075245084\n",
      "train_precision: tensor([0.7149, 0.8053, 0.7778, 0.8941], device='cuda:0')\n",
      "train_recall: tensor([0.7154, 0.8531, 0.7798, 0.3338], device='cuda:0')\n",
      "val_loss: 2.1554007159339057\n",
      "val_precision: tensor([0.7078, 0.7905, 0.7787, 0.9201], device='cuda:0')\n",
      "val_recall: tensor([0.7020, 0.8617, 0.7647, 0.3337], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 13 time:  0.33557355208333395\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 2.0721375283740815\n",
      "train_precision: tensor([0.7192, 0.8091, 0.7825, 0.9039], device='cuda:0')\n",
      "train_recall: tensor([0.7213, 0.8545, 0.7850, 0.3418], device='cuda:0')\n",
      "val_loss: 2.2163586894671123\n",
      "val_precision: tensor([0.7208, 0.8286, 0.7193, 0.9038], device='cuda:0')\n",
      "val_recall: tensor([0.6561, 0.8181, 0.8379, 0.3384], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 14 time:  0.3162641123333344\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 2.0469405361584254\n",
      "train_precision: tensor([0.7225, 0.8110, 0.7847, 0.8967], device='cuda:0')\n",
      "train_recall: tensor([0.7236, 0.8558, 0.7876, 0.3545], device='cuda:0')\n",
      "val_loss: 2.134368080563015\n",
      "val_precision: tensor([0.7073, 0.8144, 0.7723, 0.8834], device='cuda:0')\n",
      "val_recall: tensor([0.7142, 0.8398, 0.7841, 0.3879], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 15 time:  0.33405460136666726\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 2.0264757247198197\n",
      "train_precision: tensor([0.7234, 0.8127, 0.7872, 0.8974], device='cuda:0')\n",
      "train_recall: tensor([0.7274, 0.8568, 0.7877, 0.3548], device='cuda:0')\n",
      "val_loss: 2.17202308177948\n",
      "val_precision: tensor([0.7059, 0.8340, 0.7423, 0.8840], device='cuda:0')\n",
      "val_recall: tensor([0.6932, 0.8167, 0.8144, 0.3694], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 16 time:  0.3164549380000002\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 2.007418876034873\n",
      "train_precision: tensor([0.7281, 0.8167, 0.7899, 0.9002], device='cuda:0')\n",
      "train_recall: tensor([0.7324, 0.8592, 0.7919, 0.3566], device='cuda:0')\n",
      "val_loss: 2.1750993808110555\n",
      "val_precision: tensor([0.7223, 0.8286, 0.7321, 0.9230], device='cuda:0')\n",
      "val_recall: tensor([0.6712, 0.8242, 0.8337, 0.3431], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 17 time:  0.3161607714833318\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 1.9820927018211\n",
      "train_precision: tensor([0.7312, 0.8177, 0.7919, 0.8997], device='cuda:0')\n",
      "train_recall: tensor([0.7342, 0.8609, 0.7935, 0.3677], device='cuda:0')\n",
      "val_loss: 2.14088783926434\n",
      "val_precision: tensor([0.7032, 0.7989, 0.7932, 0.8950], device='cuda:0')\n",
      "val_recall: tensor([0.7249, 0.8606, 0.7536, 0.3731], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 18 time:  0.31703312868333455\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 1.9666664986383346\n",
      "train_precision: tensor([0.7304, 0.8190, 0.7951, 0.9006], device='cuda:0')\n",
      "train_recall: tensor([0.7377, 0.8614, 0.7926, 0.3724], device='cuda:0')\n",
      "val_loss: 2.1533072299427456\n",
      "val_precision: tensor([0.7148, 0.8301, 0.7434, 0.9033], device='cuda:0')\n",
      "val_recall: tensor([0.6936, 0.8231, 0.8159, 0.3650], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 19 time:  0.31860720331666814\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 1.924049467132205\n",
      "train_precision: tensor([0.7360, 0.8231, 0.8037, 0.9089], device='cuda:0')\n",
      "train_recall: tensor([0.7465, 0.8659, 0.7968, 0.3831], device='cuda:0')\n",
      "val_loss: 2.1163234670956927\n",
      "val_precision: tensor([0.7164, 0.8247, 0.7623, 0.9093], device='cuda:0')\n",
      "val_recall: tensor([0.7102, 0.8348, 0.8042, 0.3747], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 20 time:  0.3374849556666656\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 1.906738657610757\n",
      "train_precision: tensor([0.7406, 0.8244, 0.8019, 0.9049], device='cuda:0')\n",
      "train_recall: tensor([0.7459, 0.8674, 0.8013, 0.3747], device='cuda:0')\n",
      "val_loss: 2.111420057879554\n",
      "val_precision: tensor([0.7140, 0.8235, 0.7705, 0.9034], device='cuda:0')\n",
      "val_recall: tensor([0.7206, 0.8356, 0.7966, 0.3808], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 21 time:  0.33654896411666757\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 1.9059248992374964\n",
      "train_precision: tensor([0.7402, 0.8253, 0.8042, 0.9028], device='cuda:0')\n",
      "train_recall: tensor([0.7491, 0.8662, 0.8009, 0.3831], device='cuda:0')\n",
      "val_loss: 2.1223840369118583\n",
      "val_precision: tensor([0.7205, 0.8211, 0.7628, 0.9014], device='cuda:0')\n",
      "val_recall: tensor([0.7058, 0.8395, 0.8056, 0.3785], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 22 time:  0.31834003204999894\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 1.8995924064091274\n",
      "train_precision: tensor([0.7406, 0.8248, 0.8040, 0.9070], device='cuda:0')\n",
      "train_recall: tensor([0.7470, 0.8683, 0.8011, 0.3827], device='cuda:0')\n",
      "val_loss: 2.1082488179206846\n",
      "val_precision: tensor([0.7224, 0.8155, 0.7709, 0.8966], device='cuda:0')\n",
      "val_recall: tensor([0.7078, 0.8469, 0.8004, 0.3882], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 23 time:  0.33717987311666775\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 1.9016051519484747\n",
      "train_precision: tensor([0.7413, 0.8249, 0.8040, 0.9043], device='cuda:0')\n",
      "train_recall: tensor([0.7477, 0.8676, 0.8012, 0.3885], device='cuda:0')\n",
      "val_loss: 2.122682289282481\n",
      "val_precision: tensor([0.7219, 0.8246, 0.7608, 0.8932], device='cuda:0')\n",
      "val_recall: tensor([0.7053, 0.8367, 0.8104, 0.3859], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 24 time:  0.3185243557833341\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 1.892946091720036\n",
      "train_precision: tensor([0.7430, 0.8265, 0.8059, 0.9108], device='cuda:0')\n",
      "train_recall: tensor([0.7500, 0.8703, 0.8016, 0.3918], device='cuda:0')\n",
      "val_loss: 2.115304579999712\n",
      "val_precision: tensor([0.7227, 0.8186, 0.7670, 0.8960], device='cuda:0')\n",
      "val_recall: tensor([0.7063, 0.8437, 0.8043, 0.3889], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 25 time:  0.3184710595666672\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 1.8867307804879687\n",
      "train_precision: tensor([0.7442, 0.8266, 0.8043, 0.9078], device='cuda:0')\n",
      "train_recall: tensor([0.7491, 0.8680, 0.8045, 0.3909], device='cuda:0')\n",
      "val_loss: 2.1223162876235113\n",
      "val_precision: tensor([0.7197, 0.8238, 0.7633, 0.8954], device='cuda:0')\n",
      "val_recall: tensor([0.7107, 0.8349, 0.8062, 0.3835], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 26 time:  0.31866972171666624\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 1.8851221680641175\n",
      "train_precision: tensor([0.7430, 0.8269, 0.8061, 0.9100], device='cuda:0')\n",
      "train_recall: tensor([0.7503, 0.8695, 0.8027, 0.3896], device='cuda:0')\n",
      "val_loss: 2.117326891422272\n",
      "val_precision: tensor([0.7187, 0.8213, 0.7712, 0.8920], device='cuda:0')\n",
      "val_recall: tensor([0.7164, 0.8405, 0.7989, 0.3923], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 27 time:  0.3180587029499994\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 1.8796030282974243\n",
      "train_precision: tensor([0.7434, 0.8278, 0.8047, 0.9077], device='cuda:0')\n",
      "train_recall: tensor([0.7502, 0.8698, 0.8027, 0.3876], device='cuda:0')\n",
      "val_loss: 2.1159839166535273\n",
      "val_precision: tensor([0.7136, 0.8251, 0.7726, 0.8930], device='cuda:0')\n",
      "val_recall: tensor([0.7222, 0.8352, 0.7970, 0.3933], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 28 time:  0.31828699390000187\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 1.8795177374567305\n",
      "train_precision: tensor([0.7455, 0.8279, 0.8073, 0.9039], device='cuda:0')\n",
      "train_recall: tensor([0.7520, 0.8702, 0.8043, 0.3961], device='cuda:0')\n",
      "val_loss: 2.1155298325750564\n",
      "val_precision: tensor([0.7195, 0.8214, 0.7664, 0.8987], device='cuda:0')\n",
      "val_recall: tensor([0.7108, 0.8391, 0.8029, 0.3855], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 29 time:  0.31791559933333435\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 1.879214195978074\n",
      "train_precision: tensor([0.7454, 0.8272, 0.8068, 0.9050], device='cuda:0')\n",
      "train_recall: tensor([0.7525, 0.8694, 0.8041, 0.3876], device='cuda:0')\n",
      "val_loss: 2.111097170246972\n",
      "val_precision: tensor([0.7160, 0.8197, 0.7750, 0.9005], device='cuda:0')\n",
      "val_recall: tensor([0.7182, 0.8423, 0.7954, 0.3872], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 30 time:  0.3180193169333336\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 1.872463480063847\n",
      "train_precision: tensor([0.7459, 0.8286, 0.8088, 0.9071], device='cuda:0')\n",
      "train_recall: tensor([0.7537, 0.8708, 0.8046, 0.3971], device='cuda:0')\n",
      "val_loss: 2.1165127608511183\n",
      "val_precision: tensor([0.7180, 0.8238, 0.7684, 0.8992], device='cuda:0')\n",
      "val_recall: tensor([0.7144, 0.8390, 0.8016, 0.3906], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 31 time:  0.3181361741833333\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 1.8796424286706106\n",
      "train_precision: tensor([0.7460, 0.8284, 0.8058, 0.9040], device='cuda:0')\n",
      "train_recall: tensor([0.7516, 0.8692, 0.8060, 0.3873], device='cuda:0')\n",
      "val_loss: 2.1123134785228306\n",
      "val_precision: tensor([0.7186, 0.8182, 0.7748, 0.8936], device='cuda:0')\n",
      "val_recall: tensor([0.7158, 0.8454, 0.7955, 0.3933], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 32 time:  0.31819906839999895\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 1.8753909003166926\n",
      "train_precision: tensor([0.7433, 0.8282, 0.8073, 0.9119], device='cuda:0')\n",
      "train_recall: tensor([0.7522, 0.8686, 0.8047, 0.3867], device='cuda:0')\n",
      "val_loss: 2.118798045317332\n",
      "val_precision: tensor([0.7213, 0.8211, 0.7668, 0.8904], device='cuda:0')\n",
      "val_recall: tensor([0.7084, 0.8415, 0.8041, 0.3939], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "Early stopping at epoch 33 with best validation loss 2.1082488179206846\n",
      "training_checkpoints/resnet18_1024_weighted_4_4_4_1_drop0.4_2024-04-23 20:49:41.507774.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'resnet18_1024_weighted_4_4_4_1_drop0.4_{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),]\n",
    ")\n",
    "\n",
    "\n",
    "weights = torch.tensor([4.0, 4.0, 4.0, 1.0])\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=3, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 1024\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "num_classes = 4\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch/60}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac89ded-8b2a-473f-b0eb-ac8ee316caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[695 106 198   1]\n",
      " [ 97 849  53   1]\n",
      " [133  46 818   3]\n",
      " [ 32  20  15  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71      1000\n",
      "           1       0.83      0.85      0.84      1000\n",
      "           2       0.75      0.82      0.79      1000\n",
      "           3       0.87      0.33      0.48       100\n",
      "\n",
      "    accuracy                           0.77      3100\n",
      "   macro avg       0.80      0.67      0.70      3100\n",
      "weighted avg       0.77      0.77      0.77      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data')\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17bc53-caa4-49d2-b31b-e84e4136f9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
