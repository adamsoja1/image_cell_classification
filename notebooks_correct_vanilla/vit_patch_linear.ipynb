{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e06df7-20bf-4e70-ab0f-506c40e62aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240526_014944-8zv2mheb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/8zv2mheb' target=\"_blank\">vit_normalized_linear_patch2024-05-26 01:49:43.239177</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/8zv2mheb' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/8zv2mheb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 1.0134840777232534\n",
      "train_precision: tensor([0.4829, 0.5886, 0.5388, 0.0000], device='cuda:0')\n",
      "train_recall: tensor([0.4490, 0.7561, 0.4770, 0.0000], device='cuda:0')\n",
      "val_loss: 1.064895236492157\n",
      "val_precision: tensor([0.5960, 0.6735, 0.4531, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.2549, 0.5224, 0.8595, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  26.67023941499997\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.9582504851477487\n",
      "train_precision: tensor([0.5214, 0.6206, 0.5967, 0.0000], device='cuda:0')\n",
      "train_recall: tensor([0.5066, 0.7461, 0.5526, 0.0000], device='cuda:0')\n",
      "val_loss: 0.9522860722409354\n",
      "val_precision: tensor([0.5186, 0.7229, 0.5887, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.5907, 0.6124, 0.6557, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  23.97447940400002\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.9437523985902468\n",
      "train_precision: tensor([0.5297, 0.6292, 0.6046, 0.4286], device='cuda:0')\n",
      "train_recall: tensor([5.1556e-01, 7.4573e-01, 5.6909e-01, 4.3290e-04], device='cuda:0')\n",
      "val_loss: 0.9743865149716536\n",
      "val_precision: tensor([0.5883, 0.7186, 0.5106, 0.2500], device='cuda:0')\n",
      "val_recall: tensor([3.4781e-01, 6.3808e-01, 8.2747e-01, 6.7340e-04], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  23.917628455000113\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.93575683342559\n",
      "train_precision: tensor([0.5334, 0.6353, 0.6067, 0.5500], device='cuda:0')\n",
      "train_recall: tensor([0.5209, 0.7473, 0.5744, 0.0032], device='cuda:0')\n",
      "val_loss: 0.926133901046382\n",
      "val_precision: tensor([0.5264, 0.7111, 0.6007, 0.5714], device='cuda:0')\n",
      "val_recall: tensor([0.5473, 0.6494, 0.6885, 0.0054], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  23.691527135999877\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.9359552753113565\n",
      "train_precision: tensor([0.5337, 0.6327, 0.6083, 0.5161], device='cuda:0')\n",
      "train_recall: tensor([0.5220, 0.7439, 0.5750, 0.0046], device='cuda:0')\n",
      "val_loss: 0.9131732018457519\n",
      "val_precision: tensor([0.5672, 0.7155, 0.5652, 0.5556], device='cuda:0')\n",
      "val_recall: tensor([0.4619, 0.6811, 0.7534, 0.0034], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  23.771664452000095\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.9308169017945017\n",
      "train_precision: tensor([0.5350, 0.6371, 0.6093, 0.4478], device='cuda:0')\n",
      "train_recall: tensor([0.5255, 0.7466, 0.5759, 0.0043], device='cuda:0')\n",
      "val_loss: 1.0378716349601746\n",
      "val_precision: tensor([0.5338, 0.7830, 0.5117, 0.4545], device='cuda:0')\n",
      "val_recall: tensor([0.4766, 0.4718, 0.8209, 0.0017], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  23.50334855999995\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.9320335103642373\n",
      "train_precision: tensor([0.5357, 0.6357, 0.6091, 0.5048], device='cuda:0')\n",
      "train_recall: tensor([0.5291, 0.7461, 0.5708, 0.0076], device='cuda:0')\n",
      "val_loss: 0.9433974482946925\n",
      "val_precision: tensor([0.5745, 0.6616, 0.5781, 0.5402], device='cuda:0')\n",
      "val_recall: tensor([0.3944, 0.7459, 0.7418, 0.0158], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  23.430481310999994\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.9324572294950485\n",
      "train_precision: tensor([0.5346, 0.6357, 0.6085, 0.5393], device='cuda:0')\n",
      "train_recall: tensor([0.5257, 0.7452, 0.5740, 0.0069], device='cuda:0')\n",
      "val_loss: 0.9448329817917612\n",
      "val_precision: tensor([0.5770, 0.7374, 0.5291, 0.5169], device='cuda:0')\n",
      "val_recall: tensor([0.4392, 0.5995, 0.8057, 0.0155], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  23.60843464200002\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.9306602841331846\n",
      "train_precision: tensor([0.5373, 0.6365, 0.6070, 0.4857], device='cuda:0')\n",
      "train_recall: tensor([0.5270, 0.7451, 0.5745, 0.0098], device='cuda:0')\n",
      "val_loss: 0.9685622993442747\n",
      "val_precision: tensor([0.5406, 0.7631, 0.5306, 0.3824], device='cuda:0')\n",
      "val_recall: tensor([0.4527, 0.5639, 0.8029, 0.0394], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  23.60544436600003\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.9339574887639001\n",
      "train_precision: tensor([0.5371, 0.6329, 0.6058, 0.5294], device='cuda:0')\n",
      "train_recall: tensor([0.5273, 0.7437, 0.5702, 0.0104], device='cuda:0')\n",
      "val_loss: 0.9671905427343316\n",
      "val_precision: tensor([0.5534, 0.7380, 0.5383, 0.5263], device='cuda:0')\n",
      "val_recall: tensor([0.4097, 0.6277, 0.8103, 0.0202], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 9 time:  23.98207315700006\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.9157508209347724\n",
      "train_precision: tensor([0.5442, 0.6428, 0.6194, 0.5844], device='cuda:0')\n",
      "train_recall: tensor([0.5388, 0.7500, 0.5828, 0.0130], device='cuda:0')\n",
      "val_loss: 0.9635318568183316\n",
      "val_precision: tensor([0.5506, 0.7753, 0.5358, 0.6330], device='cuda:0')\n",
      "val_recall: tensor([0.4609, 0.5712, 0.8142, 0.0401], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 10 time:  23.50192932899995\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.9093858389627366\n",
      "train_precision: tensor([0.5496, 0.6459, 0.6218, 0.5896], device='cuda:0')\n",
      "train_recall: tensor([0.5396, 0.7530, 0.5902, 0.0180], device='cuda:0')\n",
      "val_loss: 0.956122335874372\n",
      "val_precision: tensor([0.5561, 0.7735, 0.5468, 0.7000], device='cuda:0')\n",
      "val_recall: tensor([0.4851, 0.5799, 0.8053, 0.0377], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 11 time:  24.103258018000133\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.906158070053373\n",
      "train_precision: tensor([0.5493, 0.6473, 0.6210, 0.5704], device='cuda:0')\n",
      "train_recall: tensor([0.5400, 0.7510, 0.5915, 0.0228], device='cuda:0')\n",
      "val_loss: 0.9689659383561876\n",
      "val_precision: tensor([0.5606, 0.7752, 0.5319, 0.6802], device='cuda:0')\n",
      "val_recall: tensor([0.4541, 0.5673, 0.8253, 0.0451], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 12 time:  23.915194416000077\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.9022281152861459\n",
      "train_precision: tensor([0.5527, 0.6511, 0.6235, 0.5508], device='cuda:0')\n",
      "train_recall: tensor([0.5406, 0.7529, 0.5991, 0.0242], device='cuda:0')\n",
      "val_loss: 0.9730102000965013\n",
      "val_precision: tensor([0.5557, 0.7746, 0.5299, 0.6869], device='cuda:0')\n",
      "val_recall: tensor([0.4399, 0.5676, 0.8314, 0.0458], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 13 time:  23.787308974000098\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.8996824546938851\n",
      "train_precision: tensor([0.5564, 0.6526, 0.6257, 0.5298], device='cuda:0')\n",
      "train_recall: tensor([0.5447, 0.7538, 0.6016, 0.0244], device='cuda:0')\n",
      "val_loss: 0.9500573621027999\n",
      "val_precision: tensor([0.5685, 0.7712, 0.5423, 0.6352], device='cuda:0')\n",
      "val_recall: tensor([0.4514, 0.5994, 0.8233, 0.0680], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "Early stopping at epoch 14 with best validation loss 0.9131732018457519\n",
      "training_checkpoints/vit_normalized_linear_patch2024-05-26 01:49:43.239177.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet50\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "from vit.vit import VisionTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'vit_normalized_linear_patch{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.6,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=4, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        wandb.log({'f1_score': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "        wandb.log({'f1_score_val': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = VisionTransformer(image_size=32, \n",
    "                          in_channels=3, \n",
    "                          num_classes=4, \n",
    "                          hidden_dims=[32], \n",
    "                          dropout_rate=0.5,\n",
    "                          embedding_dim=256,\n",
    "                          patch_size=4,\n",
    "                          num_layers=3,\n",
    "                          num_heads=4,\n",
    "                          use_linear_patch=True,\n",
    "                          use_conv_stem=False)\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2aac49f-4b3c-46f8-ae1f-3f7d56611c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41a41c-47a4-4e53-bd41-3cf2c6355e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
