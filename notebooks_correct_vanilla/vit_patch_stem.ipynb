{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38cb0334-c21c-4a04-a773-8ad02b61233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240526_025003-gpmsv7pc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/gpmsv7pc' target=\"_blank\">vit_normalized_stem_patch_config_convpatch_nopadding2024-05-26 02:50:02.552444</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/gpmsv7pc' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/gpmsv7pc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.973114908238252\n",
      "train_precision: tensor([0.5122, 0.6065, 0.5800, 0.6667], device='cuda:0')\n",
      "train_recall: tensor([4.5131e-01, 7.5590e-01, 5.6397e-01, 5.7720e-04], device='cuda:0')\n",
      "val_loss: 0.8887274243765407\n",
      "val_precision: tensor([0.5837, 0.6642, 0.6457, 0.9432], device='cuda:0')\n",
      "val_recall: tensor([0.5303, 0.7848, 0.6502, 0.0279], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  13.352598679000039\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.8944456860423088\n",
      "train_precision: tensor([0.5604, 0.6508, 0.6418, 0.5195], device='cuda:0')\n",
      "train_recall: tensor([0.5367, 0.7581, 0.6225, 0.0384], device='cuda:0')\n",
      "val_loss: 0.9023961505128277\n",
      "val_precision: tensor([0.6074, 0.7390, 0.5822, 0.7570], device='cuda:0')\n",
      "val_recall: tensor([0.4730, 0.6977, 0.7934, 0.1091], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  13.732142355999713\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.8707300401159696\n",
      "train_precision: tensor([0.5722, 0.6630, 0.6513, 0.5126], device='cuda:0')\n",
      "train_recall: tensor([0.5500, 0.7586, 0.6370, 0.0851], device='cuda:0')\n",
      "val_loss: 0.8309080054362615\n",
      "val_precision: tensor([0.6211, 0.6910, 0.6418, 0.7109], device='cuda:0')\n",
      "val_recall: tensor([0.5103, 0.7880, 0.7175, 0.1424], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  13.711028891999376\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.8506427500929151\n",
      "train_precision: tensor([0.5821, 0.6715, 0.6604, 0.5072], device='cuda:0')\n",
      "train_recall: tensor([0.5578, 0.7641, 0.6483, 0.1118], device='cuda:0')\n",
      "val_loss: 0.8716623762415515\n",
      "val_precision: tensor([0.6293, 0.7597, 0.5899, 0.5282], device='cuda:0')\n",
      "val_recall: tensor([0.4680, 0.7134, 0.8100, 0.2330], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  13.70544056000017\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.8372100296474638\n",
      "train_precision: tensor([0.5890, 0.6801, 0.6662, 0.5350], device='cuda:0')\n",
      "train_recall: tensor([0.5631, 0.7684, 0.6587, 0.1356], device='cuda:0')\n",
      "val_loss: 0.8498137524558438\n",
      "val_precision: tensor([0.5950, 0.7899, 0.5941, 0.6601], device='cuda:0')\n",
      "val_recall: tensor([0.5161, 0.6433, 0.8262, 0.1818], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  14.054639291000058\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.8254921460435504\n",
      "train_precision: tensor([0.5956, 0.6853, 0.6698, 0.5318], device='cuda:0')\n",
      "train_recall: tensor([0.5697, 0.7718, 0.6633, 0.1424], device='cuda:0')\n",
      "val_loss: 0.9332833968930774\n",
      "val_precision: tensor([0.6105, 0.7843, 0.5715, 0.3796], device='cuda:0')\n",
      "val_recall: tensor([0.4586, 0.6258, 0.8408, 0.3027], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  13.816054947999874\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.8148868364237604\n",
      "train_precision: tensor([0.6048, 0.6892, 0.6750, 0.5580], device='cuda:0')\n",
      "train_recall: tensor([0.5750, 0.7746, 0.6704, 0.1784], device='cuda:0')\n",
      "val_loss: 0.9346024677985244\n",
      "val_precision: tensor([0.5963, 0.7730, 0.5623, 0.6970], device='cuda:0')\n",
      "val_recall: tensor([0.4710, 0.6008, 0.8453, 0.2061], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  13.468690179000077\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.8061416779955228\n",
      "train_precision: tensor([0.6106, 0.6930, 0.6766, 0.5589], device='cuda:0')\n",
      "train_recall: tensor([0.5797, 0.7775, 0.6732, 0.1889], device='cuda:0')\n",
      "val_loss: 0.8016467556357384\n",
      "val_precision: tensor([0.6057, 0.7535, 0.6610, 0.5481], device='cuda:0')\n",
      "val_recall: tensor([0.5856, 0.7344, 0.7290, 0.3051], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  13.66909921899969\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.7956516341084525\n",
      "train_precision: tensor([0.6177, 0.6962, 0.6812, 0.5537], device='cuda:0')\n",
      "train_recall: tensor([0.5852, 0.7827, 0.6754, 0.2039], device='cuda:0')\n",
      "val_loss: 0.8058391880657938\n",
      "val_precision: tensor([0.6618, 0.7915, 0.6103, 0.4595], device='cuda:0')\n",
      "val_recall: tensor([0.4918, 0.7109, 0.8446, 0.3434], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  13.638299950000146\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.7893909075430461\n",
      "train_precision: tensor([0.6220, 0.6997, 0.6818, 0.5816], device='cuda:0')\n",
      "train_recall: tensor([0.5864, 0.7834, 0.6817, 0.2201], device='cuda:0')\n",
      "val_loss: 0.8253517006834348\n",
      "val_precision: tensor([0.6289, 0.8000, 0.6053, 0.6222], device='cuda:0')\n",
      "val_recall: tensor([0.5525, 0.6636, 0.8205, 0.2279], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  13.491366938000283\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.783571254994188\n",
      "train_precision: tensor([0.6268, 0.7020, 0.6864, 0.5752], device='cuda:0')\n",
      "train_recall: tensor([0.5916, 0.7858, 0.6845, 0.2278], device='cuda:0')\n",
      "val_loss: 0.7821892325248984\n",
      "val_precision: tensor([0.6353, 0.8146, 0.6279, 0.5787], device='cuda:0')\n",
      "val_recall: tensor([0.5800, 0.6630, 0.8259, 0.3354], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  13.065111390999846\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.7783712384246645\n",
      "train_precision: tensor([0.6291, 0.7055, 0.6879, 0.5745], device='cuda:0')\n",
      "train_recall: tensor([0.5943, 0.7872, 0.6869, 0.2348], device='cuda:0')\n",
      "val_loss: 0.784931953665283\n",
      "val_precision: tensor([0.6636, 0.7914, 0.6081, 0.6332], device='cuda:0')\n",
      "val_recall: tensor([0.5245, 0.7104, 0.8307, 0.2906], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  12.999098584999956\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.7725403416014853\n",
      "train_precision: tensor([0.6307, 0.7070, 0.6891, 0.5708], device='cuda:0')\n",
      "train_recall: tensor([0.5952, 0.7886, 0.6879, 0.2431], device='cuda:0')\n",
      "val_loss: 0.7459178706838026\n",
      "val_precision: tensor([0.6785, 0.7581, 0.6561, 0.5389], device='cuda:0')\n",
      "val_recall: tensor([0.5463, 0.7712, 0.7885, 0.4081], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  13.07548354499977\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.7691437487800916\n",
      "train_precision: tensor([0.6333, 0.7092, 0.6899, 0.5910], device='cuda:0')\n",
      "train_recall: tensor([0.5972, 0.7889, 0.6912, 0.2535], device='cuda:0')\n",
      "val_loss: 0.7534978859126568\n",
      "val_precision: tensor([0.6138, 0.7976, 0.6738, 0.6342], device='cuda:0')\n",
      "val_recall: tensor([0.6284, 0.7142, 0.7625, 0.3118], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 13 time:  13.108302896999703\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.7641333394107365\n",
      "train_precision: tensor([0.6374, 0.7113, 0.6945, 0.5979], device='cuda:0')\n",
      "train_recall: tensor([0.6025, 0.7919, 0.6923, 0.2670], device='cuda:0')\n",
      "val_loss: 0.7678935664395491\n",
      "val_precision: tensor([0.6374, 0.8076, 0.6449, 0.6374], device='cuda:0')\n",
      "val_recall: tensor([0.5967, 0.7022, 0.8029, 0.3148], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 14 time:  13.059229316999335\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.7613457678329377\n",
      "train_precision: tensor([0.6387, 0.7113, 0.6932, 0.5972], device='cuda:0')\n",
      "train_recall: tensor([0.5996, 0.7923, 0.6943, 0.2732], device='cuda:0')\n",
      "val_loss: 0.7590845334033172\n",
      "val_precision: tensor([0.6633, 0.7841, 0.6334, 0.6586], device='cuda:0')\n",
      "val_recall: tensor([0.5564, 0.7242, 0.8156, 0.3286], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 15 time:  13.077093420999518\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.7572373142554647\n",
      "train_precision: tensor([0.6423, 0.7134, 0.6960, 0.5986], device='cuda:0')\n",
      "train_recall: tensor([0.6053, 0.7929, 0.6960, 0.2755], device='cuda:0')\n",
      "val_loss: 0.8143999561667442\n",
      "val_precision: tensor([0.6083, 0.8208, 0.6245, 0.6660], device='cuda:0')\n",
      "val_recall: tensor([0.5851, 0.6636, 0.8086, 0.2330], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 16 time:  13.01097418900008\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.75497488734268\n",
      "train_precision: tensor([0.6444, 0.7154, 0.6958, 0.6037], device='cuda:0')\n",
      "train_recall: tensor([0.6072, 0.7951, 0.6956, 0.2814], device='cuda:0')\n",
      "val_loss: 0.7179410014715459\n",
      "val_precision: tensor([0.6483, 0.7785, 0.6955, 0.6017], device='cuda:0')\n",
      "val_recall: tensor([0.6191, 0.7754, 0.7474, 0.4471], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 17 time:  12.998835297000369\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.750601843212332\n",
      "train_precision: tensor([0.6440, 0.7174, 0.6984, 0.6166], device='cuda:0')\n",
      "train_recall: tensor([0.6080, 0.7944, 0.6991, 0.2941], device='cuda:0')\n",
      "val_loss: 0.7660015454722775\n",
      "val_precision: tensor([0.6469, 0.7963, 0.6484, 0.6041], device='cuda:0')\n",
      "val_recall: tensor([0.5705, 0.7250, 0.8063, 0.3869], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 18 time:  12.972489097000107\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.7490347322963533\n",
      "train_precision: tensor([0.6455, 0.7163, 0.6991, 0.6093], device='cuda:0')\n",
      "train_recall: tensor([0.6068, 0.7938, 0.7008, 0.2996], device='cuda:0')\n",
      "val_loss: 0.7475575025710794\n",
      "val_precision: tensor([0.6516, 0.8068, 0.6487, 0.6139], device='cuda:0')\n",
      "val_recall: tensor([0.5807, 0.7071, 0.8220, 0.4010], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 19 time:  12.94816133600034\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.7461232416686557\n",
      "train_precision: tensor([0.6456, 0.7191, 0.7009, 0.6087], device='cuda:0')\n",
      "train_recall: tensor([0.6114, 0.7941, 0.7009, 0.2957], device='cuda:0')\n",
      "val_loss: 0.7972599334186978\n",
      "val_precision: tensor([0.6590, 0.7987, 0.6084, 0.6316], device='cuda:0')\n",
      "val_recall: tensor([0.5285, 0.7062, 0.8296, 0.3175], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 20 time:  13.03311007100001\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.7440612718462944\n",
      "train_precision: tensor([0.6464, 0.7201, 0.7026, 0.6128], device='cuda:0')\n",
      "train_recall: tensor([0.6124, 0.7941, 0.7024, 0.3072], device='cuda:0')\n",
      "val_loss: 0.7247603735162153\n",
      "val_precision: tensor([0.6943, 0.7506, 0.6785, 0.5596], device='cuda:0')\n",
      "val_recall: tensor([0.5324, 0.8130, 0.7954, 0.4364], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 21 time:  13.027740896000068\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.7411055026309831\n",
      "train_precision: tensor([0.6471, 0.7215, 0.7017, 0.6150], device='cuda:0')\n",
      "train_recall: tensor([0.6116, 0.7952, 0.7029, 0.3128], device='cuda:0')\n",
      "val_loss: 0.8173028412792418\n",
      "val_precision: tensor([0.6557, 0.8337, 0.5939, 0.5648], device='cuda:0')\n",
      "val_recall: tensor([0.5308, 0.6433, 0.8584, 0.4152], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 22 time:  12.966768692999722\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.7183941537425631\n",
      "train_precision: tensor([0.6600, 0.7315, 0.7110, 0.6413], device='cuda:0')\n",
      "train_recall: tensor([0.6228, 0.8030, 0.7137, 0.3519], device='cuda:0')\n",
      "val_loss: 0.7209679996801748\n",
      "val_precision: tensor([0.6556, 0.8105, 0.6712, 0.6276], device='cuda:0')\n",
      "val_recall: tensor([0.6058, 0.7361, 0.8043, 0.4364], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 23 time:  13.0106747789996\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.7134090035444214\n",
      "train_precision: tensor([0.6623, 0.7337, 0.7153, 0.6300], device='cuda:0')\n",
      "train_recall: tensor([0.6279, 0.8027, 0.7171, 0.3494], device='cuda:0')\n",
      "val_loss: 0.7251315178970495\n",
      "val_precision: tensor([0.6505, 0.8123, 0.6746, 0.5836], device='cuda:0')\n",
      "val_recall: tensor([0.6112, 0.7314, 0.7944, 0.4805], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 24 time:  12.958522711000114\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.7123392110779172\n",
      "train_precision: tensor([0.6646, 0.7357, 0.7168, 0.6392], device='cuda:0')\n",
      "train_recall: tensor([0.6322, 0.8032, 0.7180, 0.3528], device='cuda:0')\n",
      "val_loss: 0.7301451058023506\n",
      "val_precision: tensor([0.6525, 0.8102, 0.6658, 0.6523], device='cuda:0')\n",
      "val_recall: tensor([0.5983, 0.7337, 0.8074, 0.4219], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 25 time:  12.968164717000036\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.7114551809572038\n",
      "train_precision: tensor([0.6627, 0.7340, 0.7156, 0.6451], device='cuda:0')\n",
      "train_recall: tensor([0.6277, 0.8018, 0.7189, 0.3599], device='cuda:0')\n",
      "val_loss: 0.7289978784819444\n",
      "val_precision: tensor([0.6465, 0.8219, 0.6671, 0.6192], device='cuda:0')\n",
      "val_recall: tensor([0.6219, 0.7112, 0.8006, 0.4495], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 26 time:  13.064261972999702\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.7113393334405763\n",
      "train_precision: tensor([0.6629, 0.7333, 0.7152, 0.6368], device='cuda:0')\n",
      "train_recall: tensor([0.6279, 0.8025, 0.7173, 0.3543], device='cuda:0')\n",
      "val_loss: 0.7264350681669183\n",
      "val_precision: tensor([0.6437, 0.8164, 0.6766, 0.6174], device='cuda:0')\n",
      "val_recall: tensor([0.6209, 0.7254, 0.7941, 0.4525], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "Early stopping at epoch 27 with best validation loss 0.7179410014715459\n",
      "training_checkpoints/vit_normalized_stem_patch_config_convpatch_nopadding2024-05-26 02:50:02.552444.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet50\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "from vit.vit import VisionTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'vit_normalized_stem_patch_config_convpatch_nopadding{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=4, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        wandb.log({'f1_score': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "        wandb.log({'f1_score_val': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = VisionTransformer(image_size=32, \n",
    "                          in_channels=3, \n",
    "                          num_classes=4, \n",
    "                          dropout_rate=0.5,\n",
    "                          embedding_dim=128,\n",
    "                          patch_size=4,\n",
    "                          num_layers=3,\n",
    "                          num_heads=2,\n",
    "                          use_linear_patch=False,\n",
    "                          use_conv_stem=False,\n",
    "                          use_conv_patch=True)\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47f2da1-42ab-4d45-b4c2-f13d3a70143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gpmsv7pc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Inflamatory precision</td><td>▁▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Inflamatory recall</td><td>▁▁▁▂▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>Normal precision</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Normal recall</td><td>▁▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Other precision</td><td>█▂▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▅▅▆▆▇▆▇▇▇</td></tr><tr><td>Other recall</td><td>▁▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Tumor precision</td><td>▁▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Tumor recall</td><td>▁▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>f1_score</td><td>▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>f1_score_val</td><td>▃▃▃▂▃▁▃▄▄▄▅▅▆▆▆▆▅█▇▇▆▇▆█████</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>main_metrics_precision</td><td>▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇█████</td></tr><tr><td>main_metrics_recall</td><td>▁▃▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>val_Inflamatory precision</td><td>▁▄▂▅▆▆▅▅▆▇▇▆▅▇▇▆▇▆▆▇▇▅█▇▇▇█▇</td></tr><tr><td>val_Inflamatory recall</td><td>▇▄▇▅▂▂▁▅▅▃▃▅▇▅▄▅▃▇▅▅▄█▂▅▅▅▅▅</td></tr><tr><td>val_Normal precision</td><td>▁▂▃▄▂▃▂▂▆▄▄▆▇▃▄▆▃▅▅▅▆█▆▆▅▅▅▅</td></tr><tr><td>val_Normal recall</td><td>▄▂▃▁▃▁▂▆▂▅▆▄▅█▇▅▆█▆▆▄▄▄▇▇▇██</td></tr><tr><td>val_Other precision</td><td>█▆▅▃▄▁▅▃▂▄▃▄▃▄▄▄▅▄▄▄▄▃▃▄▄▄▄▄</td></tr><tr><td>val_Other recall</td><td>▁▂▃▄▃▅▄▅▆▄▆▅▇▅▅▆▄▇▇▇▅▇▇▇█▇██</td></tr><tr><td>val_Tumor precision</td><td>▅▂▅▂▃▁▁▆▄▃▄▃▆▇▅▅▄█▆▆▃▇▃▇▇▆▇▇</td></tr><tr><td>val_Tumor recall</td><td>▁▆▃▆▇▇█▄█▇▇▇▆▅▆▇▆▄▆▇▇▆█▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>▇▇▅▆▅██▄▄▄▃▃▂▂▃▂▄▁▃▂▄▁▄▁▁▁▁▁</td></tr><tr><td>val_main_metrics_precision</td><td>█▆▆▃▅▁▅▄▄▅▅▆▅▆▆▇▆▆▆▆▆▆▅▇▆▇▇▇</td></tr><tr><td>val_main_metrics_recall</td><td>▁▂▃▄▃▄▂▅▅▄▆▅▇▆▆▆▄█▇▇▅█▆██▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Inflamatory precision</td><td>0.73333</td></tr><tr><td>Inflamatory recall</td><td>0.8025</td></tr><tr><td>Normal precision</td><td>0.66294</td></tr><tr><td>Normal recall</td><td>0.62791</td></tr><tr><td>Other precision</td><td>0.63684</td></tr><tr><td>Other recall</td><td>0.35426</td></tr><tr><td>Tumor precision</td><td>0.71521</td></tr><tr><td>Tumor recall</td><td>0.71729</td></tr><tr><td>f1_score</td><td>0.65628</td></tr><tr><td>f1_score_val</td><td>0.66837</td></tr><tr><td>loss</td><td>0.71134</td></tr><tr><td>main_metrics_precision</td><td>0.68708</td></tr><tr><td>main_metrics_recall</td><td>0.62549</td></tr><tr><td>val_Inflamatory precision</td><td>0.81642</td></tr><tr><td>val_Inflamatory recall</td><td>0.72535</td></tr><tr><td>val_Normal precision</td><td>0.64374</td></tr><tr><td>val_Normal recall</td><td>0.62088</td></tr><tr><td>val_Other precision</td><td>0.61736</td></tr><tr><td>val_Other recall</td><td>0.45253</td></tr><tr><td>val_Tumor precision</td><td>0.67657</td></tr><tr><td>val_Tumor recall</td><td>0.79414</td></tr><tr><td>val_loss</td><td>0.72644</td></tr><tr><td>val_main_metrics_precision</td><td>0.68853</td></tr><tr><td>val_main_metrics_recall</td><td>0.64822</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vit_normalized_stem_patch_config_convpatch_nopadding2024-05-26 02:50:02.552444</strong> at: <a href='https://wandb.ai/adamsoja/cells/runs/gpmsv7pc' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/gpmsv7pc</a><br/> View project at: <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240526_025003-gpmsv7pc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gpmsv7pc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240526_030740-vct8koag</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/vct8koag' target=\"_blank\">vit_normalized_stem_patch_config_stematch_nopadding2024-05-26 03:07:40.782701</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/vct8koag' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/vct8koag</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.947581824802217\n",
      "train_precision: tensor([0.5351, 0.6114, 0.6062, 0.7870], device='cuda:0')\n",
      "train_recall: tensor([0.4653, 0.7635, 0.5940, 0.0123], device='cuda:0')\n",
      "val_loss: 0.9560731190774175\n",
      "val_precision: tensor([0.5152, 0.8481, 0.5500, 0.8333], device='cuda:0')\n",
      "val_recall: tensor([0.5048, 0.4761, 0.8564, 0.0135], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  63.30921699099963\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.864716839151723\n",
      "train_precision: tensor([0.5784, 0.6704, 0.6584, 0.6061], device='cuda:0')\n",
      "train_recall: tensor([0.5487, 0.7706, 0.6549, 0.0429], device='cuda:0')\n",
      "val_loss: 0.8037727809614605\n",
      "val_precision: tensor([0.5924, 0.7604, 0.6551, 0.6750], device='cuda:0')\n",
      "val_recall: tensor([0.5903, 0.7155, 0.7458, 0.1636], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  63.21098707800047\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.8436780180249895\n",
      "train_precision: tensor([0.5877, 0.6815, 0.6672, 0.5957], device='cuda:0')\n",
      "train_recall: tensor([0.5572, 0.7763, 0.6669, 0.0795], device='cuda:0')\n",
      "val_loss: 0.7836993238992161\n",
      "val_precision: tensor([0.5923, 0.7765, 0.6707, 0.6382], device='cuda:0')\n",
      "val_recall: tensor([0.6113, 0.7167, 0.7459, 0.2091], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  63.20277005099979\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.8301773795769328\n",
      "train_precision: tensor([0.5932, 0.6885, 0.6706, 0.5660], device='cuda:0')\n",
      "train_recall: tensor([0.5613, 0.7778, 0.6727, 0.1188], device='cuda:0')\n",
      "val_loss: 0.7745601433846686\n",
      "val_precision: tensor([0.6247, 0.7324, 0.6790, 0.8797], device='cuda:0')\n",
      "val_recall: tensor([0.5822, 0.7771, 0.7394, 0.1576], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  63.182611971999904\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.8197677622238795\n",
      "train_precision: tensor([0.5992, 0.6935, 0.6748, 0.5733], device='cuda:0')\n",
      "train_recall: tensor([0.5677, 0.7815, 0.6756, 0.1411], device='cuda:0')\n",
      "val_loss: 0.7619710207813316\n",
      "val_precision: tensor([0.6172, 0.7783, 0.6732, 0.6489], device='cuda:0')\n",
      "val_recall: tensor([0.6170, 0.7308, 0.7495, 0.3111], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  63.333377382000435\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.8121312159867514\n",
      "train_precision: tensor([0.6041, 0.6967, 0.6771, 0.5623], device='cuda:0')\n",
      "train_recall: tensor([0.5720, 0.7802, 0.6798, 0.1641], device='cuda:0')\n",
      "val_loss: 0.8293791544106272\n",
      "val_precision: tensor([0.5722, 0.8502, 0.6074, 0.6744], device='cuda:0')\n",
      "val_recall: tensor([0.5940, 0.5755, 0.8165, 0.2741], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  63.08820349300004\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.8032683095052129\n",
      "train_precision: tensor([0.6080, 0.6987, 0.6819, 0.5731], device='cuda:0')\n",
      "train_recall: tensor([0.5775, 0.7837, 0.6797, 0.1811], device='cuda:0')\n",
      "val_loss: 0.7382289633154869\n",
      "val_precision: tensor([0.6204, 0.7701, 0.7012, 0.6232], device='cuda:0')\n",
      "val_recall: tensor([0.6247, 0.7728, 0.7266, 0.3313], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  63.05525349799973\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.7974161009703363\n",
      "train_precision: tensor([0.6131, 0.7040, 0.6831, 0.5736], device='cuda:0')\n",
      "train_recall: tensor([0.5809, 0.7857, 0.6843, 0.1997], device='cuda:0')\n",
      "val_loss: 0.7271189221077495\n",
      "val_precision: tensor([0.6573, 0.7456, 0.7048, 0.5245], device='cuda:0')\n",
      "val_recall: tensor([0.5799, 0.8037, 0.7448, 0.4354], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  62.985569241999656\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.7914898105320476\n",
      "train_precision: tensor([0.6151, 0.7058, 0.6829, 0.5775], device='cuda:0')\n",
      "train_recall: tensor([0.5788, 0.7868, 0.6888, 0.2055], device='cuda:0')\n",
      "val_loss: 0.7775478981435299\n",
      "val_precision: tensor([0.6426, 0.8378, 0.6104, 0.7139], device='cuda:0')\n",
      "val_recall: tensor([0.5747, 0.6584, 0.8412, 0.2983], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  62.99142390899942\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.7861627343864668\n",
      "train_precision: tensor([0.6182, 0.7094, 0.6863, 0.5841], device='cuda:0')\n",
      "train_recall: tensor([0.5862, 0.7868, 0.6900, 0.2170], device='cuda:0')\n",
      "val_loss: 0.7327063970267773\n",
      "val_precision: tensor([0.6637, 0.7922, 0.6574, 0.6290], device='cuda:0')\n",
      "val_recall: tensor([0.5772, 0.7476, 0.8081, 0.3603], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  63.028133212000284\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.7812431839250383\n",
      "train_precision: tensor([0.6213, 0.7112, 0.6871, 0.5887], device='cuda:0')\n",
      "train_recall: tensor([0.5861, 0.7874, 0.6946, 0.2270], device='cuda:0')\n",
      "val_loss: 0.719383433378405\n",
      "val_precision: tensor([0.6444, 0.7885, 0.6930, 0.5913], device='cuda:0')\n",
      "val_recall: tensor([0.6168, 0.7586, 0.7676, 0.4316], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  63.04109681299997\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.7754055733482043\n",
      "train_precision: tensor([0.6225, 0.7124, 0.6911, 0.5829], device='cuda:0')\n",
      "train_recall: tensor([0.5886, 0.7914, 0.6929, 0.2374], device='cuda:0')\n",
      "val_loss: 0.773623128897614\n",
      "val_precision: tensor([0.6481, 0.8029, 0.6109, 0.6914], device='cuda:0')\n",
      "val_recall: tensor([0.4873, 0.7229, 0.8561, 0.3199], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  62.9973857140003\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.7720432890313013\n",
      "train_precision: tensor([0.6280, 0.7154, 0.6898, 0.5886], device='cuda:0')\n",
      "train_recall: tensor([0.5921, 0.7907, 0.6970, 0.2440], device='cuda:0')\n",
      "val_loss: 0.7406018763780594\n",
      "val_precision: tensor([0.6919, 0.7902, 0.6380, 0.7583], device='cuda:0')\n",
      "val_recall: tensor([0.5417, 0.7549, 0.8422, 0.3158], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  62.98707376400034\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.7695483994625864\n",
      "train_precision: tensor([0.6268, 0.7150, 0.6927, 0.5949], device='cuda:0')\n",
      "train_recall: tensor([0.5935, 0.7901, 0.6973, 0.2469], device='cuda:0')\n",
      "val_loss: 0.7257784734169642\n",
      "val_precision: tensor([0.6352, 0.8100, 0.6820, 0.7162], device='cuda:0')\n",
      "val_recall: tensor([0.6317, 0.7278, 0.7892, 0.3569], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 13 time:  63.00700262999999\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.7653308793902397\n",
      "train_precision: tensor([0.6285, 0.7186, 0.6940, 0.5959], device='cuda:0')\n",
      "train_recall: tensor([0.5965, 0.7901, 0.7008, 0.2483], device='cuda:0')\n",
      "val_loss: 0.7448140598005719\n",
      "val_precision: tensor([0.6574, 0.8204, 0.6405, 0.6846], device='cuda:0')\n",
      "val_recall: tensor([0.5875, 0.7099, 0.8303, 0.3047], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 14 time:  63.029507927999475\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.7639023564401127\n",
      "train_precision: tensor([0.6292, 0.7174, 0.6917, 0.5962], device='cuda:0')\n",
      "train_recall: tensor([0.5942, 0.7920, 0.6972, 0.2603], device='cuda:0')\n",
      "val_loss: 0.7170235637161467\n",
      "val_precision: tensor([0.6504, 0.8064, 0.6733, 0.6926], device='cuda:0')\n",
      "val_recall: tensor([0.6024, 0.7399, 0.8080, 0.3892], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 15 time:  62.998554974999934\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.7583317063394047\n",
      "train_precision: tensor([0.6320, 0.7212, 0.6971, 0.6091], device='cuda:0')\n",
      "train_recall: tensor([0.5997, 0.7935, 0.7025, 0.2622], device='cuda:0')\n",
      "val_loss: 0.6938988114396731\n",
      "val_precision: tensor([0.6492, 0.7742, 0.7314, 0.6344], device='cuda:0')\n",
      "val_recall: tensor([0.6545, 0.8051, 0.7225, 0.4061], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 16 time:  62.98467099000027\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.7552959758610952\n",
      "train_precision: tensor([0.6340, 0.7230, 0.7005, 0.6029], device='cuda:0')\n",
      "train_recall: tensor([0.6053, 0.7950, 0.7014, 0.2681], device='cuda:0')\n",
      "val_loss: 0.7059385571214888\n",
      "val_precision: tensor([0.6210, 0.8251, 0.7133, 0.7972], device='cuda:0')\n",
      "val_recall: tensor([0.6905, 0.7239, 0.7628, 0.3296], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 17 time:  63.01118206499996\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.7529930823615619\n",
      "train_precision: tensor([0.6329, 0.7233, 0.7003, 0.5946], device='cuda:0')\n",
      "train_recall: tensor([0.6051, 0.7929, 0.7019, 0.2698], device='cuda:0')\n",
      "val_loss: 0.6869809018241034\n",
      "val_precision: tensor([0.6641, 0.7631, 0.7280, 0.6673], device='cuda:0')\n",
      "val_recall: tensor([0.6362, 0.8193, 0.7393, 0.3519], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 18 time:  63.00911026999984\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.7499058192684537\n",
      "train_precision: tensor([0.6374, 0.7252, 0.7029, 0.6059], device='cuda:0')\n",
      "train_recall: tensor([0.6090, 0.7955, 0.7036, 0.2828], device='cuda:0')\n",
      "val_loss: 0.7085385373897023\n",
      "val_precision: tensor([0.6716, 0.8155, 0.6666, 0.7876], device='cuda:0')\n",
      "val_recall: tensor([0.6146, 0.7519, 0.8169, 0.2946], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 19 time:  63.02039026700004\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.7477039948815392\n",
      "train_precision: tensor([0.6390, 0.7253, 0.7016, 0.6009], device='cuda:0')\n",
      "train_recall: tensor([0.6053, 0.7966, 0.7074, 0.2785], device='cuda:0')\n",
      "val_loss: 0.7325661525130271\n",
      "val_precision: tensor([0.6471, 0.8456, 0.6547, 0.8150], device='cuda:0')\n",
      "val_recall: tensor([0.6355, 0.6961, 0.8251, 0.2818], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 20 time:  63.02274754299924\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.7437185510283425\n",
      "train_precision: tensor([0.6412, 0.7266, 0.7032, 0.5994], device='cuda:0')\n",
      "train_recall: tensor([0.6103, 0.7962, 0.7069, 0.2818], device='cuda:0')\n",
      "val_loss: 0.7022980976435873\n",
      "val_precision: tensor([0.6631, 0.8217, 0.6773, 0.7313], device='cuda:0')\n",
      "val_recall: tensor([0.6218, 0.7458, 0.8181, 0.3418], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 21 time:  62.96761160400001\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.741609799010413\n",
      "train_precision: tensor([0.6411, 0.7276, 0.7042, 0.6016], device='cuda:0')\n",
      "train_recall: tensor([0.6116, 0.7966, 0.7056, 0.2957], device='cuda:0')\n",
      "val_loss: 0.6814768811066946\n",
      "val_precision: tensor([0.6245, 0.8151, 0.7382, 0.7941], device='cuda:0')\n",
      "val_recall: tensor([0.7078, 0.7577, 0.7361, 0.3168], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 22 time:  63.03429282699926\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.738868870408762\n",
      "train_precision: tensor([0.6438, 0.7294, 0.7070, 0.6059], device='cuda:0')\n",
      "train_recall: tensor([0.6122, 0.7995, 0.7095, 0.2988], device='cuda:0')\n",
      "val_loss: 0.6946949642565515\n",
      "val_precision: tensor([0.6781, 0.7611, 0.7047, 0.7713], device='cuda:0')\n",
      "val_recall: tensor([0.6006, 0.8089, 0.7805, 0.3384], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 23 time:  63.02315727199948\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.735263858238856\n",
      "train_precision: tensor([0.6442, 0.7306, 0.7067, 0.6088], device='cuda:0')\n",
      "train_recall: tensor([0.6132, 0.7987, 0.7100, 0.3052], device='cuda:0')\n",
      "val_loss: 0.6867653256489171\n",
      "val_precision: tensor([0.6683, 0.7971, 0.7095, 0.7138], device='cuda:0')\n",
      "val_recall: tensor([0.6550, 0.7805, 0.7738, 0.3569], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 24 time:  63.012998477999645\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.7337864272651218\n",
      "train_precision: tensor([0.6479, 0.7330, 0.7063, 0.6128], device='cuda:0')\n",
      "train_recall: tensor([0.6170, 0.7984, 0.7121, 0.3084], device='cuda:0')\n",
      "val_loss: 0.6762803150547876\n",
      "val_precision: tensor([0.6648, 0.7833, 0.7348, 0.8333], device='cuda:0')\n",
      "val_recall: tensor([0.6687, 0.8027, 0.7616, 0.2744], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 25 time:  63.04657433400007\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.7313840084132694\n",
      "train_precision: tensor([0.6467, 0.7312, 0.7096, 0.6127], device='cuda:0')\n",
      "train_recall: tensor([0.6156, 0.8005, 0.7121, 0.3052], device='cuda:0')\n",
      "val_loss: 0.6891487339304553\n",
      "val_precision: tensor([0.6622, 0.8225, 0.6904, 0.7665], device='cuda:0')\n",
      "val_recall: tensor([0.6369, 0.7502, 0.8151, 0.3481], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 26 time:  63.04980939699999\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.7280903033557392\n",
      "train_precision: tensor([0.6466, 0.7339, 0.7089, 0.6185], device='cuda:0')\n",
      "train_recall: tensor([0.6171, 0.7984, 0.7137, 0.3160], device='cuda:0')\n",
      "val_loss: 0.6989688352578216\n",
      "val_precision: tensor([0.7305, 0.7832, 0.6634, 0.6126], device='cuda:0')\n",
      "val_recall: tensor([0.5428, 0.7990, 0.8408, 0.4249], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 27 time:  62.99036345799959\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.7280844370524089\n",
      "train_precision: tensor([0.6480, 0.7331, 0.7099, 0.6120], device='cuda:0')\n",
      "train_recall: tensor([0.6182, 0.7998, 0.7118, 0.3198], device='cuda:0')\n",
      "val_loss: 0.6764048284126652\n",
      "val_precision: tensor([0.6527, 0.8079, 0.7254, 0.7247], device='cuda:0')\n",
      "val_recall: tensor([0.6700, 0.7717, 0.7699, 0.4121], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 28 time:  63.00520520899954\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.7254340922548658\n",
      "train_precision: tensor([0.6498, 0.7351, 0.7123, 0.6199], device='cuda:0')\n",
      "train_recall: tensor([0.6225, 0.8010, 0.7123, 0.3235], device='cuda:0')\n",
      "val_loss: 0.6706223514344957\n",
      "val_precision: tensor([0.6732, 0.7911, 0.7234, 0.7065], device='cuda:0')\n",
      "val_recall: tensor([0.6453, 0.8010, 0.7744, 0.4141], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 29 time:  63.01756839900008\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.722879752942494\n",
      "train_precision: tensor([0.6499, 0.7370, 0.7101, 0.6204], device='cuda:0')\n",
      "train_recall: tensor([0.6233, 0.8006, 0.7121, 0.3212], device='cuda:0')\n",
      "val_loss: 0.684482190426853\n",
      "val_precision: tensor([0.6623, 0.8314, 0.6901, 0.7775], device='cuda:0')\n",
      "val_recall: tensor([0.6388, 0.7440, 0.8232, 0.3694], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 30 time:  63.022134402999654\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 0.72090932762339\n",
      "train_precision: tensor([0.6536, 0.7375, 0.7134, 0.6220], device='cuda:0')\n",
      "train_recall: tensor([0.6240, 0.8026, 0.7159, 0.3333], device='cuda:0')\n",
      "val_loss: 0.6911969808240731\n",
      "val_precision: tensor([0.6590, 0.8295, 0.6982, 0.7575], device='cuda:0')\n",
      "val_recall: tensor([0.6541, 0.7440, 0.8096, 0.3848], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 31 time:  63.03838841600009\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 0.7190337434411049\n",
      "train_precision: tensor([0.6543, 0.7366, 0.7133, 0.6278], device='cuda:0')\n",
      "train_recall: tensor([0.6234, 0.8014, 0.7163, 0.3449], device='cuda:0')\n",
      "val_loss: 0.7030852919651402\n",
      "val_precision: tensor([0.6958, 0.8325, 0.6575, 0.7469], device='cuda:0')\n",
      "val_recall: tensor([0.5959, 0.7450, 0.8529, 0.3855], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 32 time:  63.04562701000032\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 0.7159783154016449\n",
      "train_precision: tensor([0.6563, 0.7392, 0.7149, 0.6217], device='cuda:0')\n",
      "train_recall: tensor([0.6276, 0.8042, 0.7167, 0.3302], device='cuda:0')\n",
      "val_loss: 0.7143983494076463\n",
      "val_precision: tensor([0.6101, 0.8673, 0.7170, 0.8087], device='cuda:0')\n",
      "val_recall: tensor([0.7506, 0.6606, 0.7630, 0.3559], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 33 time:  63.075956730000144\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 34\n",
      "train_loss: 0.7144488052952858\n",
      "train_precision: tensor([0.6564, 0.7397, 0.7170, 0.6210], device='cuda:0')\n",
      "train_recall: tensor([0.6278, 0.8034, 0.7191, 0.3377], device='cuda:0')\n",
      "val_loss: 0.6735541607770655\n",
      "val_precision: tensor([0.6902, 0.8132, 0.7015, 0.7458], device='cuda:0')\n",
      "val_recall: tensor([0.6305, 0.7878, 0.8178, 0.3872], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 34 time:  63.00999682499969\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 35\n",
      "train_loss: 0.6915862832041014\n",
      "train_precision: tensor([0.6681, 0.7494, 0.7252, 0.6568], device='cuda:0')\n",
      "train_recall: tensor([0.6403, 0.8107, 0.7278, 0.3678], device='cuda:0')\n",
      "val_loss: 0.6567125615146425\n",
      "val_precision: tensor([0.6805, 0.8363, 0.7134, 0.7323], device='cuda:0')\n",
      "val_recall: tensor([0.6762, 0.7595, 0.8111, 0.4485], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 35 time:  63.01796528799969\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 36\n",
      "train_loss: 0.6864816052573067\n",
      "train_precision: tensor([0.6692, 0.7525, 0.7252, 0.6571], device='cuda:0')\n",
      "train_recall: tensor([0.6418, 0.8101, 0.7295, 0.3854], device='cuda:0')\n",
      "val_loss: 0.6621796859635247\n",
      "val_precision: tensor([0.6937, 0.8266, 0.7002, 0.7353], device='cuda:0')\n",
      "val_recall: tensor([0.6456, 0.7680, 0.8250, 0.4545], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 36 time:  63.05044721400009\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 37\n",
      "train_loss: 0.6843948047075953\n",
      "train_precision: tensor([0.6733, 0.7540, 0.7279, 0.6550], device='cuda:0')\n",
      "train_recall: tensor([0.6433, 0.8123, 0.7335, 0.3905], device='cuda:0')\n",
      "val_loss: 0.6606636266741488\n",
      "val_precision: tensor([0.6693, 0.8331, 0.7243, 0.7574], device='cuda:0')\n",
      "val_recall: tensor([0.6938, 0.7592, 0.7932, 0.4320], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 37 time:  62.99490836099994\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 38\n",
      "train_loss: 0.6839924709427925\n",
      "train_precision: tensor([0.6710, 0.7535, 0.7277, 0.6538], device='cuda:0')\n",
      "train_recall: tensor([0.6433, 0.8116, 0.7309, 0.3905], device='cuda:0')\n",
      "val_loss: 0.6549647107720376\n",
      "val_precision: tensor([0.6941, 0.8234, 0.7102, 0.7206], device='cuda:0')\n",
      "val_recall: tensor([0.6485, 0.7786, 0.8214, 0.4576], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 38 time:  63.04484769299961\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 39\n",
      "train_loss: 0.6824746041780426\n",
      "train_precision: tensor([0.6741, 0.7547, 0.7295, 0.6531], device='cuda:0')\n",
      "train_recall: tensor([0.6453, 0.8121, 0.7350, 0.3860], device='cuda:0')\n",
      "val_loss: 0.6650632869038317\n",
      "val_precision: tensor([0.6897, 0.8354, 0.7010, 0.7035], device='cuda:0')\n",
      "val_recall: tensor([0.6531, 0.7583, 0.8251, 0.4818], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 39 time:  63.06735083899912\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 40\n",
      "train_loss: 0.681812347471714\n",
      "train_precision: tensor([0.6731, 0.7537, 0.7288, 0.6610], device='cuda:0')\n",
      "train_recall: tensor([0.6459, 0.8126, 0.7307, 0.3952], device='cuda:0')\n",
      "val_loss: 0.6611790230704678\n",
      "val_precision: tensor([0.6775, 0.8432, 0.7065, 0.7359], device='cuda:0')\n",
      "val_recall: tensor([0.6751, 0.7466, 0.8171, 0.4522], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 40 time:  63.059960159000184\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 41\n",
      "train_loss: 0.6804405775808152\n",
      "train_precision: tensor([0.6743, 0.7534, 0.7302, 0.6520], device='cuda:0')\n",
      "train_recall: tensor([0.6464, 0.8118, 0.7328, 0.3926], device='cuda:0')\n",
      "val_loss: 0.6529944445523951\n",
      "val_precision: tensor([0.6786, 0.8292, 0.7270, 0.7217], device='cuda:0')\n",
      "val_recall: tensor([0.6870, 0.7703, 0.7947, 0.4724], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 41 time:  63.001823608999985\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 42\n",
      "train_loss: 0.6797241704094977\n",
      "train_precision: tensor([0.6732, 0.7546, 0.7283, 0.6526], device='cuda:0')\n",
      "train_recall: tensor([0.6451, 0.8126, 0.7322, 0.3882], device='cuda:0')\n",
      "val_loss: 0.6542651605274942\n",
      "val_precision: tensor([0.6882, 0.8297, 0.7121, 0.7344], device='cuda:0')\n",
      "val_recall: tensor([0.6688, 0.7699, 0.8105, 0.4562], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 42 time:  63.04702674799955\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 43\n",
      "train_loss: 0.6783414573896499\n",
      "train_precision: tensor([0.6744, 0.7560, 0.7324, 0.6519], device='cuda:0')\n",
      "train_recall: tensor([0.6492, 0.8132, 0.7335, 0.3926], device='cuda:0')\n",
      "val_loss: 0.668309326055977\n",
      "val_precision: tensor([0.6880, 0.8358, 0.7004, 0.7169], device='cuda:0')\n",
      "val_recall: tensor([0.6614, 0.7525, 0.8219, 0.4646], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 43 time:  63.030118693000986\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 44\n",
      "train_loss: 0.6786502467024894\n",
      "train_precision: tensor([0.6739, 0.7540, 0.7306, 0.6546], device='cuda:0')\n",
      "train_recall: tensor([0.6463, 0.8118, 0.7325, 0.4036], device='cuda:0')\n",
      "val_loss: 0.6572408623165554\n",
      "val_precision: tensor([0.6956, 0.8258, 0.7089, 0.7700], device='cuda:0')\n",
      "val_recall: tensor([0.6558, 0.7803, 0.8208, 0.4205], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 44 time:  62.98898915599966\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 45\n",
      "train_loss: 0.6790172325003715\n",
      "train_precision: tensor([0.6732, 0.7557, 0.7305, 0.6536], device='cuda:0')\n",
      "train_recall: tensor([0.6474, 0.8122, 0.7330, 0.3926], device='cuda:0')\n",
      "val_loss: 0.6495661931733291\n",
      "val_precision: tensor([0.6954, 0.8215, 0.7175, 0.6938], device='cuda:0')\n",
      "val_recall: tensor([0.6546, 0.7851, 0.8113, 0.5020], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 45 time:  63.03060552399984\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 46\n",
      "train_loss: 0.6777314941797937\n",
      "train_precision: tensor([0.6741, 0.7567, 0.7317, 0.6563], device='cuda:0')\n",
      "train_recall: tensor([0.6475, 0.8145, 0.7331, 0.4017], device='cuda:0')\n",
      "val_loss: 0.6480196849339538\n",
      "val_precision: tensor([0.6925, 0.8325, 0.7141, 0.6897], device='cuda:0')\n",
      "val_recall: tensor([0.6672, 0.7703, 0.8119, 0.5118], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 46 time:  63.06108916299854\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 47\n",
      "train_loss: 0.6775156706571579\n",
      "train_precision: tensor([0.6738, 0.7555, 0.7315, 0.6506], device='cuda:0')\n",
      "train_recall: tensor([0.6468, 0.8142, 0.7324, 0.3977], device='cuda:0')\n",
      "val_loss: 0.6470167162517707\n",
      "val_precision: tensor([0.6869, 0.8269, 0.7240, 0.6749], device='cuda:0')\n",
      "val_recall: tensor([0.6724, 0.7746, 0.8021, 0.5158], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 47 time:  63.032306556999174\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 48\n",
      "train_loss: 0.6770771830564454\n",
      "train_precision: tensor([0.6754, 0.7550, 0.7323, 0.6645], device='cuda:0')\n",
      "train_recall: tensor([0.6483, 0.8119, 0.7345, 0.4113], device='cuda:0')\n",
      "val_loss: 0.6733121426569091\n",
      "val_precision: tensor([0.6752, 0.8448, 0.7038, 0.7152], device='cuda:0')\n",
      "val_recall: tensor([0.6736, 0.7404, 0.8164, 0.4727], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 48 time:  63.03063024200128\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 49\n",
      "train_loss: 0.675127378318991\n",
      "train_precision: tensor([0.6737, 0.7551, 0.7335, 0.6546], device='cuda:0')\n",
      "train_recall: tensor([0.6477, 0.8130, 0.7336, 0.4051], device='cuda:0')\n",
      "val_loss: 0.6559300741387738\n",
      "val_precision: tensor([0.6937, 0.8288, 0.7056, 0.7111], device='cuda:0')\n",
      "val_recall: tensor([0.6530, 0.7716, 0.8186, 0.4798], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 49 time:  63.03274066599988\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 50\n",
      "train_loss: 0.6759186288430578\n",
      "train_precision: tensor([0.6772, 0.7563, 0.7303, 0.6535], device='cuda:0')\n",
      "train_recall: tensor([0.6477, 0.8139, 0.7345, 0.4039], device='cuda:0')\n",
      "val_loss: 0.651505199737019\n",
      "val_precision: tensor([0.6970, 0.8310, 0.7117, 0.6900], device='cuda:0')\n",
      "val_recall: tensor([0.6611, 0.7724, 0.8174, 0.5074], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 50 time:  63.024822252999\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 51\n",
      "train_loss: 0.6744222904954638\n",
      "train_precision: tensor([0.6761, 0.7576, 0.7330, 0.6561], device='cuda:0')\n",
      "train_recall: tensor([0.6492, 0.8135, 0.7361, 0.4048], device='cuda:0')\n",
      "val_loss: 0.6540003387464417\n",
      "val_precision: tensor([0.6918, 0.8216, 0.7166, 0.7194], device='cuda:0')\n",
      "val_recall: tensor([0.6587, 0.7806, 0.8104, 0.4808], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 51 time:  63.04087252700083\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 52\n",
      "train_loss: 0.6752873326341311\n",
      "train_precision: tensor([0.6754, 0.7561, 0.7323, 0.6564], device='cuda:0')\n",
      "train_recall: tensor([0.6503, 0.8120, 0.7329, 0.4091], device='cuda:0')\n",
      "val_loss: 0.6535088962978787\n",
      "val_precision: tensor([0.6975, 0.8279, 0.7061, 0.7134], device='cuda:0')\n",
      "val_recall: tensor([0.6505, 0.7764, 0.8204, 0.4828], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 52 time:  63.044179586999235\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 53\n",
      "train_loss: 0.6707046016341164\n",
      "train_precision: tensor([0.6786, 0.7575, 0.7333, 0.6608], device='cuda:0')\n",
      "train_recall: tensor([0.6492, 0.8149, 0.7375, 0.4088], device='cuda:0')\n",
      "val_loss: 0.6544944489167797\n",
      "val_precision: tensor([0.6952, 0.8297, 0.7072, 0.7103], device='cuda:0')\n",
      "val_recall: tensor([0.6578, 0.7695, 0.8196, 0.4788], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 53 time:  63.01771437400021\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 54\n",
      "train_loss: 0.6714840495160648\n",
      "train_precision: tensor([0.6780, 0.7576, 0.7349, 0.6522], device='cuda:0')\n",
      "train_recall: tensor([0.6511, 0.8134, 0.7377, 0.4051], device='cuda:0')\n",
      "val_loss: 0.653738294955757\n",
      "val_precision: tensor([0.6967, 0.8290, 0.7093, 0.7124], device='cuda:0')\n",
      "val_recall: tensor([0.6588, 0.7739, 0.8177, 0.4845], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 54 time:  63.0170872689996\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 55\n",
      "train_loss: 0.6704754699553762\n",
      "train_precision: tensor([0.6770, 0.7585, 0.7317, 0.6645], device='cuda:0')\n",
      "train_recall: tensor([0.6481, 0.8143, 0.7367, 0.4136], device='cuda:0')\n",
      "val_loss: 0.6603849943313334\n",
      "val_precision: tensor([0.6983, 0.8290, 0.7012, 0.7186], device='cuda:0')\n",
      "val_recall: tensor([0.6483, 0.7705, 0.8254, 0.4677], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 55 time:  63.05264240299948\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 56\n",
      "train_loss: 0.6697725679902803\n",
      "train_precision: tensor([0.6788, 0.7593, 0.7361, 0.6692], device='cuda:0')\n",
      "train_recall: tensor([0.6542, 0.8143, 0.7369, 0.4201], device='cuda:0')\n",
      "val_loss: 0.6581385717623763\n",
      "val_precision: tensor([0.6966, 0.8298, 0.7030, 0.7144], device='cuda:0')\n",
      "val_recall: tensor([0.6527, 0.7685, 0.8228, 0.4751], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 56 time:  62.9983417429994\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 57\n",
      "train_loss: 0.6690974316426685\n",
      "train_precision: tensor([0.6777, 0.7588, 0.7321, 0.6583], device='cuda:0')\n",
      "train_recall: tensor([0.6491, 0.8156, 0.7361, 0.4087], device='cuda:0')\n",
      "val_loss: 0.6586099675132169\n",
      "val_precision: tensor([0.6912, 0.8334, 0.7063, 0.7185], device='cuda:0')\n",
      "val_recall: tensor([0.6610, 0.7639, 0.8197, 0.4778], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "Early stopping at epoch 57 with best validation loss 0.6470167162517707\n",
      "training_checkpoints/vit_normalized_stem_patch_config_stematch_nopadding2024-05-26 03:07:40.782701.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet50\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "from vit.vit import VisionTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'vit_normalized_stem_patch_config_stematch_nopadding{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=4, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        wandb.log({'f1_score': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "        wandb.log({'f1_score_val': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = VisionTransformer(image_size=32, \n",
    "                          in_channels=3, \n",
    "                          num_classes=4, \n",
    "                          dropout_rate=0.5,\n",
    "                          embedding_dim=128,\n",
    "                          patch_size=8,\n",
    "                          num_layers=3,\n",
    "                          num_heads=2,\n",
    "                          use_linear_patch=False,\n",
    "                          use_conv_stem=True,\n",
    "                          hidden_dims = [32, 32],\n",
    "                          use_conv_patch=False)\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d0539-78b8-43e3-848b-9c49d3de9a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
