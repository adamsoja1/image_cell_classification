{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb942526-371e-41ed-bb89-a69172fe56e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240425_003300-lf1b9fu0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/lf1b9fu0' target=\"_blank\">efficient_netb0_normalize_batch_2048_test2024-04-25 00:32:59.640440</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/lf1b9fu0' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/lf1b9fu0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 1.103253522373381\n",
      "train_precision: tensor([0.4450, 0.5485, 0.4844, 0.0432], device='cuda:0')\n",
      "train_recall: tensor([0.3927, 0.6359, 0.5053, 0.0065], device='cuda:0')\n",
      "val_loss: 0.951799914571974\n",
      "val_precision: tensor([0.5204, 0.6891, 0.5828, 0.1366], device='cuda:0')\n",
      "val_recall: tensor([0.4838, 0.7113, 0.6489, 0.0337], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  21.454394700000194\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.9514361864044553\n",
      "train_precision: tensor([0.5335, 0.6327, 0.6101, 0.1637], device='cuda:0')\n",
      "train_recall: tensor([0.5104, 0.7345, 0.5974, 0.0053], device='cuda:0')\n",
      "val_loss: 0.8729834463861254\n",
      "val_precision: tensor([0.5641, 0.7100, 0.6330, 0.4355], device='cuda:0')\n",
      "val_recall: tensor([0.5600, 0.7321, 0.6733, 0.0545], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  22.00403084899881\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.9119221829232715\n",
      "train_precision: tensor([0.5546, 0.6536, 0.6311, 0.3154], device='cuda:0')\n",
      "train_recall: tensor([0.5379, 0.7431, 0.6246, 0.0110], device='cuda:0')\n",
      "val_loss: 0.8441760275099013\n",
      "val_precision: tensor([0.6123, 0.6945, 0.6264, 0.5110], device='cuda:0')\n",
      "val_recall: tensor([0.4791, 0.7755, 0.7437, 0.0704], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  22.062649149998833\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.8855509349278041\n",
      "train_precision: tensor([0.5692, 0.6646, 0.6454, 0.4169], device='cuda:0')\n",
      "train_recall: tensor([0.5517, 0.7529, 0.6400, 0.0264], device='cuda:0')\n",
      "val_loss: 0.8241217586729261\n",
      "val_precision: tensor([0.5957, 0.7286, 0.6488, 0.6224], device='cuda:0')\n",
      "val_recall: tensor([0.5777, 0.7480, 0.7086, 0.0710], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  21.884077315999093\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.8650041881061735\n",
      "train_precision: tensor([0.5789, 0.6732, 0.6546, 0.5111], device='cuda:0')\n",
      "train_recall: tensor([0.5605, 0.7623, 0.6475, 0.0531], device='cuda:0')\n",
      "val_loss: 0.801084988647037\n",
      "val_precision: tensor([0.6124, 0.7401, 0.6535, 0.7012], device='cuda:0')\n",
      "val_recall: tensor([0.5934, 0.7483, 0.7212, 0.1138], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  22.138665555001353\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.8465853106407892\n",
      "train_precision: tensor([0.5874, 0.6812, 0.6625, 0.5085], device='cuda:0')\n",
      "train_recall: tensor([0.5710, 0.7647, 0.6559, 0.0781], device='cuda:0')\n",
      "val_loss: 0.7922790063752069\n",
      "val_precision: tensor([0.6242, 0.7515, 0.6428, 0.6026], device='cuda:0')\n",
      "val_recall: tensor([0.5807, 0.7360, 0.7486, 0.1552], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  22.560090375000073\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.834809468473707\n",
      "train_precision: tensor([0.5965, 0.6874, 0.6635, 0.5101], device='cuda:0')\n",
      "train_recall: tensor([0.5751, 0.7696, 0.6616, 0.0981], device='cuda:0')\n",
      "val_loss: 0.7666626095771789\n",
      "val_precision: tensor([0.6345, 0.7360, 0.6759, 0.5811], device='cuda:0')\n",
      "val_recall: tensor([0.5785, 0.7875, 0.7306, 0.2172], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  22.753615958999944\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.8238351958138602\n",
      "train_precision: tensor([0.6014, 0.6919, 0.6693, 0.5208], device='cuda:0')\n",
      "train_recall: tensor([0.5754, 0.7756, 0.6684, 0.1231], device='cuda:0')\n",
      "val_loss: 0.7550410800509982\n",
      "val_precision: tensor([0.6462, 0.7434, 0.6702, 0.5811], device='cuda:0')\n",
      "val_recall: tensor([0.5708, 0.7816, 0.7500, 0.2690], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  22.712849033001476\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.8115276796477181\n",
      "train_precision: tensor([0.6102, 0.6955, 0.6733, 0.5440], device='cuda:0')\n",
      "train_recall: tensor([0.5802, 0.7813, 0.6720, 0.1517], device='cuda:0')\n",
      "val_loss: 0.7471770617696974\n",
      "val_precision: tensor([0.6570, 0.7303, 0.6738, 0.6201], device='cuda:0')\n",
      "val_recall: tensor([0.5532, 0.8027, 0.7554, 0.2347], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  22.781520169999567\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.8043158559572129\n",
      "train_precision: tensor([0.6152, 0.7008, 0.6728, 0.5359], device='cuda:0')\n",
      "train_recall: tensor([0.5849, 0.7782, 0.6786, 0.1616], device='cuda:0')\n",
      "val_loss: 0.7431974371274312\n",
      "val_precision: tensor([0.6484, 0.7322, 0.6972, 0.5923], device='cuda:0')\n",
      "val_recall: tensor([0.5920, 0.8101, 0.7229, 0.2593], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  22.423169723000683\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.7951269376845587\n",
      "train_precision: tensor([0.6192, 0.7030, 0.6804, 0.5390], device='cuda:0')\n",
      "train_recall: tensor([0.5901, 0.7824, 0.6801, 0.1866], device='cuda:0')\n",
      "val_loss: 0.725560720761617\n",
      "val_precision: tensor([0.6640, 0.7410, 0.6964, 0.5985], device='cuda:0')\n",
      "val_recall: tensor([0.5877, 0.8123, 0.7448, 0.2936], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  22.649765676000243\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.7884434756778536\n",
      "train_precision: tensor([0.6224, 0.7060, 0.6802, 0.5467], device='cuda:0')\n",
      "train_recall: tensor([0.5914, 0.7844, 0.6825, 0.1941], device='cuda:0')\n",
      "val_loss: 0.7247574581040277\n",
      "val_precision: tensor([0.6581, 0.7627, 0.6888, 0.5748], device='cuda:0')\n",
      "val_recall: tensor([0.6096, 0.7805, 0.7496, 0.3569], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  22.664082192999558\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.7798975672040667\n",
      "train_precision: tensor([0.6293, 0.7098, 0.6848, 0.5545], device='cuda:0')\n",
      "train_recall: tensor([0.5961, 0.7879, 0.6887, 0.2049], device='cuda:0')\n",
      "val_loss: 0.7284927162859175\n",
      "val_precision: tensor([0.6890, 0.7642, 0.6493, 0.7354], device='cuda:0')\n",
      "val_recall: tensor([0.5364, 0.7864, 0.8170, 0.2508], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  22.305079854000724\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.7765074707212902\n",
      "train_precision: tensor([0.6282, 0.7099, 0.6866, 0.5725], device='cuda:0')\n",
      "train_recall: tensor([0.5978, 0.7891, 0.6849, 0.2255], device='cuda:0')\n",
      "val_loss: 0.7126383238368564\n",
      "val_precision: tensor([0.6531, 0.7875, 0.6858, 0.6212], device='cuda:0')\n",
      "val_recall: tensor([0.6105, 0.7602, 0.7820, 0.3710], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 13 time:  22.525706512000397\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.768388793582008\n",
      "train_precision: tensor([0.6338, 0.7150, 0.6896, 0.5642], device='cuda:0')\n",
      "train_recall: tensor([0.6036, 0.7880, 0.6930, 0.2294], device='cuda:0')\n",
      "val_loss: 0.6995501187112596\n",
      "val_precision: tensor([0.6533, 0.7646, 0.7200, 0.6921], device='cuda:0')\n",
      "val_recall: tensor([0.6535, 0.7934, 0.7310, 0.3239], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 14 time:  22.56321761399886\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.7636816416467939\n",
      "train_precision: tensor([0.6361, 0.7151, 0.6913, 0.5836], device='cuda:0')\n",
      "train_recall: tensor([0.6051, 0.7900, 0.6927, 0.2453], device='cuda:0')\n",
      "val_loss: 0.6989067693551382\n",
      "val_precision: tensor([0.6887, 0.7441, 0.7062, 0.6115], device='cuda:0')\n",
      "val_recall: tensor([0.5902, 0.8275, 0.7607, 0.3286], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 15 time:  22.623062761000256\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.7576742217654273\n",
      "train_precision: tensor([0.6374, 0.7192, 0.6963, 0.5818], device='cuda:0')\n",
      "train_recall: tensor([0.6090, 0.7931, 0.6956, 0.2488], device='cuda:0')\n",
      "val_loss: 0.7255097832944658\n",
      "val_precision: tensor([0.6614, 0.8104, 0.6408, 0.7583], device='cuda:0')\n",
      "val_recall: tensor([0.6234, 0.7093, 0.7975, 0.2852], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 16 time:  22.21146260400019\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.7517174743470691\n",
      "train_precision: tensor([0.6426, 0.7217, 0.6981, 0.5962], device='cuda:0')\n",
      "train_recall: tensor([0.6120, 0.7950, 0.6984, 0.2719], device='cuda:0')\n",
      "val_loss: 0.6866044316026899\n",
      "val_precision: tensor([0.6894, 0.7465, 0.7178, 0.6833], device='cuda:0')\n",
      "val_recall: tensor([0.6135, 0.8269, 0.7527, 0.3684], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 17 time:  22.551187461000154\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.7488064232326689\n",
      "train_precision: tensor([0.6430, 0.7233, 0.6995, 0.5905], device='cuda:0')\n",
      "train_recall: tensor([0.6143, 0.7936, 0.7009, 0.2680], device='cuda:0')\n",
      "val_loss: 0.6930413722991944\n",
      "val_precision: tensor([0.6613, 0.7978, 0.7021, 0.5789], device='cuda:0')\n",
      "val_recall: tensor([0.6496, 0.7569, 0.7701, 0.4175], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 18 time:  22.332907447000252\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.7439861939066932\n",
      "train_precision: tensor([0.6441, 0.7244, 0.7012, 0.5863], device='cuda:0')\n",
      "train_recall: tensor([0.6164, 0.7943, 0.7005, 0.2788], device='cuda:0')\n",
      "val_loss: 0.6824133144484625\n",
      "val_precision: tensor([0.6715, 0.7921, 0.6985, 0.7197], device='cuda:0')\n",
      "val_recall: tensor([0.6411, 0.7785, 0.7778, 0.3519], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 19 time:  22.5763756260003\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.7400005408695766\n",
      "train_precision: tensor([0.6470, 0.7253, 0.7036, 0.6087], device='cuda:0')\n",
      "train_recall: tensor([0.6150, 0.7962, 0.7061, 0.2932], device='cuda:0')\n",
      "val_loss: 0.6677516195509169\n",
      "val_precision: tensor([0.6808, 0.7610, 0.7291, 0.7249], device='cuda:0')\n",
      "val_recall: tensor([0.6399, 0.8216, 0.7499, 0.3761], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 20 time:  22.814439379999385\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.7350763701257251\n",
      "train_precision: tensor([0.6474, 0.7306, 0.7058, 0.5939], device='cuda:0')\n",
      "train_recall: tensor([0.6229, 0.7980, 0.7026, 0.2961], device='cuda:0')\n",
      "val_loss: 0.6708516968621148\n",
      "val_precision: tensor([0.6934, 0.7594, 0.7150, 0.6783], device='cuda:0')\n",
      "val_recall: tensor([0.6094, 0.8270, 0.7681, 0.3926], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 21 time:  22.357999238000048\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.7301709299995786\n",
      "train_precision: tensor([0.6516, 0.7312, 0.7086, 0.6191], device='cuda:0')\n",
      "train_recall: tensor([0.6214, 0.8006, 0.7101, 0.3049], device='cuda:0')\n",
      "val_loss: 0.67241197625796\n",
      "val_precision: tensor([0.6930, 0.7865, 0.6929, 0.6916], device='cuda:0')\n",
      "val_recall: tensor([0.6218, 0.7797, 0.7958, 0.4357], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 22 time:  22.261502980998557\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.727230829851968\n",
      "train_precision: tensor([0.6502, 0.7315, 0.7108, 0.6104], device='cuda:0')\n",
      "train_recall: tensor([0.6269, 0.7986, 0.7057, 0.3123], device='cuda:0')\n",
      "val_loss: 0.6672872569825914\n",
      "val_precision: tensor([0.6835, 0.7736, 0.7186, 0.6992], device='cuda:0')\n",
      "val_recall: tensor([0.6379, 0.8078, 0.7639, 0.4155], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 23 time:  22.543729196999266\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.7226409259296599\n",
      "train_precision: tensor([0.6545, 0.7334, 0.7106, 0.6214], device='cuda:0')\n",
      "train_recall: tensor([0.6276, 0.8002, 0.7092, 0.3235], device='cuda:0')\n",
      "val_loss: 0.6842252161767748\n",
      "val_precision: tensor([0.6832, 0.7941, 0.6826, 0.7065], device='cuda:0')\n",
      "val_recall: tensor([0.5849, 0.7827, 0.8184, 0.4199], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 24 time:  22.021433257999888\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.7238093807583763\n",
      "train_precision: tensor([0.6544, 0.7316, 0.7111, 0.6150], device='cuda:0')\n",
      "train_recall: tensor([0.6263, 0.8016, 0.7074, 0.3225], device='cuda:0')\n",
      "val_loss: 0.6770105971230401\n",
      "val_precision: tensor([0.6665, 0.7657, 0.7352, 0.7050], device='cuda:0')\n",
      "val_recall: tensor([0.6624, 0.8050, 0.7331, 0.4064], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 25 time:  22.142063313998733\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.7166696571168445\n",
      "train_precision: tensor([0.6554, 0.7373, 0.7148, 0.6122], device='cuda:0')\n",
      "train_recall: tensor([0.6310, 0.8014, 0.7117, 0.3339], device='cuda:0')\n",
      "val_loss: 0.6535933534304301\n",
      "val_precision: tensor([0.6924, 0.7887, 0.7156, 0.6523], device='cuda:0')\n",
      "val_recall: tensor([0.6432, 0.8019, 0.7797, 0.4226], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 26 time:  22.26217846899999\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.713907109555744\n",
      "train_precision: tensor([0.6580, 0.7368, 0.7135, 0.6245], device='cuda:0')\n",
      "train_recall: tensor([0.6328, 0.8004, 0.7134, 0.3245], device='cuda:0')\n",
      "val_loss: 0.655626302295261\n",
      "val_precision: tensor([0.6827, 0.7625, 0.7492, 0.6980], device='cuda:0')\n",
      "val_recall: tensor([0.6592, 0.8277, 0.7408, 0.4195], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 27 time:  21.90772889800064\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.7096231801169259\n",
      "train_precision: tensor([0.6598, 0.7379, 0.7176, 0.6273], device='cuda:0')\n",
      "train_recall: tensor([0.6349, 0.8025, 0.7139, 0.3459], device='cuda:0')\n",
      "val_loss: 0.6496293809678819\n",
      "val_precision: tensor([0.6852, 0.7994, 0.7222, 0.7249], device='cuda:0')\n",
      "val_recall: tensor([0.6761, 0.7885, 0.7716, 0.4249], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 28 time:  22.395212590001393\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.7078556367329188\n",
      "train_precision: tensor([0.6604, 0.7396, 0.7169, 0.6232], device='cuda:0')\n",
      "train_recall: tensor([0.6343, 0.8039, 0.7148, 0.3468], device='cuda:0')\n",
      "val_loss: 0.6392160150739882\n",
      "val_precision: tensor([0.6686, 0.8088, 0.7487, 0.7476], device='cuda:0')\n",
      "val_recall: tensor([0.7074, 0.7838, 0.7611, 0.4199], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 29 time:  22.29954238999926\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.7050517314956302\n",
      "train_precision: tensor([0.6632, 0.7413, 0.7202, 0.6247], device='cuda:0')\n",
      "train_recall: tensor([0.6384, 0.8046, 0.7167, 0.3550], device='cuda:0')\n",
      "val_loss: 0.65803495115704\n",
      "val_precision: tensor([0.7002, 0.8042, 0.6885, 0.6429], device='cuda:0')\n",
      "val_recall: tensor([0.6049, 0.7782, 0.8241, 0.4589], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 30 time:  21.993445754000277\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 0.7002178016163054\n",
      "train_precision: tensor([0.6639, 0.7426, 0.7195, 0.6386], device='cuda:0')\n",
      "train_recall: tensor([0.6383, 0.8037, 0.7190, 0.3631], device='cuda:0')\n",
      "val_loss: 0.647036772304111\n",
      "val_precision: tensor([0.7080, 0.8179, 0.6879, 0.7479], device='cuda:0')\n",
      "val_recall: tensor([0.6246, 0.7763, 0.8344, 0.4155], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 31 time:  22.061823316998925\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 0.6971379660424732\n",
      "train_precision: tensor([0.6638, 0.7423, 0.7229, 0.6277], device='cuda:0')\n",
      "train_recall: tensor([0.6411, 0.8063, 0.7155, 0.3657], device='cuda:0')\n",
      "val_loss: 0.6333492974440257\n",
      "val_precision: tensor([0.6962, 0.7887, 0.7333, 0.7715], device='cuda:0')\n",
      "val_recall: tensor([0.6642, 0.8124, 0.7787, 0.4162], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 32 time:  22.34292963199914\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 0.6939100980758667\n",
      "train_precision: tensor([0.6673, 0.7449, 0.7229, 0.6299], device='cuda:0')\n",
      "train_recall: tensor([0.6406, 0.8068, 0.7211, 0.3733], device='cuda:0')\n",
      "val_loss: 0.6270082791646322\n",
      "val_precision: tensor([0.6828, 0.7773, 0.7706, 0.7621], device='cuda:0')\n",
      "val_recall: tensor([0.6935, 0.8353, 0.7374, 0.4013], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 33 time:  22.396124728998984\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 34\n",
      "train_loss: 0.6927275186493284\n",
      "train_precision: tensor([0.6680, 0.7446, 0.7241, 0.6308], device='cuda:0')\n",
      "train_recall: tensor([0.6428, 0.8076, 0.7202, 0.3700], device='cuda:0')\n",
      "val_loss: 0.628202391995324\n",
      "val_precision: tensor([0.6980, 0.7981, 0.7354, 0.6478], device='cuda:0')\n",
      "val_recall: tensor([0.6627, 0.8180, 0.7732, 0.4811], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 34 time:  21.995188647999385\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 35\n",
      "train_loss: 0.6890250785010201\n",
      "train_precision: tensor([0.6706, 0.7485, 0.7229, 0.6514], device='cuda:0')\n",
      "train_recall: tensor([0.6451, 0.8073, 0.7234, 0.3824], device='cuda:0')\n",
      "val_loss: 0.652177345752716\n",
      "val_precision: tensor([0.7130, 0.7897, 0.6994, 0.7285], device='cuda:0')\n",
      "val_recall: tensor([0.6181, 0.8077, 0.8015, 0.4680], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 35 time:  21.93361231400013\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 36\n",
      "train_loss: 0.6846047946384974\n",
      "train_precision: tensor([0.6694, 0.7490, 0.7281, 0.6364], device='cuda:0')\n",
      "train_recall: tensor([0.6489, 0.8080, 0.7219, 0.3841], device='cuda:0')\n",
      "val_loss: 0.6285910871293809\n",
      "val_precision: tensor([0.7063, 0.7805, 0.7371, 0.7410], device='cuda:0')\n",
      "val_recall: tensor([0.6443, 0.8383, 0.7769, 0.4421], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 36 time:  21.986719208000068\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 37\n",
      "train_loss: 0.6829046726226806\n",
      "train_precision: tensor([0.6729, 0.7485, 0.7278, 0.6426], device='cuda:0')\n",
      "train_recall: tensor([0.6466, 0.8093, 0.7256, 0.3908], device='cuda:0')\n",
      "val_loss: 0.6162508169809977\n",
      "val_precision: tensor([0.7052, 0.8018, 0.7361, 0.7221], device='cuda:0')\n",
      "val_recall: tensor([0.6635, 0.8149, 0.7913, 0.4899], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 37 time:  22.15337942899896\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 38\n",
      "train_loss: 0.6794643657548087\n",
      "train_precision: tensor([0.6746, 0.7507, 0.7297, 0.6456], device='cuda:0')\n",
      "train_recall: tensor([0.6493, 0.8089, 0.7280, 0.4027], device='cuda:0')\n",
      "val_loss: 0.6478579090701209\n",
      "val_precision: tensor([0.7117, 0.8095, 0.6961, 0.7000], device='cuda:0')\n",
      "val_recall: tensor([0.6452, 0.7698, 0.8146, 0.5044], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 38 time:  22.125378183000066\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 39\n",
      "train_loss: 0.6778735722814287\n",
      "train_precision: tensor([0.6755, 0.7501, 0.7308, 0.6498], device='cuda:0')\n",
      "train_recall: tensor([0.6510, 0.8115, 0.7250, 0.4048], device='cuda:0')\n",
      "val_loss: 0.6189263549115923\n",
      "val_precision: tensor([0.6983, 0.7812, 0.7598, 0.7692], device='cuda:0')\n",
      "val_recall: tensor([0.6807, 0.8307, 0.7631, 0.4421], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 39 time:  22.074358025000038\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 40\n",
      "train_loss: 0.6757648655346462\n",
      "train_precision: tensor([0.6745, 0.7525, 0.7322, 0.6549], device='cuda:0')\n",
      "train_recall: tensor([0.6550, 0.8095, 0.7257, 0.4069], device='cuda:0')\n",
      "val_loss: 0.6190330260329776\n",
      "val_precision: tensor([0.7090, 0.8152, 0.7202, 0.6899], device='cuda:0')\n",
      "val_recall: tensor([0.6498, 0.8057, 0.8060, 0.5242], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 40 time:  21.87005036700066\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 41\n",
      "train_loss: 0.672448902470725\n",
      "train_precision: tensor([0.6776, 0.7540, 0.7344, 0.6564], device='cuda:0')\n",
      "train_recall: tensor([0.6546, 0.8120, 0.7300, 0.4127], device='cuda:0')\n",
      "val_loss: 0.6285553144084083\n",
      "val_precision: tensor([0.7082, 0.8102, 0.7162, 0.7265], device='cuda:0')\n",
      "val_recall: tensor([0.6652, 0.7944, 0.7994, 0.4660], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 41 time:  21.961156444000153\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 42\n",
      "train_loss: 0.6537923716363453\n",
      "train_precision: tensor([0.6867, 0.7658, 0.7377, 0.6741], device='cuda:0')\n",
      "train_recall: tensor([0.6649, 0.8130, 0.7414, 0.4390], device='cuda:0')\n",
      "val_loss: 0.589960695637597\n",
      "val_precision: tensor([0.7188, 0.8133, 0.7481, 0.7090], device='cuda:0')\n",
      "val_recall: tensor([0.6808, 0.8183, 0.8016, 0.5333], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 42 time:  22.159238682999785\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 43\n",
      "train_loss: 0.6475351061139788\n",
      "train_precision: tensor([0.6900, 0.7615, 0.7436, 0.6692], device='cuda:0')\n",
      "train_recall: tensor([0.6656, 0.8170, 0.7406, 0.4449], device='cuda:0')\n",
      "val_loss: 0.5882810811201732\n",
      "val_precision: tensor([0.7225, 0.8148, 0.7462, 0.7026], device='cuda:0')\n",
      "val_recall: tensor([0.6780, 0.8189, 0.8057, 0.5394], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 43 time:  22.360869530000855\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 44\n",
      "train_loss: 0.6433306557791574\n",
      "train_precision: tensor([0.6900, 0.7659, 0.7453, 0.6802], device='cuda:0')\n",
      "train_recall: tensor([0.6710, 0.8163, 0.7410, 0.4597], device='cuda:0')\n",
      "val_loss: 0.5861195464928944\n",
      "val_precision: tensor([0.7156, 0.8188, 0.7524, 0.6942], device='cuda:0')\n",
      "val_recall: tensor([0.6920, 0.8137, 0.7972, 0.5542], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 44 time:  22.39711373099999\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 45\n",
      "train_loss: 0.6415539281708854\n",
      "train_precision: tensor([0.6910, 0.7655, 0.7458, 0.6769], device='cuda:0')\n",
      "train_recall: tensor([0.6689, 0.8195, 0.7410, 0.4599], device='cuda:0')\n",
      "val_loss: 0.5853822794225481\n",
      "val_precision: tensor([0.7240, 0.8142, 0.7475, 0.6920], device='cuda:0')\n",
      "val_recall: tensor([0.6759, 0.8214, 0.8054, 0.5545], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 45 time:  22.206116960000145\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 46\n",
      "train_loss: 0.6400592145465669\n",
      "train_precision: tensor([0.6910, 0.7665, 0.7472, 0.6666], device='cuda:0')\n",
      "train_recall: tensor([0.6720, 0.8180, 0.7415, 0.4535], device='cuda:0')\n",
      "val_loss: 0.5838807582855224\n",
      "val_precision: tensor([0.7187, 0.8154, 0.7550, 0.6908], device='cuda:0')\n",
      "val_recall: tensor([0.6882, 0.8188, 0.7993, 0.5485], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 46 time:  22.302488076998998\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 47\n",
      "train_loss: 0.6410897073291597\n",
      "train_precision: tensor([0.6921, 0.7669, 0.7466, 0.6612], device='cuda:0')\n",
      "train_recall: tensor([0.6720, 0.8177, 0.7419, 0.4582], device='cuda:0')\n",
      "val_loss: 0.5831100364526113\n",
      "val_precision: tensor([0.7158, 0.8202, 0.7516, 0.7319], device='cuda:0')\n",
      "val_recall: tensor([0.6925, 0.8133, 0.8022, 0.5387], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 47 time:  22.172173851999105\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 48\n",
      "train_loss: 0.638175870691027\n",
      "train_precision: tensor([0.6949, 0.7662, 0.7469, 0.6870], device='cuda:0')\n",
      "train_recall: tensor([0.6718, 0.8186, 0.7441, 0.4720], device='cuda:0')\n",
      "val_loss: 0.5828875137699975\n",
      "val_precision: tensor([0.7148, 0.8207, 0.7538, 0.6938], device='cuda:0')\n",
      "val_recall: tensor([0.6914, 0.8125, 0.8005, 0.5606], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 48 time:  22.072766260000208\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 49\n",
      "train_loss: 0.637522520337786\n",
      "train_precision: tensor([0.6934, 0.7666, 0.7472, 0.6647], device='cuda:0')\n",
      "train_recall: tensor([0.6700, 0.8187, 0.7440, 0.4659], device='cuda:0')\n",
      "val_loss: 0.5820924500624339\n",
      "val_precision: tensor([0.7249, 0.8115, 0.7523, 0.7074], device='cuda:0')\n",
      "val_recall: tensor([0.6780, 0.8276, 0.8031, 0.5471], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 49 time:  22.25794630999917\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 50\n",
      "train_loss: 0.6368687930561248\n",
      "train_precision: tensor([0.6933, 0.7678, 0.7479, 0.6746], device='cuda:0')\n",
      "train_recall: tensor([0.6728, 0.8182, 0.7443, 0.4642], device='cuda:0')\n",
      "val_loss: 0.5828779260317485\n",
      "val_precision: tensor([0.7231, 0.8166, 0.7498, 0.7237], device='cuda:0')\n",
      "val_recall: tensor([0.6839, 0.8196, 0.8069, 0.5387], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 50 time:  21.944044226998813\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 51\n",
      "train_loss: 0.6362914306776865\n",
      "train_precision: tensor([0.6936, 0.7666, 0.7471, 0.6827], device='cuda:0')\n",
      "train_recall: tensor([0.6700, 0.8195, 0.7445, 0.4681], device='cuda:0')\n",
      "val_loss: 0.5833142711056604\n",
      "val_precision: tensor([0.7179, 0.8167, 0.7527, 0.7330], device='cuda:0')\n",
      "val_recall: tensor([0.6904, 0.8173, 0.8017, 0.5306], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 51 time:  21.994602139000563\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 52\n",
      "train_loss: 0.6347948619297572\n",
      "train_precision: tensor([0.6933, 0.7676, 0.7483, 0.6881], device='cuda:0')\n",
      "train_recall: tensor([0.6725, 0.8216, 0.7422, 0.4671], device='cuda:0')\n",
      "val_loss: 0.5801472100946639\n",
      "val_precision: tensor([0.7204, 0.8147, 0.7563, 0.7234], device='cuda:0')\n",
      "val_recall: tensor([0.6900, 0.8229, 0.7999, 0.5397], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 52 time:  22.315361719000066\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 53\n",
      "train_loss: 0.6329715950148446\n",
      "train_precision: tensor([0.6958, 0.7689, 0.7484, 0.6821], device='cuda:0')\n",
      "train_recall: tensor([0.6749, 0.8191, 0.7448, 0.4747], device='cuda:0')\n",
      "val_loss: 0.5802542845408122\n",
      "val_precision: tensor([0.7226, 0.8156, 0.7545, 0.7013], device='cuda:0')\n",
      "val_recall: tensor([0.6868, 0.8215, 0.8011, 0.5643], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 53 time:  22.076336156000252\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 54\n",
      "train_loss: 0.63286813440777\n",
      "train_precision: tensor([0.6958, 0.7681, 0.7475, 0.6787], device='cuda:0')\n",
      "train_recall: tensor([0.6729, 0.8187, 0.7464, 0.4649], device='cuda:0')\n",
      "val_loss: 0.5814536988735199\n",
      "val_precision: tensor([0.7197, 0.8189, 0.7525, 0.7121], device='cuda:0')\n",
      "val_recall: tensor([0.6914, 0.8149, 0.8034, 0.5448], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 54 time:  22.07825469599993\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 55\n",
      "train_loss: 0.6327215546653384\n",
      "train_precision: tensor([0.6952, 0.7676, 0.7527, 0.6845], device='cuda:0')\n",
      "train_recall: tensor([0.6765, 0.8200, 0.7444, 0.4762], device='cuda:0')\n",
      "val_loss: 0.5797293550438352\n",
      "val_precision: tensor([0.7174, 0.8188, 0.7582, 0.7196], device='cuda:0')\n",
      "val_recall: tensor([0.6977, 0.8177, 0.7980, 0.5478], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 55 time:  22.346591154000635\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 56\n",
      "train_loss: 0.6300586359841484\n",
      "train_precision: tensor([0.6987, 0.7689, 0.7517, 0.6818], device='cuda:0')\n",
      "train_recall: tensor([0.6759, 0.8217, 0.7475, 0.4733], device='cuda:0')\n",
      "val_loss: 0.5790447096029917\n",
      "val_precision: tensor([0.7171, 0.8188, 0.7603, 0.7228], device='cuda:0')\n",
      "val_recall: tensor([0.6998, 0.8190, 0.7964, 0.5539], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 56 time:  22.385927450000963\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 57\n",
      "train_loss: 0.6301949762162709\n",
      "train_precision: tensor([0.6967, 0.7683, 0.7503, 0.6870], device='cuda:0')\n",
      "train_recall: tensor([0.6743, 0.8197, 0.7462, 0.4861], device='cuda:0')\n",
      "val_loss: 0.5813912676440345\n",
      "val_precision: tensor([0.7180, 0.8241, 0.7517, 0.6932], device='cuda:0')\n",
      "val_recall: tensor([0.6926, 0.8096, 0.8045, 0.5727], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 57 time:  21.865303216998655\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 58\n",
      "train_loss: 0.6296382909729368\n",
      "train_precision: tensor([0.6969, 0.7692, 0.7502, 0.6844], device='cuda:0')\n",
      "train_recall: tensor([0.6752, 0.8207, 0.7451, 0.4853], device='cuda:0')\n",
      "val_loss: 0.5778968254725139\n",
      "val_precision: tensor([0.7207, 0.8145, 0.7589, 0.7148], device='cuda:0')\n",
      "val_recall: tensor([0.6934, 0.8220, 0.7978, 0.5535], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 58 time:  22.193730987999515\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 59\n",
      "train_loss: 0.6276911775271098\n",
      "train_precision: tensor([0.6980, 0.7700, 0.7512, 0.6925], device='cuda:0')\n",
      "train_recall: tensor([0.6765, 0.8217, 0.7451, 0.4973], device='cuda:0')\n",
      "val_loss: 0.5791575935151841\n",
      "val_precision: tensor([0.7187, 0.8166, 0.7580, 0.7109], device='cuda:0')\n",
      "val_recall: tensor([0.6949, 0.8183, 0.7969, 0.5663], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 59 time:  21.87758120000035\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 60\n",
      "train_loss: 0.6278791779563541\n",
      "train_precision: tensor([0.6975, 0.7713, 0.7522, 0.6884], device='cuda:0')\n",
      "train_recall: tensor([0.6771, 0.8220, 0.7468, 0.4864], device='cuda:0')\n",
      "val_loss: 0.5770817041397095\n",
      "val_precision: tensor([0.7260, 0.8118, 0.7591, 0.7292], device='cuda:0')\n",
      "val_recall: tensor([0.6899, 0.8291, 0.7999, 0.5448], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 60 time:  22.579783922999923\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 61\n",
      "train_loss: 0.6304379366693043\n",
      "train_precision: tensor([0.6969, 0.7689, 0.7501, 0.6852], device='cuda:0')\n",
      "train_recall: tensor([0.6751, 0.8202, 0.7463, 0.4778], device='cuda:0')\n",
      "val_loss: 0.5790048764811622\n",
      "val_precision: tensor([0.7229, 0.8141, 0.7562, 0.6981], device='cuda:0')\n",
      "val_recall: tensor([0.6875, 0.8226, 0.7996, 0.5677], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 61 time:  21.864003230999515\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 62\n",
      "train_loss: 0.6276636748086839\n",
      "train_precision: tensor([0.6987, 0.7687, 0.7515, 0.6882], device='cuda:0')\n",
      "train_recall: tensor([0.6753, 0.8213, 0.7479, 0.4804], device='cuda:0')\n",
      "val_loss: 0.5774265600575341\n",
      "val_precision: tensor([0.7198, 0.8167, 0.7610, 0.7158], device='cuda:0')\n",
      "val_recall: tensor([0.6970, 0.8227, 0.7960, 0.5606], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 62 time:  21.825446364000527\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 63\n",
      "train_loss: 0.6256414209093366\n",
      "train_precision: tensor([0.6977, 0.7699, 0.7520, 0.6953], device='cuda:0')\n",
      "train_recall: tensor([0.6768, 0.8204, 0.7475, 0.4889], device='cuda:0')\n",
      "val_loss: 0.5792894701162974\n",
      "val_precision: tensor([0.7278, 0.8100, 0.7578, 0.6909], device='cuda:0')\n",
      "val_recall: tensor([0.6838, 0.8280, 0.7991, 0.5795], device='cuda:0')\n",
      "Learning rate: 5e-05\n",
      "epoch 63 time:  21.944676782000897\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 64\n",
      "train_loss: 0.6257532903126308\n",
      "train_precision: tensor([0.6983, 0.7706, 0.7516, 0.6831], device='cuda:0')\n",
      "train_recall: tensor([0.6765, 0.8227, 0.7455, 0.4902], device='cuda:0')\n",
      "val_loss: 0.580021674103207\n",
      "val_precision: tensor([0.7264, 0.8147, 0.7521, 0.7123], device='cuda:0')\n",
      "val_recall: tensor([0.6818, 0.8229, 0.8076, 0.5535], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 64 time:  21.982132362998527\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 65\n",
      "train_loss: 0.6237240677788144\n",
      "train_precision: tensor([0.7000, 0.7679, 0.7545, 0.6942], device='cuda:0')\n",
      "train_recall: tensor([0.6762, 0.8259, 0.7460, 0.4843], device='cuda:0')\n",
      "val_loss: 0.5771987034214867\n",
      "val_precision: tensor([0.7226, 0.8163, 0.7580, 0.7121], device='cuda:0')\n",
      "val_recall: tensor([0.6915, 0.8214, 0.8017, 0.5630], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 65 time:  21.87248187899968\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 66\n",
      "train_loss: 0.6228289076260158\n",
      "train_precision: tensor([0.6991, 0.7718, 0.7566, 0.6908], device='cuda:0')\n",
      "train_recall: tensor([0.6800, 0.8248, 0.7473, 0.4903], device='cuda:0')\n",
      "val_loss: 0.5767033047146267\n",
      "val_precision: tensor([0.7236, 0.8147, 0.7591, 0.7199], device='cuda:0')\n",
      "val_recall: tensor([0.6915, 0.8242, 0.8011, 0.5566], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 66 time:  22.431708342001002\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 67\n",
      "train_loss: 0.6244740020661127\n",
      "train_precision: tensor([0.6989, 0.7707, 0.7544, 0.6942], device='cuda:0')\n",
      "train_recall: tensor([0.6793, 0.8214, 0.7483, 0.4887], device='cuda:0')\n",
      "val_loss: 0.5775863422287835\n",
      "val_precision: tensor([0.7225, 0.8184, 0.7557, 0.7193], device='cuda:0')\n",
      "val_recall: tensor([0.6915, 0.8184, 0.8047, 0.5616], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 67 time:  21.81472232300075\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 68\n",
      "train_loss: 0.6246535136586144\n",
      "train_precision: tensor([0.6999, 0.7713, 0.7529, 0.6963], device='cuda:0')\n",
      "train_recall: tensor([0.6777, 0.8220, 0.7489, 0.4965], device='cuda:0')\n",
      "val_loss: 0.5776322464148204\n",
      "val_precision: tensor([0.7231, 0.8178, 0.7558, 0.7190], device='cuda:0')\n",
      "val_recall: tensor([0.6911, 0.8196, 0.8044, 0.5593], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 68 time:  21.908251858998483\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 69\n",
      "train_loss: 0.6236925811994644\n",
      "train_precision: tensor([0.6991, 0.7724, 0.7522, 0.6875], device='cuda:0')\n",
      "train_recall: tensor([0.6812, 0.8199, 0.7467, 0.4911], device='cuda:0')\n",
      "val_loss: 0.5772494594256083\n",
      "val_precision: tensor([0.7232, 0.8178, 0.7567, 0.7161], device='cuda:0')\n",
      "val_recall: tensor([0.6916, 0.8205, 0.8036, 0.5613], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 69 time:  21.901133131999813\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 70\n",
      "train_loss: 0.6223894056819734\n",
      "train_precision: tensor([0.7010, 0.7704, 0.7546, 0.7014], device='cuda:0')\n",
      "train_recall: tensor([0.6793, 0.8220, 0.7490, 0.4997], device='cuda:0')\n",
      "val_loss: 0.5766393860181173\n",
      "val_precision: tensor([0.7226, 0.8163, 0.7584, 0.7245], device='cuda:0')\n",
      "val_recall: tensor([0.6940, 0.8218, 0.8008, 0.5579], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 70 time:  22.37276484299946\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 71\n",
      "train_loss: 0.6230147628557114\n",
      "train_precision: tensor([0.7008, 0.7731, 0.7538, 0.6928], device='cuda:0')\n",
      "train_recall: tensor([0.6802, 0.8226, 0.7487, 0.4991], device='cuda:0')\n",
      "val_loss: 0.5762468682395088\n",
      "val_precision: tensor([0.7212, 0.8157, 0.7614, 0.7193], device='cuda:0')\n",
      "val_recall: tensor([0.6966, 0.8223, 0.7978, 0.5626], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 71 time:  22.36656052000035\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 72\n",
      "train_loss: 0.6231248429843358\n",
      "train_precision: tensor([0.6990, 0.7703, 0.7547, 0.6938], device='cuda:0')\n",
      "train_recall: tensor([0.6783, 0.8226, 0.7472, 0.4980], device='cuda:0')\n",
      "val_loss: 0.5766954256428612\n",
      "val_precision: tensor([0.7252, 0.8159, 0.7573, 0.7004], device='cuda:0')\n",
      "val_recall: tensor([0.6887, 0.8229, 0.8020, 0.5795], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 72 time:  21.90540786099882\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 73\n",
      "train_loss: 0.6219185948371887\n",
      "train_precision: tensor([0.7003, 0.7721, 0.7528, 0.7009], device='cuda:0')\n",
      "train_recall: tensor([0.6782, 0.8228, 0.7487, 0.5006], device='cuda:0')\n",
      "val_loss: 0.5772814995712704\n",
      "val_precision: tensor([0.7229, 0.8175, 0.7563, 0.7183], device='cuda:0')\n",
      "val_recall: tensor([0.6922, 0.8196, 0.8029, 0.5633], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 73 time:  21.83391729199866\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 74\n",
      "train_loss: 0.6232031038829259\n",
      "train_precision: tensor([0.7015, 0.7712, 0.7537, 0.6906], device='cuda:0')\n",
      "train_recall: tensor([0.6774, 0.8236, 0.7495, 0.4975], device='cuda:0')\n",
      "val_loss: 0.576479873392317\n",
      "val_precision: tensor([0.7230, 0.8167, 0.7583, 0.7189], device='cuda:0')\n",
      "val_recall: tensor([0.6925, 0.8215, 0.8021, 0.5640], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 74 time:  21.98994426399986\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 75\n",
      "train_loss: 0.623209848290398\n",
      "train_precision: tensor([0.6986, 0.7715, 0.7535, 0.6844], device='cuda:0')\n",
      "train_recall: tensor([0.6783, 0.8220, 0.7474, 0.4912], device='cuda:0')\n",
      "val_loss: 0.5768704805109236\n",
      "val_precision: tensor([0.7239, 0.8155, 0.7566, 0.7226], device='cuda:0')\n",
      "val_recall: tensor([0.6895, 0.8228, 0.8028, 0.5596], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 75 time:  21.866973186000905\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 76\n",
      "train_loss: 0.6235263710930234\n",
      "train_precision: tensor([0.7006, 0.7725, 0.7539, 0.6933], device='cuda:0')\n",
      "train_recall: tensor([0.6805, 0.8220, 0.7492, 0.4913], device='cuda:0')\n",
      "val_loss: 0.5768944362799326\n",
      "val_precision: tensor([0.7203, 0.8204, 0.7581, 0.7194], device='cuda:0')\n",
      "val_recall: tensor([0.6973, 0.8179, 0.8012, 0.5620], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 76 time:  21.9369274590008\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 77\n",
      "train_loss: 0.6230356738680884\n",
      "train_precision: tensor([0.7005, 0.7708, 0.7529, 0.6883], device='cuda:0')\n",
      "train_recall: tensor([0.6788, 0.8221, 0.7476, 0.4922], device='cuda:0')\n",
      "val_loss: 0.5776720775498284\n",
      "val_precision: tensor([0.7207, 0.8201, 0.7560, 0.7188], device='cuda:0')\n",
      "val_recall: tensor([0.6948, 0.8168, 0.8027, 0.5613], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 77 time:  21.958476350000637\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 78\n",
      "train_loss: 0.6216734227680024\n",
      "train_precision: tensor([0.7000, 0.7719, 0.7548, 0.6992], device='cuda:0')\n",
      "train_recall: tensor([0.6799, 0.8239, 0.7471, 0.5010], device='cuda:0')\n",
      "val_loss: 0.5768029835489061\n",
      "val_precision: tensor([0.7253, 0.8157, 0.7556, 0.7137], device='cuda:0')\n",
      "val_recall: tensor([0.6869, 0.8228, 0.8050, 0.5623], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 78 time:  22.099711418999505\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 79\n",
      "train_loss: 0.6225694940203712\n",
      "train_precision: tensor([0.7007, 0.7719, 0.7529, 0.6934], device='cuda:0')\n",
      "train_recall: tensor([0.6792, 0.8213, 0.7496, 0.4922], device='cuda:0')\n",
      "val_loss: 0.576538950867123\n",
      "val_precision: tensor([0.7215, 0.8156, 0.7603, 0.7154], device='cuda:0')\n",
      "val_recall: tensor([0.6949, 0.8223, 0.7979, 0.5653], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 79 time:  21.94353050599966\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 80\n",
      "train_loss: 0.621982843535287\n",
      "train_precision: tensor([0.7005, 0.7723, 0.7535, 0.6927], device='cuda:0')\n",
      "train_recall: tensor([0.6797, 0.8239, 0.7469, 0.4957], device='cuda:0')\n",
      "val_loss: 0.5756899429692163\n",
      "val_precision: tensor([0.7239, 0.8146, 0.7593, 0.7200], device='cuda:0')\n",
      "val_recall: tensor([0.6919, 0.8241, 0.8002, 0.5653], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 80 time:  22.24773049400028\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 81\n",
      "train_loss: 0.6228970567385356\n",
      "train_precision: tensor([0.7025, 0.7717, 0.7540, 0.6913], device='cuda:0')\n",
      "train_recall: tensor([0.6790, 0.8219, 0.7513, 0.4974], device='cuda:0')\n",
      "val_loss: 0.5766758150524564\n",
      "val_precision: tensor([0.7258, 0.8149, 0.7567, 0.7118], device='cuda:0')\n",
      "val_recall: tensor([0.6884, 0.8242, 0.8023, 0.5687], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 81 time:  22.00042510500134\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 82\n",
      "train_loss: 0.6204456562087649\n",
      "train_precision: tensor([0.7013, 0.7730, 0.7562, 0.6926], device='cuda:0')\n",
      "train_recall: tensor([0.6817, 0.8231, 0.7496, 0.4981], device='cuda:0')\n",
      "val_loss: 0.5763985051049126\n",
      "val_precision: tensor([0.7230, 0.8166, 0.7579, 0.7128], device='cuda:0')\n",
      "val_recall: tensor([0.6923, 0.8219, 0.8004, 0.5700], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 82 time:  21.962846132999402\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 83\n",
      "train_loss: 0.6207815845807393\n",
      "train_precision: tensor([0.7021, 0.7721, 0.7534, 0.6938], device='cuda:0')\n",
      "train_recall: tensor([0.6789, 0.8224, 0.7501, 0.5001], device='cuda:0')\n",
      "val_loss: 0.5767354514863756\n",
      "val_precision: tensor([0.7248, 0.8160, 0.7569, 0.7183], device='cuda:0')\n",
      "val_recall: tensor([0.6893, 0.8238, 0.8022, 0.5700], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 83 time:  21.911036825000338\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 84\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 223\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m    222\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 223\u001b[0m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m my_model\u001b[38;5;241m.\u001b[39mevaluate(testloader)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n",
      "Cell \u001b[0;32mIn[1], line 115\u001b[0m, in \u001b[0;36mMyModel.train_one_epoch\u001b[0;34m(self, trainloader)\u001b[0m\n\u001b[1;32m    113\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    114\u001b[0m _, labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(labels, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_recall(preds, labels)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torchmetrics/metric.py:304\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torchmetrics/metric.py:373\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torchmetrics/metric.py:466\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torchmetrics/classification/stat_scores.py:333\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 333\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m    337\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    338\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torchmetrics/functional/classification/stat_scores.py:309\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    307\u001b[0m check_value \u001b[38;5;241m=\u001b[39m num_classes \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_classes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, name \u001b[38;5;129;01min\u001b[39;00m ((target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m),) \u001b[38;5;241m+\u001b[39m ((preds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m),) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m ():  \u001b[38;5;66;03m# noqa: RUF005\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     num_unique_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_unique_values \u001b[38;5;241m>\u001b[39m check_value:\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected more unique values in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` than expected. Expected only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheck_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_unique_values\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in `target`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/_jit_internal.py:499\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/_jit_internal.py:499\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/functional.py:991\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 991\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/functional.py:905\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    897\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[1;32m    898\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    899\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[1;32m    903\u001b[0m     )\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 905\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'efficient_netb0_normalize_batch_2048_test{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.base_model = models.efficientnet_b0(pretrained=False)\n",
    "        num_ftrs = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.05, patience=3, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        wandb.log({'f1_score': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "        wandb.log({'f1_score_val': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 2048\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = EfficientNetB0()\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca2b778-5e5c-4b73-b30d-307bbebf419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[686 105 200   9]\n",
      " [108 829  60   3]\n",
      " [127  44 821   8]\n",
      " [ 18   8  14  60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71      1000\n",
      "           1       0.84      0.83      0.83      1000\n",
      "           2       0.75      0.82      0.78      1000\n",
      "           3       0.75      0.60      0.67       100\n",
      "\n",
      "    accuracy                           0.77      3100\n",
      "   macro avg       0.77      0.73      0.75      3100\n",
      "weighted avg       0.77      0.77      0.77      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data', transform=transform_test)\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a5e04e-3bd4-4604-9846-c17a82ba49a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_checkpoints/efficient_netb0_normalize_batch_2048_test2024-04-25 00:32:59.640440.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c9add-a886-4f69-8136-5421bd955840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
