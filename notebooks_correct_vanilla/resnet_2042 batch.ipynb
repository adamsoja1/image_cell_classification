{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd47a18-ba85-446a-aade-be2ffc99868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240423_001452-de3ocfst</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/de3ocfst' target=\"_blank\">resnet18_2048batch_2024-04-23 00:14:51.938641</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/de3ocfst' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/de3ocfst</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.9192088927541461\n",
      "train_precision: tensor([0.5288, 0.6805, 0.6153, 0.5672], device='cuda:0')\n",
      "train_recall: tensor([0.5253, 0.7428, 0.6204, 0.0384], device='cuda:0')\n",
      "val_loss: 0.8070167203744253\n",
      "val_precision: tensor([0.6160, 0.7856, 0.6092, 0.7404], device='cuda:0')\n",
      "val_recall: tensor([0.5328, 0.7064, 0.7995, 0.1747], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  1.307993630366667\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.798546948887053\n",
      "train_precision: tensor([0.5911, 0.7174, 0.6792, 0.6499], device='cuda:0')\n",
      "train_recall: tensor([0.5825, 0.7826, 0.6777, 0.1683], device='cuda:0')\n",
      "val_loss: 0.7553661015298632\n",
      "val_precision: tensor([0.6370, 0.6921, 0.7332, 0.6249], device='cuda:0')\n",
      "val_recall: tensor([0.5819, 0.8452, 0.6674, 0.3444], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  0.34738614591666706\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.7603705411865598\n",
      "train_precision: tensor([0.6159, 0.7334, 0.6943, 0.6282], device='cuda:0')\n",
      "train_recall: tensor([0.6039, 0.7896, 0.6951, 0.2619], device='cuda:0')\n",
      "val_loss: 0.8233932813008626\n",
      "val_precision: tensor([0.6218, 0.6781, 0.7512, 0.7175], device='cuda:0')\n",
      "val_recall: tensor([0.6052, 0.8621, 0.6174, 0.2394], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  0.32687213824999994\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.7328780724888756\n",
      "train_precision: tensor([0.6289, 0.7456, 0.7079, 0.6320], device='cuda:0')\n",
      "train_recall: tensor([0.6200, 0.7967, 0.7049, 0.3162], device='cuda:0')\n",
      "val_loss: 0.7224462370077769\n",
      "val_precision: tensor([0.6492, 0.7098, 0.7236, 0.8126], device='cuda:0')\n",
      "val_recall: tensor([0.5793, 0.8662, 0.6877, 0.3007], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  0.34581100605\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.7118557668867566\n",
      "train_precision: tensor([0.6412, 0.7550, 0.7160, 0.6591], device='cuda:0')\n",
      "train_recall: tensor([0.6294, 0.8040, 0.7141, 0.3704], device='cuda:0')\n",
      "val_loss: 0.7486513899432288\n",
      "val_precision: tensor([0.7128, 0.6530, 0.7498, 0.5617], device='cuda:0')\n",
      "val_recall: tensor([0.4898, 0.9191, 0.6989, 0.4121], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  0.3259762132166666\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.6945229132970174\n",
      "train_precision: tensor([0.6501, 0.7599, 0.7236, 0.6635], device='cuda:0')\n",
      "train_recall: tensor([0.6370, 0.8081, 0.7207, 0.4023], device='cuda:0')\n",
      "val_loss: 0.7137794004546272\n",
      "val_precision: tensor([0.6795, 0.7720, 0.6581, 0.7065], device='cuda:0')\n",
      "val_recall: tensor([0.5180, 0.8085, 0.8106, 0.4141], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  0.3461562013499995\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.6787625346864973\n",
      "train_precision: tensor([0.6581, 0.7659, 0.7308, 0.6765], device='cuda:0')\n",
      "train_recall: tensor([0.6460, 0.8133, 0.7250, 0.4361], device='cuda:0')\n",
      "val_loss: 0.7429782417085435\n",
      "val_precision: tensor([0.6027, 0.7903, 0.6952, 0.7191], device='cuda:0')\n",
      "val_recall: tensor([0.6480, 0.7187, 0.7403, 0.3620], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  0.3268889077833326\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.6644535217966352\n",
      "train_precision: tensor([0.6672, 0.7709, 0.7367, 0.6719], device='cuda:0')\n",
      "train_recall: tensor([0.6534, 0.8172, 0.7314, 0.4566], device='cuda:0')\n",
      "val_loss: 0.6709736042552524\n",
      "val_precision: tensor([0.6959, 0.7974, 0.6801, 0.7827], device='cuda:0')\n",
      "val_recall: tensor([0.5824, 0.8009, 0.8218, 0.3929], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  0.343903171366667\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.6531409939130147\n",
      "train_precision: tensor([0.6700, 0.7761, 0.7441, 0.6778], device='cuda:0')\n",
      "train_recall: tensor([0.6620, 0.8185, 0.7339, 0.4814], device='cuda:0')\n",
      "val_loss: 0.7136994461218517\n",
      "val_precision: tensor([0.7233, 0.7896, 0.6439, 0.4517], device='cuda:0')\n",
      "val_recall: tensor([0.5030, 0.8075, 0.8177, 0.5051], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  0.3270880884500002\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.6419073927970159\n",
      "train_precision: tensor([0.6793, 0.7811, 0.7479, 0.6795], device='cuda:0')\n",
      "train_recall: tensor([0.6668, 0.8254, 0.7399, 0.4919], device='cuda:0')\n",
      "val_loss: 0.64012567864524\n",
      "val_precision: tensor([0.6950, 0.7816, 0.7123, 0.7999], device='cuda:0')\n",
      "val_recall: tensor([0.5935, 0.8413, 0.7924, 0.4576], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  0.34663144933333284\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.6300547747384935\n",
      "train_precision: tensor([0.6819, 0.7855, 0.7534, 0.6907], device='cuda:0')\n",
      "train_recall: tensor([0.6728, 0.8269, 0.7417, 0.5255], device='cuda:0')\n",
      "val_loss: 0.6744073357847001\n",
      "val_precision: tensor([0.7016, 0.7795, 0.7347, 0.4113], device='cuda:0')\n",
      "val_recall: tensor([0.6080, 0.8277, 0.7436, 0.6562], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  0.32617371581666627\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.6206330520766122\n",
      "train_precision: tensor([0.6876, 0.7878, 0.7575, 0.6859], device='cuda:0')\n",
      "train_recall: tensor([0.6762, 0.8282, 0.7480, 0.5351], device='cuda:0')\n",
      "val_loss: 0.6427867207262251\n",
      "val_precision: tensor([0.6508, 0.7842, 0.7986, 0.8052], device='cuda:0')\n",
      "val_recall: tensor([0.7334, 0.8256, 0.6938, 0.4148], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  0.32603398614999907\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.6095602018492562\n",
      "train_precision: tensor([0.6928, 0.7924, 0.7629, 0.7170], device='cuda:0')\n",
      "train_recall: tensor([0.6826, 0.8312, 0.7540, 0.5554], device='cuda:0')\n",
      "val_loss: 0.6720486978689829\n",
      "val_precision: tensor([0.5827, 0.8388, 0.8242, 0.6406], device='cuda:0')\n",
      "val_recall: tensor([0.8136, 0.7443, 0.5976, 0.5845], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 12 time:  0.3261534105666669\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.5650717985062372\n",
      "train_precision: tensor([0.7164, 0.8091, 0.7841, 0.7320], device='cuda:0')\n",
      "train_recall: tensor([0.7080, 0.8453, 0.7695, 0.6264], device='cuda:0')\n",
      "val_loss: 0.5756560001108382\n",
      "val_precision: tensor([0.7217, 0.8164, 0.7595, 0.7717], device='cuda:0')\n",
      "val_recall: tensor([0.6880, 0.8350, 0.7967, 0.5781], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 13 time:  0.34597273240000087\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.5485471668697539\n",
      "train_precision: tensor([0.7262, 0.8148, 0.7883, 0.7475], device='cuda:0')\n",
      "train_recall: tensor([0.7125, 0.8495, 0.7798, 0.6522], device='cuda:0')\n",
      "val_loss: 0.5840190675523546\n",
      "val_precision: tensor([0.7277, 0.8228, 0.7450, 0.7284], device='cuda:0')\n",
      "val_recall: tensor([0.6680, 0.8325, 0.8098, 0.6067], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 14 time:  0.3268076036166671\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.5408504673412868\n",
      "train_precision: tensor([0.7280, 0.8178, 0.7918, 0.7499], device='cuda:0')\n",
      "train_recall: tensor([0.7184, 0.8516, 0.7789, 0.6616], device='cuda:0')\n",
      "val_loss: 0.5759721961286333\n",
      "val_precision: tensor([0.6992, 0.8023, 0.8059, 0.7667], device='cuda:0')\n",
      "val_recall: tensor([0.7316, 0.8506, 0.7378, 0.5976], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 15 time:  0.3274616440333337\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.5320938101836613\n",
      "train_precision: tensor([0.7323, 0.8225, 0.7966, 0.7619], device='cuda:0')\n",
      "train_recall: tensor([0.7242, 0.8542, 0.7834, 0.6784], device='cuda:0')\n",
      "val_loss: 0.5733078261216481\n",
      "val_precision: tensor([0.7067, 0.7981, 0.8021, 0.7455], device='cuda:0')\n",
      "val_recall: tensor([0.7172, 0.8605, 0.7409, 0.6195], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 16 time:  0.3459808138500004\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.5257379355884734\n",
      "train_precision: tensor([0.7369, 0.8227, 0.8002, 0.7667], device='cuda:0')\n",
      "train_recall: tensor([0.7283, 0.8544, 0.7868, 0.6903], device='cuda:0')\n",
      "val_loss: 0.5706526623831855\n",
      "val_precision: tensor([0.7132, 0.8066, 0.7895, 0.7813], device='cuda:0')\n",
      "val_recall: tensor([0.7112, 0.8504, 0.7670, 0.6003], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 17 time:  0.3498349247499997\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.5200306846981957\n",
      "train_precision: tensor([0.7397, 0.8268, 0.8028, 0.7597], device='cuda:0')\n",
      "train_recall: tensor([0.7324, 0.8577, 0.7877, 0.6945], device='cuda:0')\n",
      "val_loss: 0.5749627305401697\n",
      "val_precision: tensor([0.7075, 0.7914, 0.8088, 0.7488], device='cuda:0')\n",
      "val_recall: tensor([0.7183, 0.8659, 0.7337, 0.6253], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 18 time:  0.3277303017499984\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.5124963422616323\n",
      "train_precision: tensor([0.7415, 0.8301, 0.8058, 0.7721], device='cuda:0')\n",
      "train_recall: tensor([0.7347, 0.8584, 0.7929, 0.7025], device='cuda:0')\n",
      "val_loss: 0.574205587969886\n",
      "val_precision: tensor([0.7168, 0.8311, 0.7623, 0.7904], device='cuda:0')\n",
      "val_recall: tensor([0.7090, 0.8223, 0.7983, 0.5865], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 19 time:  0.3275601204833341\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.5066160633450463\n",
      "train_precision: tensor([0.7447, 0.8306, 0.8088, 0.7792], device='cuda:0')\n",
      "train_recall: tensor([0.7396, 0.8608, 0.7916, 0.7160], device='cuda:0')\n",
      "val_loss: 0.5720772193537818\n",
      "val_precision: tensor([0.7374, 0.8227, 0.7545, 0.7360], device='cuda:0')\n",
      "val_recall: tensor([0.6750, 0.8399, 0.8127, 0.6374], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 20 time:  0.32773958771666684\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.49319868087768554\n",
      "train_precision: tensor([0.7561, 0.8335, 0.8140, 0.7929], device='cuda:0')\n",
      "train_recall: tensor([0.7440, 0.8679, 0.8002, 0.7268], device='cuda:0')\n",
      "val_loss: 0.5630520900090535\n",
      "val_precision: tensor([0.7183, 0.8284, 0.7817, 0.7625], device='cuda:0')\n",
      "val_recall: tensor([0.7200, 0.8361, 0.7857, 0.6347], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 21 time:  0.34690333710000043\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.4905880343346369\n",
      "train_precision: tensor([0.7531, 0.8360, 0.8159, 0.7948], device='cuda:0')\n",
      "train_recall: tensor([0.7483, 0.8655, 0.7986, 0.7346], device='cuda:0')\n",
      "val_loss: 0.5633810983763801\n",
      "val_precision: tensor([0.7221, 0.8260, 0.7797, 0.7719], device='cuda:0')\n",
      "val_recall: tensor([0.7136, 0.8403, 0.7898, 0.6300], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 22 time:  0.3274530889833329\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.48924831804775054\n",
      "train_precision: tensor([0.7542, 0.8386, 0.8162, 0.7912], device='cuda:0')\n",
      "train_recall: tensor([0.7499, 0.8675, 0.7986, 0.7356], device='cuda:0')\n",
      "val_loss: 0.5626897275447845\n",
      "val_precision: tensor([0.7254, 0.8271, 0.7763, 0.7625], device='cuda:0')\n",
      "val_recall: tensor([0.7083, 0.8389, 0.7959, 0.6411], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 23 time:  0.3470913976833325\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.4880753605138688\n",
      "train_precision: tensor([0.7558, 0.8377, 0.8170, 0.7945], device='cuda:0')\n",
      "train_recall: tensor([0.7496, 0.8674, 0.8004, 0.7387], device='cuda:0')\n",
      "val_loss: 0.5650981307029724\n",
      "val_precision: tensor([0.7235, 0.8308, 0.7744, 0.7646], device='cuda:0')\n",
      "val_recall: tensor([0.7097, 0.8346, 0.7989, 0.6333], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 24 time:  0.3277268652500008\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.4855291051524026\n",
      "train_precision: tensor([0.7556, 0.8394, 0.8167, 0.7934], device='cuda:0')\n",
      "train_recall: tensor([0.7506, 0.8669, 0.8011, 0.7369], device='cuda:0')\n",
      "val_loss: 0.5644295632839202\n",
      "val_precision: tensor([0.7259, 0.8253, 0.7771, 0.7577], device='cuda:0')\n",
      "val_recall: tensor([0.7053, 0.8411, 0.7960, 0.6434], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 25 time:  0.32787958334999984\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.48583134639830816\n",
      "train_precision: tensor([0.7561, 0.8392, 0.8152, 0.7991], device='cuda:0')\n",
      "train_recall: tensor([0.7495, 0.8657, 0.8026, 0.7398], device='cuda:0')\n",
      "val_loss: 0.567991312344869\n",
      "val_precision: tensor([0.7237, 0.8360, 0.7669, 0.7613], device='cuda:0')\n",
      "val_recall: tensor([0.7081, 0.8260, 0.8050, 0.6380], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 26 time:  0.3286714456000008\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.482254607904525\n",
      "train_precision: tensor([0.7580, 0.8405, 0.8180, 0.7969], device='cuda:0')\n",
      "train_recall: tensor([0.7522, 0.8679, 0.8028, 0.7462], device='cuda:0')\n",
      "val_loss: 0.564926987224155\n",
      "val_precision: tensor([0.7229, 0.8302, 0.7762, 0.7638], device='cuda:0')\n",
      "val_recall: tensor([0.7114, 0.8357, 0.7961, 0.6391], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 27 time:  0.3263396291499987\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.482533103511447\n",
      "train_precision: tensor([0.7576, 0.8407, 0.8178, 0.7985], device='cuda:0')\n",
      "train_recall: tensor([0.7512, 0.8686, 0.8030, 0.7452], device='cuda:0')\n",
      "val_loss: 0.5652141061094073\n",
      "val_precision: tensor([0.7218, 0.8317, 0.7765, 0.7582], device='cuda:0')\n",
      "val_recall: tensor([0.7141, 0.8337, 0.7951, 0.6397], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 28 time:  0.3278744229000002\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.48133862245650516\n",
      "train_precision: tensor([0.7583, 0.8415, 0.8190, 0.7987], device='cuda:0')\n",
      "train_recall: tensor([0.7531, 0.8688, 0.8037, 0.7450], device='cuda:0')\n",
      "val_loss: 0.5651344034406874\n",
      "val_precision: tensor([0.7245, 0.8285, 0.7757, 0.7688], device='cuda:0')\n",
      "val_recall: tensor([0.7089, 0.8381, 0.7967, 0.6360], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 29 time:  0.3267886241166669\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.48234633264087495\n",
      "train_precision: tensor([0.7580, 0.8398, 0.8194, 0.7967], device='cuda:0')\n",
      "train_recall: tensor([0.7529, 0.8692, 0.8022, 0.7392], device='cuda:0')\n",
      "val_loss: 0.5661098632547591\n",
      "val_precision: tensor([0.7239, 0.8305, 0.7730, 0.7584], device='cuda:0')\n",
      "val_recall: tensor([0.7078, 0.8350, 0.7981, 0.6384], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 30 time:  0.3295971203499998\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'resnet18_2048batch_{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),]\n",
    ")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=2, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 2048\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "num_classes = 4\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch/60}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba7df3-b374-46fd-a065-2d32a5fbe366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
