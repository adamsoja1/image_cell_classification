{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00eca7f-8e70-4f86-97c7-f475ac2a2429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240421_162449-cb9967to</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/cb9967to' target=\"_blank\">efficient_net_b1_2024-04-21 16:24:48.826988</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/cb9967to' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/cb9967to</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.9993465444871358\n",
      "train_precision: tensor([0.4875, 0.6362, 0.5653, 0.0842], device='cuda:0')\n",
      "train_recall: tensor([0.4727, 0.7242, 0.5571, 0.0056], device='cuda:0')\n",
      "val_loss: 0.910924018919468\n",
      "val_precision: tensor([0.5435, 0.7467, 0.5464, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.3640, 0.7074, 0.8103, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  0.442259094900002\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.9047999948972747\n",
      "train_precision: tensor([0.5446, 0.6755, 0.6317, 0.2323], device='cuda:0')\n",
      "train_recall: tensor([0.5239, 0.7644, 0.6348, 0.0033], device='cuda:0')\n",
      "val_loss: 0.8498986515733931\n",
      "val_precision: tensor([0.5692, 0.7546, 0.6081, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.5135, 0.7111, 0.7634, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  0.44345843081666014\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.8620735339465595\n",
      "train_precision: tensor([0.5685, 0.6898, 0.6531, 0.4017], device='cuda:0')\n",
      "train_recall: tensor([0.5455, 0.7731, 0.6626, 0.0206], device='cuda:0')\n",
      "val_loss: 0.8216261918346087\n",
      "val_precision: tensor([0.5977, 0.7227, 0.6519, 0.5216], device='cuda:0')\n",
      "val_recall: tensor([0.5506, 0.7734, 0.7048, 0.1424], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  0.44383956621666887\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.8543249260811578\n",
      "train_precision: tensor([0.5759, 0.6879, 0.6578, 0.4611], device='cuda:0')\n",
      "train_recall: tensor([0.5417, 0.7771, 0.6692, 0.0573], device='cuda:0')\n",
      "val_loss: 0.8188749358885818\n",
      "val_precision: tensor([0.6189, 0.6649, 0.6760, 1.0000], device='cuda:0')\n",
      "val_recall: tensor([0.4913, 0.8437, 0.7007, 0.0064], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  0.4451581235333303\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.8571164182963825\n",
      "train_precision: tensor([0.5728, 0.6862, 0.6593, 0.5178], device='cuda:0')\n",
      "train_recall: tensor([0.5473, 0.7758, 0.6613, 0.0566], device='cuda:0')\n",
      "val_loss: 0.7939202066924836\n",
      "val_precision: tensor([0.6299, 0.7170, 0.6371, 0.9206], device='cuda:0')\n",
      "val_recall: tensor([0.4799, 0.8032, 0.7733, 0.0391], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  0.44585672749999505\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.822472758662133\n",
      "train_precision: tensor([0.5903, 0.7006, 0.6716, 0.5119], device='cuda:0')\n",
      "train_recall: tensor([0.5622, 0.7823, 0.6782, 0.1082], device='cuda:0')\n",
      "val_loss: 0.7850340985589557\n",
      "val_precision: tensor([0.6352, 0.7360, 0.6524, 0.6197], device='cuda:0')\n",
      "val_recall: tensor([0.5622, 0.7822, 0.7419, 0.0933], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  0.4464549929166651\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.8126191877893039\n",
      "train_precision: tensor([0.5952, 0.7045, 0.6790, 0.5552], device='cuda:0')\n",
      "train_recall: tensor([0.5693, 0.7844, 0.6825, 0.1378], device='cuda:0')\n",
      "val_loss: 0.8504240936703152\n",
      "val_precision: tensor([0.5800, 0.7498, 0.6200, 0.7718], device='cuda:0')\n",
      "val_recall: tensor([0.5274, 0.7220, 0.7491, 0.1492], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  0.4334322987000026\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.8129892594047955\n",
      "train_precision: tensor([0.5974, 0.7020, 0.6808, 0.6120], device='cuda:0')\n",
      "train_recall: tensor([0.5658, 0.7852, 0.6856, 0.1680], device='cuda:0')\n",
      "val_loss: 0.7491970001823373\n",
      "val_precision: tensor([0.6186, 0.7268, 0.7110, 0.8423], device='cuda:0')\n",
      "val_recall: tensor([0.6059, 0.7990, 0.7097, 0.1943], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  0.4477595614166679\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.7731312074121974\n",
      "train_precision: tensor([0.6138, 0.7256, 0.6943, 0.6168], device='cuda:0')\n",
      "train_recall: tensor([0.5877, 0.7915, 0.7030, 0.2423], device='cuda:0')\n",
      "val_loss: 0.7307189712093936\n",
      "val_precision: tensor([0.6342, 0.7521, 0.6976, 0.8646], device='cuda:0')\n",
      "val_recall: tensor([0.6073, 0.7894, 0.7456, 0.2064], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  0.4452524511333346\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.7887014159844035\n",
      "train_precision: tensor([0.6103, 0.7157, 0.6922, 0.6070], device='cuda:0')\n",
      "train_recall: tensor([0.5798, 0.7907, 0.6951, 0.2492], device='cuda:0')\n",
      "val_loss: 0.7498123928904533\n",
      "val_precision: tensor([0.6357, 0.7078, 0.7254, 0.8181], device='cuda:0')\n",
      "val_recall: tensor([0.5970, 0.8389, 0.6879, 0.2256], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  0.43584398649999606\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.7474317843005771\n",
      "train_precision: tensor([0.6257, 0.7362, 0.7035, 0.6195], device='cuda:0')\n",
      "train_recall: tensor([0.5986, 0.7962, 0.7116, 0.3113], device='cuda:0')\n",
      "val_loss: 0.7065995241204898\n",
      "val_precision: tensor([0.6465, 0.7645, 0.7028, 0.8038], device='cuda:0')\n",
      "val_recall: tensor([0.6316, 0.8002, 0.7300, 0.3020], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  0.44875075361666555\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.7623319487486567\n",
      "train_precision: tensor([0.6223, 0.7314, 0.7026, 0.5952], device='cuda:0')\n",
      "train_recall: tensor([0.5991, 0.7953, 0.7044, 0.2818], device='cuda:0')\n",
      "val_loss: 0.7418168236811956\n",
      "val_precision: tensor([0.6620, 0.7275, 0.6850, 0.6776], device='cuda:0')\n",
      "val_recall: tensor([0.5458, 0.8198, 0.7573, 0.2923], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  0.4417044574000026\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.7302615223895936\n",
      "train_precision: tensor([0.6325, 0.7449, 0.7115, 0.6235], device='cuda:0')\n",
      "train_recall: tensor([0.6107, 0.7998, 0.7149, 0.3494], device='cuda:0')\n",
      "val_loss: 0.6922526994513141\n",
      "val_precision: tensor([0.6540, 0.7961, 0.7007, 0.6687], device='cuda:0')\n",
      "val_recall: tensor([0.6396, 0.7728, 0.7610, 0.4357], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  0.45298482311667004\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.7072649984842255\n",
      "train_precision: tensor([0.6425, 0.7545, 0.7207, 0.6340], device='cuda:0')\n",
      "train_recall: tensor([0.6244, 0.8030, 0.7240, 0.3759], device='cuda:0')\n",
      "val_loss: 0.6842535191939937\n",
      "val_precision: tensor([0.6602, 0.7735, 0.7101, 0.7948], device='cuda:0')\n",
      "val_recall: tensor([0.6221, 0.8045, 0.7639, 0.3313], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 13 time:  0.4635495378833336\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.6974419102072715\n",
      "train_precision: tensor([0.6490, 0.7587, 0.7255, 0.6516], device='cuda:0')\n",
      "train_recall: tensor([0.6320, 0.8079, 0.7256, 0.3975], device='cuda:0')\n",
      "val_loss: 0.6897707400222619\n",
      "val_precision: tensor([0.6807, 0.7617, 0.7019, 0.7601], device='cuda:0')\n",
      "val_recall: tensor([0.5945, 0.8225, 0.7774, 0.2987], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 14 time:  0.4342026091666639\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.6899868489021347\n",
      "train_precision: tensor([0.6532, 0.7610, 0.7281, 0.6564], device='cuda:0')\n",
      "train_recall: tensor([0.6368, 0.8081, 0.7278, 0.4185], device='cuda:0')\n",
      "val_loss: 0.6643244835237662\n",
      "val_precision: tensor([0.6714, 0.7811, 0.7240, 0.8365], device='cuda:0')\n",
      "val_recall: tensor([0.6440, 0.8069, 0.7723, 0.3444], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 15 time:  0.44003027941666917\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.6811942742693992\n",
      "train_precision: tensor([0.6570, 0.7667, 0.7322, 0.6608], device='cuda:0')\n",
      "train_recall: tensor([0.6426, 0.8106, 0.7323, 0.4264], device='cuda:0')\n",
      "val_loss: 0.6604871686134074\n",
      "val_precision: tensor([0.6730, 0.8172, 0.6977, 0.7360], device='cuda:0')\n",
      "val_recall: tensor([0.6378, 0.7687, 0.8021, 0.4562], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 16 time:  0.44714170941666304\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.6697130173444747\n",
      "train_precision: tensor([0.6647, 0.7717, 0.7359, 0.6680], device='cuda:0')\n",
      "train_recall: tensor([0.6482, 0.8138, 0.7382, 0.4483], device='cuda:0')\n",
      "val_loss: 0.6554696884420183\n",
      "val_precision: tensor([0.6799, 0.8097, 0.6941, 0.8538], device='cuda:0')\n",
      "val_recall: tensor([0.6305, 0.7820, 0.8075, 0.3717], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 17 time:  0.45541348263333625\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.660447176794211\n",
      "train_precision: tensor([0.6677, 0.7752, 0.7392, 0.6734], device='cuda:0')\n",
      "train_recall: tensor([0.6517, 0.8171, 0.7392, 0.4716], device='cuda:0')\n",
      "val_loss: 0.6408899115191565\n",
      "val_precision: tensor([0.6875, 0.7906, 0.7386, 0.6422], device='cuda:0')\n",
      "val_recall: tensor([0.6476, 0.8208, 0.7636, 0.5519], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 18 time:  0.4637948164833385\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.6531430594977878\n",
      "train_precision: tensor([0.6738, 0.7775, 0.7439, 0.6751], device='cuda:0')\n",
      "train_recall: tensor([0.6578, 0.8181, 0.7443, 0.4789], device='cuda:0')\n",
      "val_loss: 0.6561044261687332\n",
      "val_precision: tensor([0.6801, 0.8068, 0.7069, 0.7423], device='cuda:0')\n",
      "val_recall: tensor([0.6454, 0.7796, 0.7925, 0.4724], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 19 time:  0.4392091815166774\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.6488188642121496\n",
      "train_precision: tensor([0.6758, 0.7784, 0.7441, 0.6861], device='cuda:0')\n",
      "train_recall: tensor([0.6607, 0.8179, 0.7451, 0.4823], device='cuda:0')\n",
      "val_loss: 0.6290566595064269\n",
      "val_precision: tensor([0.6870, 0.7941, 0.7441, 0.7611], device='cuda:0')\n",
      "val_recall: tensor([0.6778, 0.8139, 0.7630, 0.4805], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 20 time:  0.45336475438333157\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.6541500751106512\n",
      "train_precision: tensor([0.6753, 0.7753, 0.7458, 0.6671], device='cuda:0')\n",
      "train_recall: tensor([0.6597, 0.8181, 0.7428, 0.4795], device='cuda:0')\n",
      "val_loss: 0.6399093517826663\n",
      "val_precision: tensor([0.6823, 0.8096, 0.7181, 0.7203], device='cuda:0')\n",
      "val_recall: tensor([0.6428, 0.7956, 0.7944, 0.4960], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 21 time:  0.44288900085001237\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.723942426272801\n",
      "train_precision: tensor([0.6390, 0.7491, 0.7170, 0.6719], device='cuda:0')\n",
      "train_recall: tensor([0.6254, 0.8024, 0.7130, 0.3734], device='cuda:0')\n",
      "val_loss: 0.8555471441811986\n",
      "val_precision: tensor([0.5799, 0.7078, 0.6353, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.5080, 0.7751, 0.7172, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 22 time:  0.4348082169333338\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.8280478450514022\n",
      "train_precision: tensor([0.5761, 0.7128, 0.6707, 0.5315], device='cuda:0')\n",
      "train_recall: tensor([0.5674, 0.7798, 0.6735, 0.0902], device='cuda:0')\n",
      "val_loss: 0.7225216592351595\n",
      "val_precision: tensor([0.6149, 0.7855, 0.6991, 0.7689], device='cuda:0')\n",
      "val_recall: tensor([0.6382, 0.7665, 0.7326, 0.2946], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 23 time:  0.4354232082166618\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.7431486649882226\n",
      "train_precision: tensor([0.6191, 0.7445, 0.7042, 0.5945], device='cuda:0')\n",
      "train_recall: tensor([0.6068, 0.7960, 0.7046, 0.2978], device='cuda:0')\n",
      "val_loss: 0.700956349571546\n",
      "val_precision: tensor([0.6498, 0.7712, 0.7023, 0.7386], device='cuda:0')\n",
      "val_recall: tensor([0.6081, 0.8009, 0.7564, 0.3586], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 24 time:  0.42933265749999616\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.728861466050148\n",
      "train_precision: tensor([0.6287, 0.7489, 0.7099, 0.6122], device='cuda:0')\n",
      "train_recall: tensor([0.6130, 0.8003, 0.7109, 0.3351], device='cuda:0')\n",
      "val_loss: 0.685079540974564\n",
      "val_precision: tensor([0.6621, 0.7715, 0.7129, 0.7320], device='cuda:0')\n",
      "val_recall: tensor([0.6171, 0.8064, 0.7614, 0.4000], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 25 time:  0.4378526987166727\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.7120675002535184\n",
      "train_precision: tensor([0.6381, 0.7541, 0.7191, 0.6354], device='cuda:0')\n",
      "train_recall: tensor([0.6245, 0.8041, 0.7166, 0.3732], device='cuda:0')\n",
      "val_loss: 0.6718204143974517\n",
      "val_precision: tensor([0.6621, 0.7884, 0.7190, 0.7541], device='cuda:0')\n",
      "val_recall: tensor([0.6428, 0.7998, 0.7634, 0.3997], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 26 time:  0.44928777206666076\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.7020641478754225\n",
      "train_precision: tensor([0.6419, 0.7602, 0.7259, 0.6420], device='cuda:0')\n",
      "train_recall: tensor([0.6355, 0.8047, 0.7194, 0.3869], device='cuda:0')\n",
      "val_loss: 0.6749489164186848\n",
      "val_precision: tensor([0.6629, 0.8002, 0.7070, 0.7691], device='cuda:0')\n",
      "val_recall: tensor([0.6385, 0.7838, 0.7819, 0.3960], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 27 time:  0.44830286660000335\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.6996889503229232\n",
      "train_precision: tensor([0.6449, 0.7594, 0.7248, 0.6365], device='cuda:0')\n",
      "train_recall: tensor([0.6316, 0.8066, 0.7228, 0.3896], device='cuda:0')\n",
      "val_loss: 0.6708446042405234\n",
      "val_precision: tensor([0.6609, 0.8000, 0.7143, 0.7500], device='cuda:0')\n",
      "val_recall: tensor([0.6496, 0.7848, 0.7724, 0.4111], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 28 time:  0.44762651641667617\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.695552298568544\n",
      "train_precision: tensor([0.6484, 0.7605, 0.7264, 0.6452], device='cuda:0')\n",
      "train_recall: tensor([0.6349, 0.8079, 0.7242, 0.3970], device='cuda:0')\n",
      "val_loss: 0.6646228004660871\n",
      "val_precision: tensor([0.6632, 0.7882, 0.7261, 0.7509], device='cuda:0')\n",
      "val_recall: tensor([0.6491, 0.8024, 0.7603, 0.4222], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 29 time:  0.43743785198333474\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.6945106323276248\n",
      "train_precision: tensor([0.6491, 0.7612, 0.7284, 0.6473], device='cuda:0')\n",
      "train_recall: tensor([0.6363, 0.8088, 0.7241, 0.4074], device='cuda:0')\n",
      "val_loss: 0.6655597494708168\n",
      "val_precision: tensor([0.6732, 0.7891, 0.7149, 0.7658], device='cuda:0')\n",
      "val_recall: tensor([0.6336, 0.8019, 0.7791, 0.4040], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "Early stopping at epoch 30 with best validation loss 0.6290566595064269\n",
      "training_checkpoints/efficient_net_b1_2024-04-21 16:24:48.826988.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "#intecubic interpol\n",
    "\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.base_model = models.efficientnet_b1(pretrained=False)\n",
    "        num_ftrs = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "\n",
    "run_name = f'efficient_net_b1_{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),]\n",
    ")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=2, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = EfficientNetB0()\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch/60}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9649e625-064d-4c04-b6f6-beb5c67addf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[681 112 204   3]\n",
      " [102 835  59   4]\n",
      " [158  61 774   7]\n",
      " [ 25  15  10  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      1000\n",
      "           1       0.82      0.83      0.83      1000\n",
      "           2       0.74      0.77      0.76      1000\n",
      "           3       0.78      0.50      0.61       100\n",
      "\n",
      "    accuracy                           0.75      3100\n",
      "   macro avg       0.76      0.70      0.72      3100\n",
      "weighted avg       0.75      0.75      0.75      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data')\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8bc9b4-afcb-4bc7-95f0-edf410b2de55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
