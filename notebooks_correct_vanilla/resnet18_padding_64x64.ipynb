{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f79c789-4457-4457-aae6-c3bbb9dab39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c82331fe-709a-4040-95cc-a439748f8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dupa'] = [1, 2, 3, 4, 5]\n",
    "df['nazwa'] = ['a', 'b', 'c', 'd', 'f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8269f03-da65-4952-a141-56e8461676bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dupa</th>\n",
       "      <th>nazwa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dupa nazwa\n",
       "0     1     a\n",
       "1     2     b\n",
       "2     3     c\n",
       "3     4     d\n",
       "4     5     f"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f61122-6626-4fb7-9f37-b8ffe3417c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(3).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf30abe-2fb9-4ae9-bb85-d9cde5b3e17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dupa</th>\n",
       "      <th>nazwa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  dupa nazwa\n",
       "0      0     1     a\n",
       "1      1     2     b\n",
       "2      2     3     c\n",
       "3      4     5     f"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863120fc-b045-4196-9d47-705a5b975878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16e08448-0c6b-4250-bf7d-528750689841",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset('train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff7e27d3-c0ff-41e5-acb6-f3c29f3cd195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214830"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ffc041-374a-4cbe-a22f-f052b4118cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198821"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import ImageDataset\n",
    "dataset = ImageDataset('train_data')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f36e005-e6df-43ba-8857-72f35c159719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240505_155239-mriuezyk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/mriuezyk' target=\"_blank\">resnet18_base_norm_padding_64x64_without_very_small_images_2024-05-05 15:52:38.940420</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/mriuezyk' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/mriuezyk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.8904014965435406\n",
      "train_precision: tensor([0.5646, 0.6558, 0.6369, 0.5629], device='cuda:0')\n",
      "train_recall: tensor([0.5323, 0.7711, 0.6043, 0.0522], device='cuda:0')\n",
      "val_loss: 0.8040062896124236\n",
      "val_precision: tensor([0.5779, 0.7504, 0.6515, 0.7210], device='cuda:0')\n",
      "val_recall: tensor([0.5672, 0.7330, 0.7139, 0.1784], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  70.5791654679997\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.7963460704534671\n",
      "train_precision: tensor([0.6092, 0.7112, 0.6756, 0.6889], device='cuda:0')\n",
      "train_recall: tensor([0.5810, 0.7932, 0.6699, 0.1225], device='cuda:0')\n",
      "val_loss: 0.7452696681738615\n",
      "val_precision: tensor([0.6383, 0.7402, 0.6943, 0.5014], device='cuda:0')\n",
      "val_recall: tensor([0.6061, 0.7879, 0.7080, 0.2625], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  71.36216272699676\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.763433529526724\n",
      "train_precision: tensor([0.6284, 0.7232, 0.6886, 0.6872], device='cuda:0')\n",
      "train_recall: tensor([0.5924, 0.8045, 0.6887, 0.1688], device='cuda:0')\n",
      "val_loss: 0.7231554659279259\n",
      "val_precision: tensor([0.6824, 0.7856, 0.6496, 0.9010], device='cuda:0')\n",
      "val_recall: tensor([0.5686, 0.7764, 0.7975, 0.2124], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  71.53413943699707\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.7386966610046888\n",
      "train_precision: tensor([0.6428, 0.7357, 0.6975, 0.7058], device='cuda:0')\n",
      "train_recall: tensor([0.6081, 0.8095, 0.7000, 0.2227], device='cuda:0')\n",
      "val_loss: 0.6974758067288557\n",
      "val_precision: tensor([0.6691, 0.8109, 0.6770, 0.5101], device='cuda:0')\n",
      "val_recall: tensor([0.6185, 0.7692, 0.7755, 0.3563], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  71.53026482099813\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.7199989187517989\n",
      "train_precision: tensor([0.6524, 0.7423, 0.7067, 0.6914], device='cuda:0')\n",
      "train_recall: tensor([0.6148, 0.8152, 0.7118, 0.2391], device='cuda:0')\n",
      "val_loss: 0.6767220055018818\n",
      "val_precision: tensor([0.6805, 0.8172, 0.6810, 0.8594], device='cuda:0')\n",
      "val_recall: tensor([0.6295, 0.7686, 0.8033, 0.2854], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  70.75851366900315\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.7041632789289015\n",
      "train_precision: tensor([0.6626, 0.7486, 0.7132, 0.7095], device='cuda:0')\n",
      "train_recall: tensor([0.6268, 0.8181, 0.7186, 0.2581], device='cuda:0')\n",
      "val_loss: 0.6424500910011498\n",
      "val_precision: tensor([0.6873, 0.7559, 0.7685, 0.8224], device='cuda:0')\n",
      "val_recall: tensor([0.6741, 0.8503, 0.7228, 0.3106], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  71.40506487699895\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.6902830398220814\n",
      "train_precision: tensor([0.6697, 0.7550, 0.7214, 0.7088], device='cuda:0')\n",
      "train_recall: tensor([0.6360, 0.8227, 0.7257, 0.2698], device='cuda:0')\n",
      "val_loss: 0.6396227020759124\n",
      "val_precision: tensor([0.6704, 0.7868, 0.7579, 0.7539], device='cuda:0')\n",
      "val_recall: tensor([0.6823, 0.8400, 0.7218, 0.3797], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  71.20983251399593\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.6795726543534523\n",
      "train_precision: tensor([0.6738, 0.7578, 0.7259, 0.7132], device='cuda:0')\n",
      "train_recall: tensor([0.6383, 0.8253, 0.7300, 0.3006], device='cuda:0')\n",
      "val_loss: 0.6296061370465849\n",
      "val_precision: tensor([0.6948, 0.7648, 0.7651, 0.8508], device='cuda:0')\n",
      "val_recall: tensor([0.6683, 0.8617, 0.7325, 0.3160], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  71.70521619999636\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.6671825654258139\n",
      "train_precision: tensor([0.6818, 0.7634, 0.7321, 0.7340], device='cuda:0')\n",
      "train_recall: tensor([0.6459, 0.8306, 0.7365, 0.3155], device='cuda:0')\n",
      "val_loss: 0.6317000523343816\n",
      "val_precision: tensor([0.7286, 0.7735, 0.7292, 0.7399], device='cuda:0')\n",
      "val_recall: tensor([0.6019, 0.8622, 0.7924, 0.4079], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  70.58592416399915\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.6557817219767331\n",
      "train_precision: tensor([0.6882, 0.7673, 0.7379, 0.7181], device='cuda:0')\n",
      "train_recall: tensor([0.6532, 0.8314, 0.7421, 0.3383], device='cuda:0')\n",
      "val_loss: 0.6008131931851934\n",
      "val_precision: tensor([0.6828, 0.8051, 0.7854, 0.6770], device='cuda:0')\n",
      "val_recall: tensor([0.7236, 0.8376, 0.7275, 0.4565], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  71.48238488999777\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.6462377941516375\n",
      "train_precision: tensor([0.6938, 0.7702, 0.7435, 0.7290], device='cuda:0')\n",
      "train_recall: tensor([0.6591, 0.8334, 0.7476, 0.3528], device='cuda:0')\n",
      "val_loss: 0.6098243887718018\n",
      "val_precision: tensor([0.7230, 0.7824, 0.7611, 0.6632], device='cuda:0')\n",
      "val_recall: tensor([0.6677, 0.8616, 0.7603, 0.4317], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  70.19718864800234\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.6362450586169229\n",
      "train_precision: tensor([0.6984, 0.7743, 0.7454, 0.7223], device='cuda:0')\n",
      "train_recall: tensor([0.6622, 0.8355, 0.7512, 0.3731], device='cuda:0')\n",
      "val_loss: 0.6032074603053542\n",
      "val_precision: tensor([0.6882, 0.8380, 0.7481, 0.7919], device='cuda:0')\n",
      "val_recall: tensor([0.7078, 0.7887, 0.7975, 0.4088], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  70.08570239999972\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.6280658582999746\n",
      "train_precision: tensor([0.7033, 0.7775, 0.7505, 0.7267], device='cuda:0')\n",
      "train_recall: tensor([0.6693, 0.8372, 0.7549, 0.3829], device='cuda:0')\n",
      "val_loss: 0.5857050388424963\n",
      "val_precision: tensor([0.7006, 0.8180, 0.7681, 0.7426], device='cuda:0')\n",
      "val_recall: tensor([0.7081, 0.8273, 0.7718, 0.4754], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  71.56356457999937\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.6175434513058288\n",
      "train_precision: tensor([0.7066, 0.7817, 0.7556, 0.7343], device='cuda:0')\n",
      "train_recall: tensor([0.6746, 0.8398, 0.7576, 0.4122], device='cuda:0')\n",
      "val_loss: 0.582215063922756\n",
      "val_precision: tensor([0.7338, 0.7963, 0.7617, 0.7934], device='cuda:0')\n",
      "val_recall: tensor([0.6734, 0.8573, 0.7880, 0.4575], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 13 time:  71.53588969400153\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.6102824105259074\n",
      "train_precision: tensor([0.7123, 0.7831, 0.7576, 0.7327], device='cuda:0')\n",
      "train_recall: tensor([0.6772, 0.8417, 0.7616, 0.4200], device='cuda:0')\n",
      "val_loss: 0.5756802354846988\n",
      "val_precision: tensor([0.7246, 0.8407, 0.7417, 0.8233], device='cuda:0')\n",
      "val_recall: tensor([0.6919, 0.8062, 0.8279, 0.4599], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 14 time:  71.6253377940011\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.6001975885382643\n",
      "train_precision: tensor([0.7169, 0.7873, 0.7628, 0.7399], device='cuda:0')\n",
      "train_recall: tensor([0.6832, 0.8451, 0.7651, 0.4388], device='cuda:0')\n",
      "val_loss: 0.5669349274477801\n",
      "val_precision: tensor([0.7289, 0.8334, 0.7624, 0.6818], device='cuda:0')\n",
      "val_recall: tensor([0.6960, 0.8319, 0.8061, 0.5678], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 15 time:  71.443478975998\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.5914224963083844\n",
      "train_precision: tensor([0.7194, 0.7898, 0.7661, 0.7337], device='cuda:0')\n",
      "train_recall: tensor([0.6894, 0.8444, 0.7655, 0.4624], device='cuda:0')\n",
      "val_loss: 0.5579592551555004\n",
      "val_precision: tensor([0.7209, 0.8169, 0.7953, 0.6476], device='cuda:0')\n",
      "val_recall: tensor([0.7220, 0.8446, 0.7751, 0.5620], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 16 time:  71.17833956699906\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.5832699596344888\n",
      "train_precision: tensor([0.7222, 0.7901, 0.7705, 0.7475], device='cuda:0')\n",
      "train_recall: tensor([0.6902, 0.8488, 0.7677, 0.4755], device='cuda:0')\n",
      "val_loss: 0.5603159753767936\n",
      "val_precision: tensor([0.7394, 0.8133, 0.7641, 0.8045], device='cuda:0')\n",
      "val_recall: tensor([0.6821, 0.8501, 0.8086, 0.4900], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 17 time:  70.22389712299628\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.5738689892540567\n",
      "train_precision: tensor([0.7275, 0.7956, 0.7720, 0.7548], device='cuda:0')\n",
      "train_recall: tensor([0.6960, 0.8497, 0.7719, 0.4962], device='cuda:0')\n",
      "val_loss: 0.5453104096668977\n",
      "val_precision: tensor([0.7236, 0.8294, 0.7982, 0.6505], device='cuda:0')\n",
      "val_recall: tensor([0.7293, 0.8435, 0.7798, 0.6378], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 18 time:  71.2728640399946\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.5653467276918689\n",
      "train_precision: tensor([0.7310, 0.7982, 0.7776, 0.7484], device='cuda:0')\n",
      "train_recall: tensor([0.7012, 0.8513, 0.7759, 0.5034], device='cuda:0')\n",
      "val_loss: 0.5589397427914021\n",
      "val_precision: tensor([0.7322, 0.8182, 0.7754, 0.6936], device='cuda:0')\n",
      "val_recall: tensor([0.6951, 0.8472, 0.7952, 0.5809], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 19 time:  69.46528464199946\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.5572808212678558\n",
      "train_precision: tensor([0.7343, 0.8007, 0.7816, 0.7577], device='cuda:0')\n",
      "train_recall: tensor([0.7057, 0.8521, 0.7788, 0.5298], device='cuda:0')\n",
      "val_loss: 0.5643894466551932\n",
      "val_precision: tensor([0.7452, 0.8007, 0.7848, 0.7171], device='cuda:0')\n",
      "val_recall: tensor([0.6893, 0.8736, 0.7803, 0.5989], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 20 time:  68.43505554999865\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.5471613460065775\n",
      "train_precision: tensor([0.7400, 0.8053, 0.7856, 0.7649], device='cuda:0')\n",
      "train_recall: tensor([0.7106, 0.8578, 0.7818, 0.5446], device='cuda:0')\n",
      "val_loss: 0.5522495717615694\n",
      "val_precision: tensor([0.7597, 0.7847, 0.7919, 0.7456], device='cuda:0')\n",
      "val_recall: tensor([0.6741, 0.8863, 0.7883, 0.5926], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 21 time:  70.2874626460034\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.5373607176611322\n",
      "train_precision: tensor([0.7441, 0.8083, 0.7904, 0.7663], device='cuda:0')\n",
      "train_recall: tensor([0.7161, 0.8584, 0.7865, 0.5610], device='cuda:0')\n",
      "val_loss: 0.54524702263308\n",
      "val_precision: tensor([0.7468, 0.8538, 0.7554, 0.7298], device='cuda:0')\n",
      "val_recall: tensor([0.6974, 0.8186, 0.8433, 0.6106], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 22 time:  71.75373816499632\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.5284312862993974\n",
      "train_precision: tensor([0.7491, 0.8104, 0.7942, 0.7767], device='cuda:0')\n",
      "train_recall: tensor([0.7214, 0.8606, 0.7882, 0.5866], device='cuda:0')\n",
      "val_loss: 0.5371862870078903\n",
      "val_precision: tensor([0.7178, 0.8294, 0.8215, 0.6687], device='cuda:0')\n",
      "val_recall: tensor([0.7588, 0.8486, 0.7567, 0.6772], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 23 time:  71.24794315300096\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.5181754972100104\n",
      "train_precision: tensor([0.7557, 0.8138, 0.8010, 0.7757], device='cuda:0')\n",
      "train_recall: tensor([0.7283, 0.8648, 0.7934, 0.5931], device='cuda:0')\n",
      "val_loss: 0.535363855931136\n",
      "val_precision: tensor([0.7421, 0.8285, 0.7902, 0.7350], device='cuda:0')\n",
      "val_recall: tensor([0.7189, 0.8574, 0.7987, 0.5824], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 24 time:  71.65481943799386\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.508707078113826\n",
      "train_precision: tensor([0.7595, 0.8160, 0.8041, 0.7854], device='cuda:0')\n",
      "train_recall: tensor([0.7341, 0.8656, 0.7949, 0.6118], device='cuda:0')\n",
      "val_loss: 0.5370930638220217\n",
      "val_precision: tensor([0.7455, 0.8382, 0.7919, 0.6913], device='cuda:0')\n",
      "val_recall: tensor([0.7254, 0.8470, 0.8073, 0.6544], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 25 time:  69.08525278400339\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.4966142868750191\n",
      "train_precision: tensor([0.7636, 0.8218, 0.8087, 0.7935], device='cuda:0')\n",
      "train_recall: tensor([0.7408, 0.8678, 0.7994, 0.6337], device='cuda:0')\n",
      "val_loss: 0.5533158797938544\n",
      "val_precision: tensor([0.7547, 0.8354, 0.7677, 0.7269], device='cuda:0')\n",
      "val_recall: tensor([0.6936, 0.8466, 0.8236, 0.6456], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 26 time:  70.4578067830007\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.4851145785747808\n",
      "train_precision: tensor([0.7727, 0.8222, 0.8144, 0.8032], device='cuda:0')\n",
      "train_recall: tensor([0.7455, 0.8720, 0.8046, 0.6521], device='cuda:0')\n",
      "val_loss: 0.5345435936350722\n",
      "val_precision: tensor([0.7274, 0.8412, 0.8115, 0.7103], device='cuda:0')\n",
      "val_recall: tensor([0.7589, 0.8478, 0.7763, 0.6519], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 27 time:  71.442421998996\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.4757529780978248\n",
      "train_precision: tensor([0.7759, 0.8252, 0.8186, 0.8007], device='cuda:0')\n",
      "train_recall: tensor([0.7493, 0.8752, 0.8068, 0.6677], device='cuda:0')\n",
      "val_loss: 0.5440697915203221\n",
      "val_precision: tensor([0.7574, 0.8103, 0.7974, 0.8543], device='cuda:0')\n",
      "val_recall: tensor([0.7117, 0.8791, 0.8000, 0.5129], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 28 time:  69.60656126600225\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.4631780332273191\n",
      "train_precision: tensor([0.7842, 0.8301, 0.8244, 0.8272], device='cuda:0')\n",
      "train_recall: tensor([0.7587, 0.8789, 0.8121, 0.6962], device='cuda:0')\n",
      "val_loss: 0.5399406732202651\n",
      "val_precision: tensor([0.7497, 0.8270, 0.7989, 0.7646], device='cuda:0')\n",
      "val_recall: tensor([0.7202, 0.8682, 0.7989, 0.6441], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 29 time:  69.24650979999569\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.45188437097321144\n",
      "train_precision: tensor([0.7904, 0.8341, 0.8303, 0.8211], device='cuda:0')\n",
      "train_recall: tensor([0.7675, 0.8808, 0.8169, 0.6970], device='cuda:0')\n",
      "val_loss: 0.554159203449169\n",
      "val_precision: tensor([0.7572, 0.8115, 0.8115, 0.7747], device='cuda:0')\n",
      "val_recall: tensor([0.7252, 0.8834, 0.7840, 0.6368], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 30 time:  68.78363123800227\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 0.439645004702044\n",
      "train_precision: tensor([0.7964, 0.8384, 0.8360, 0.8335], device='cuda:0')\n",
      "train_recall: tensor([0.7723, 0.8860, 0.8221, 0.7179], device='cuda:0')\n",
      "val_loss: 0.5381619649248438\n",
      "val_precision: tensor([0.7361, 0.8452, 0.8085, 0.7367], device='cuda:0')\n",
      "val_recall: tensor([0.7542, 0.8513, 0.7892, 0.6665], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 31 time:  68.19018060599774\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 0.38415852284953095\n",
      "train_precision: tensor([0.8231, 0.8569, 0.8585, 0.8756], device='cuda:0')\n",
      "train_recall: tensor([0.8036, 0.8986, 0.8440, 0.7771], device='cuda:0')\n",
      "val_loss: 0.5364749630292257\n",
      "val_precision: tensor([0.7535, 0.8448, 0.8147, 0.7895], device='cuda:0')\n",
      "val_recall: tensor([0.7526, 0.8670, 0.8037, 0.6655], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 32 time:  67.95167604200105\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 0.36429885559100444\n",
      "train_precision: tensor([0.8335, 0.8652, 0.8672, 0.8885], device='cuda:0')\n",
      "train_recall: tensor([0.8146, 0.9040, 0.8542, 0.7986], device='cuda:0')\n",
      "val_loss: 0.5417894489235349\n",
      "val_precision: tensor([0.7658, 0.8439, 0.8034, 0.7820], device='cuda:0')\n",
      "val_recall: tensor([0.7333, 0.8696, 0.8185, 0.6942], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 33 time:  68.45472702600091\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 34\n",
      "train_loss: 0.3540559075820707\n",
      "train_precision: tensor([0.8414, 0.8674, 0.8692, 0.8913], device='cuda:0')\n",
      "train_recall: tensor([0.8180, 0.9067, 0.8590, 0.8160], device='cuda:0')\n",
      "val_loss: 0.55129183922802\n",
      "val_precision: tensor([0.7568, 0.8510, 0.8102, 0.7908], device='cuda:0')\n",
      "val_recall: tensor([0.7537, 0.8623, 0.8102, 0.6928], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 34 time:  68.48144868500094\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 35\n",
      "train_loss: 0.34458703343472424\n",
      "train_precision: tensor([0.8461, 0.8710, 0.8740, 0.8924], device='cuda:0')\n",
      "train_recall: tensor([0.8249, 0.9095, 0.8622, 0.8189], device='cuda:0')\n",
      "val_loss: 0.5485838019812072\n",
      "val_precision: tensor([0.7573, 0.8470, 0.8131, 0.8047], device='cuda:0')\n",
      "val_recall: tensor([0.7502, 0.8682, 0.8088, 0.6889], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 35 time:  68.14659923900035\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 36\n",
      "train_loss: 0.33703267334587633\n",
      "train_precision: tensor([0.8482, 0.8726, 0.8771, 0.8935], device='cuda:0')\n",
      "train_recall: tensor([0.8265, 0.9101, 0.8666, 0.8234], device='cuda:0')\n",
      "val_loss: 0.5582163021550164\n",
      "val_precision: tensor([0.7521, 0.8571, 0.8076, 0.7808], device='cuda:0')\n",
      "val_recall: tensor([0.7543, 0.8544, 0.8137, 0.7015], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 36 time:  66.37634596200223\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 37\n",
      "train_loss: 0.3312707853861911\n",
      "train_precision: tensor([0.8517, 0.8745, 0.8802, 0.9015], device='cuda:0')\n",
      "train_recall: tensor([0.8300, 0.9141, 0.8670, 0.8377], device='cuda:0')\n",
      "val_loss: 0.560036668190369\n",
      "val_precision: tensor([0.7558, 0.8523, 0.8152, 0.7997], device='cuda:0')\n",
      "val_recall: tensor([0.7590, 0.8620, 0.8108, 0.6908], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "Early stopping at epoch 37 with best validation loss 0.5345435936350722\n",
      "training_checkpoints/resnet18_base_norm_padding_64x64_without_very_small_images_2024-05-05 15:52:38.940420.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'resnet18_base_norm_padding_64x64_without_very_small_images_{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.01, patience=3, min_lr=0.0001, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "num_classes = 4\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8c35b5-819a-45b6-bca0-1a01b5509afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[670  89 145   7]\n",
      " [100 810  31   1]\n",
      " [149  60 731   8]\n",
      " [  7   3  13  52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       911\n",
      "           1       0.84      0.86      0.85       942\n",
      "           2       0.79      0.77      0.78       948\n",
      "           3       0.76      0.69      0.73        75\n",
      "\n",
      "    accuracy                           0.79      2876\n",
      "   macro avg       0.78      0.76      0.77      2876\n",
      "weighted avg       0.79      0.79      0.79      2876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data', transform=transform_test)\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2623fc-6cdc-4f07-b42f-044297d943be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
