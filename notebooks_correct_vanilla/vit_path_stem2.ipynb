{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc8ea71-91e6-4d57-98a7-e43091d1cffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240526_135140-v2esjwa0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/v2esjwa0' target=\"_blank\">vit_normalized_stem_patch_config_stempatch_nopadding2_8_patch2024-05-26 13:51:39.630794</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/v2esjwa0' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/v2esjwa0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 0.9351299196481705\n",
      "train_precision: tensor([0.5336, 0.6320, 0.6068, 0.6757], device='cuda:0')\n",
      "train_recall: tensor([0.4729, 0.7628, 0.6107, 0.0036], device='cuda:0')\n",
      "val_loss: 0.8607411918540796\n",
      "val_precision: tensor([0.6323, 0.7267, 0.5925, 0.6986], device='cuda:0')\n",
      "val_recall: tensor([0.4580, 0.7262, 0.8069, 0.1007], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  45.03777548500511\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 0.8492862453772908\n",
      "train_precision: tensor([0.5799, 0.6809, 0.6670, 0.5572], device='cuda:0')\n",
      "train_recall: tensor([0.5636, 0.7730, 0.6533, 0.0745], device='cuda:0')\n",
      "val_loss: 0.810562218974034\n",
      "val_precision: tensor([0.6440, 0.7481, 0.6159, 0.5480], device='cuda:0')\n",
      "val_recall: tensor([0.4616, 0.7580, 0.8173, 0.2364], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  44.97041719600384\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 0.8260380684619858\n",
      "train_precision: tensor([0.5960, 0.6910, 0.6744, 0.5446], device='cuda:0')\n",
      "train_recall: tensor([0.5711, 0.7780, 0.6677, 0.1410], device='cuda:0')\n",
      "val_loss: 0.7772083239422904\n",
      "val_precision: tensor([0.6294, 0.7257, 0.6759, 0.7061], device='cuda:0')\n",
      "val_recall: tensor([0.5684, 0.7819, 0.7316, 0.2630], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  44.62250602000131\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 0.8075159358836356\n",
      "train_precision: tensor([0.6043, 0.6986, 0.6790, 0.5487], device='cuda:0')\n",
      "train_recall: tensor([0.5745, 0.7799, 0.6788, 0.1821], device='cuda:0')\n",
      "val_loss: 0.745871728244755\n",
      "val_precision: tensor([0.6369, 0.7470, 0.7109, 0.6706], device='cuda:0')\n",
      "val_recall: tensor([0.6027, 0.7900, 0.7426, 0.3455], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  44.677783194005315\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.7941964718557539\n",
      "train_precision: tensor([0.6108, 0.7048, 0.6862, 0.5608], device='cuda:0')\n",
      "train_recall: tensor([0.5841, 0.7831, 0.6831, 0.2089], device='cuda:0')\n",
      "val_loss: 0.7779520144893064\n",
      "val_precision: tensor([0.7244, 0.6888, 0.6756, 0.4590], device='cuda:0')\n",
      "val_recall: tensor([0.4406, 0.8732, 0.7704, 0.3842], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  44.702686273994914\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.7846951294512976\n",
      "train_precision: tensor([0.6166, 0.7087, 0.6888, 0.5809], device='cuda:0')\n",
      "train_recall: tensor([0.5849, 0.7852, 0.6919, 0.2264], device='cuda:0')\n",
      "val_loss: 0.7188188926213317\n",
      "val_precision: tensor([0.6489, 0.7796, 0.6888, 0.6490], device='cuda:0')\n",
      "val_recall: tensor([0.5921, 0.7666, 0.7884, 0.3872], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  44.567694846999075\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.7780102404100554\n",
      "train_precision: tensor([0.6212, 0.7124, 0.6917, 0.5852], device='cuda:0')\n",
      "train_recall: tensor([0.5922, 0.7854, 0.6947, 0.2325], device='cuda:0')\n",
      "val_loss: 0.7375417640639677\n",
      "val_precision: tensor([0.7099, 0.7355, 0.6727, 0.5254], device='cuda:0')\n",
      "val_recall: tensor([0.5023, 0.8267, 0.8032, 0.3906], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  44.62595681699895\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.7696017906069755\n",
      "train_precision: tensor([0.6252, 0.7171, 0.6960, 0.5767], device='cuda:0')\n",
      "train_recall: tensor([0.5971, 0.7875, 0.6980, 0.2528], device='cuda:0')\n",
      "val_loss: 0.709995167536868\n",
      "val_precision: tensor([0.6719, 0.7438, 0.7259, 0.5807], device='cuda:0')\n",
      "val_recall: tensor([0.5891, 0.8312, 0.7506, 0.4168], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  44.794384099994204\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.7599223962851933\n",
      "train_precision: tensor([0.6299, 0.7198, 0.6990, 0.6003], device='cuda:0')\n",
      "train_recall: tensor([0.6006, 0.7903, 0.7013, 0.2720], device='cuda:0')\n",
      "val_loss: 0.7121063837574588\n",
      "val_precision: tensor([0.7046, 0.7303, 0.7246, 0.5727], device='cuda:0')\n",
      "val_recall: tensor([0.5626, 0.8507, 0.7621, 0.4855], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  44.67285685800016\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.7561915537431126\n",
      "train_precision: tensor([0.6293, 0.7224, 0.6981, 0.5991], device='cuda:0')\n",
      "train_recall: tensor([0.6018, 0.7895, 0.7019, 0.2726], device='cuda:0')\n",
      "val_loss: 0.695020117279556\n",
      "val_precision: tensor([0.7149, 0.7360, 0.7084, 0.6002], device='cuda:0')\n",
      "val_recall: tensor([0.5399, 0.8443, 0.7926, 0.4721], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  44.640541602995654\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.748642478457519\n",
      "train_precision: tensor([0.6339, 0.7272, 0.7021, 0.6081], device='cuda:0')\n",
      "train_recall: tensor([0.6073, 0.7911, 0.7059, 0.2964], device='cuda:0')\n",
      "val_loss: 0.7141767533289062\n",
      "val_precision: tensor([0.7328, 0.7214, 0.7075, 0.5690], device='cuda:0')\n",
      "val_recall: tensor([0.5204, 0.8691, 0.7821, 0.4529], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  44.781010029000754\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.7439046795524302\n",
      "train_precision: tensor([0.6366, 0.7263, 0.7049, 0.6108], device='cuda:0')\n",
      "train_recall: tensor([0.6091, 0.7908, 0.7087, 0.2990], device='cuda:0')\n",
      "val_loss: 0.6917790362404452\n",
      "val_precision: tensor([0.7243, 0.7547, 0.7015, 0.5558], device='cuda:0')\n",
      "val_recall: tensor([0.5422, 0.8339, 0.8068, 0.5364], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  44.6732107620046\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.7374701783061027\n",
      "train_precision: tensor([0.6416, 0.7320, 0.7057, 0.6072], device='cuda:0')\n",
      "train_recall: tensor([0.6118, 0.7946, 0.7128, 0.3101], device='cuda:0')\n",
      "val_loss: 0.6882088950110806\n",
      "val_precision: tensor([0.6854, 0.7563, 0.7518, 0.4762], device='cuda:0')\n",
      "val_recall: tensor([0.6125, 0.8345, 0.7435, 0.5428], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  44.797404123004526\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.732867538645154\n",
      "train_precision: tensor([0.6436, 0.7326, 0.7099, 0.6109], device='cuda:0')\n",
      "train_recall: tensor([0.6173, 0.7944, 0.7136, 0.3133], device='cuda:0')\n",
      "val_loss: 0.6604815731445949\n",
      "val_precision: tensor([0.6886, 0.7675, 0.7416, 0.6938], device='cuda:0')\n",
      "val_recall: tensor([0.6371, 0.8246, 0.7686, 0.4441], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 13 time:  44.682519070003764\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.7305353776330039\n",
      "train_precision: tensor([0.6449, 0.7323, 0.7091, 0.6203], device='cuda:0')\n",
      "train_recall: tensor([0.6168, 0.7952, 0.7133, 0.3225], device='cuda:0')\n",
      "val_loss: 0.6601594815651576\n",
      "val_precision: tensor([0.6723, 0.7658, 0.7600, 0.6641], device='cuda:0')\n",
      "val_recall: tensor([0.6654, 0.8299, 0.7298, 0.4407], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 14 time:  44.68772880300094\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.723368393097605\n",
      "train_precision: tensor([0.6468, 0.7364, 0.7124, 0.6161], device='cuda:0')\n",
      "train_recall: tensor([0.6193, 0.7969, 0.7166, 0.3369], device='cuda:0')\n",
      "val_loss: 0.7064788411888812\n",
      "val_precision: tensor([0.6755, 0.7824, 0.7062, 0.6819], device='cuda:0')\n",
      "val_recall: tensor([0.6049, 0.7806, 0.8053, 0.4532], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 15 time:  44.63972248200298\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.7207752566252436\n",
      "train_precision: tensor([0.6482, 0.7379, 0.7130, 0.6292], device='cuda:0')\n",
      "train_recall: tensor([0.6210, 0.7977, 0.7171, 0.3465], device='cuda:0')\n",
      "val_loss: 0.6933002337813378\n",
      "val_precision: tensor([0.7236, 0.7292, 0.7307, 0.6527], device='cuda:0')\n",
      "val_recall: tensor([0.5633, 0.8602, 0.7837, 0.4525], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 16 time:  44.63559400400118\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.7165548919921829\n",
      "train_precision: tensor([0.6503, 0.7397, 0.7167, 0.6298], device='cuda:0')\n",
      "train_recall: tensor([0.6258, 0.7995, 0.7175, 0.3511], device='cuda:0')\n",
      "val_loss: 0.689956896752119\n",
      "val_precision: tensor([0.7338, 0.7352, 0.7253, 0.5826], device='cuda:0')\n",
      "val_recall: tensor([0.5553, 0.8568, 0.7888, 0.5259], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 17 time:  44.5952029129985\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.7137204310723714\n",
      "train_precision: tensor([0.6550, 0.7403, 0.7159, 0.6351], device='cuda:0')\n",
      "train_recall: tensor([0.6261, 0.8007, 0.7202, 0.3589], device='cuda:0')\n",
      "val_loss: 0.669166111946106\n",
      "val_precision: tensor([0.7091, 0.7533, 0.7452, 0.5992], device='cuda:0')\n",
      "val_recall: tensor([0.6067, 0.8536, 0.7667, 0.4933], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 18 time:  44.63834255200345\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.7096258588490032\n",
      "train_precision: tensor([0.6580, 0.7422, 0.7171, 0.6349], device='cuda:0')\n",
      "train_recall: tensor([0.6274, 0.8019, 0.7228, 0.3681], device='cuda:0')\n",
      "val_loss: 0.6661407599846522\n",
      "val_precision: tensor([0.7182, 0.7456, 0.7501, 0.5770], device='cuda:0')\n",
      "val_recall: tensor([0.6085, 0.8473, 0.7695, 0.5222], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 19 time:  44.683208287002344\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.6809884406981014\n",
      "train_precision: tensor([0.6685, 0.7544, 0.7310, 0.6771], device='cuda:0')\n",
      "train_recall: tensor([0.6454, 0.8069, 0.7346, 0.4072], device='cuda:0')\n",
      "val_loss: 0.6466227490040991\n",
      "val_precision: tensor([0.7222, 0.7673, 0.7563, 0.6194], device='cuda:0')\n",
      "val_recall: tensor([0.6288, 0.8502, 0.7810, 0.5495], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 20 time:  44.55395898700226\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.677255972013587\n",
      "train_precision: tensor([0.6728, 0.7567, 0.7326, 0.6637], device='cuda:0')\n",
      "train_recall: tensor([0.6480, 0.8079, 0.7368, 0.4212], device='cuda:0')\n",
      "val_loss: 0.6449022588630517\n",
      "val_precision: tensor([0.7312, 0.7603, 0.7504, 0.6237], device='cuda:0')\n",
      "val_recall: tensor([0.6167, 0.8530, 0.7866, 0.5391], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 21 time:  44.241251555002236\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.6728719541714305\n",
      "train_precision: tensor([0.6739, 0.7583, 0.7323, 0.6611], device='cuda:0')\n",
      "train_recall: tensor([0.6479, 0.8107, 0.7360, 0.4247], device='cuda:0')\n",
      "val_loss: 0.644519407964415\n",
      "val_precision: tensor([0.7217, 0.7721, 0.7547, 0.5877], device='cuda:0')\n",
      "val_recall: tensor([0.6313, 0.8444, 0.7818, 0.5616], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 22 time:  44.200867253995966\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.6717306995675677\n",
      "train_precision: tensor([0.6757, 0.7574, 0.7331, 0.6670], device='cuda:0')\n",
      "train_recall: tensor([0.6460, 0.8115, 0.7394, 0.4255], device='cuda:0')\n",
      "val_loss: 0.6438051789999009\n",
      "val_precision: tensor([0.7249, 0.7802, 0.7439, 0.6214], device='cuda:0')\n",
      "val_recall: tensor([0.6282, 0.8402, 0.7959, 0.5377], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 23 time:  43.307341728999745\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.6718494764396122\n",
      "train_precision: tensor([0.6764, 0.7566, 0.7328, 0.6704], device='cuda:0')\n",
      "train_recall: tensor([0.6475, 0.8095, 0.7390, 0.4317], device='cuda:0')\n",
      "val_loss: 0.650695091817114\n",
      "val_precision: tensor([0.7313, 0.7648, 0.7482, 0.6063], device='cuda:0')\n",
      "val_recall: tensor([0.6125, 0.8540, 0.7887, 0.5559], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 24 time:  43.51792798799579\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.6677970759215809\n",
      "train_precision: tensor([0.6765, 0.7585, 0.7344, 0.6614], device='cuda:0')\n",
      "train_recall: tensor([0.6496, 0.8111, 0.7381, 0.4322], device='cuda:0')\n",
      "val_loss: 0.6524720533854431\n",
      "val_precision: tensor([0.7366, 0.7652, 0.7434, 0.5991], device='cuda:0')\n",
      "val_recall: tensor([0.6021, 0.8511, 0.7991, 0.5710], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 25 time:  43.03147338400595\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.6676814539091928\n",
      "train_precision: tensor([0.6763, 0.7601, 0.7343, 0.6627], device='cuda:0')\n",
      "train_recall: tensor([0.6500, 0.8116, 0.7388, 0.4307], device='cuda:0')\n",
      "val_loss: 0.6403306009040939\n",
      "val_precision: tensor([0.7216, 0.7798, 0.7499, 0.5881], device='cuda:0')\n",
      "val_recall: tensor([0.6311, 0.8379, 0.7903, 0.5700], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 26 time:  43.042353605000244\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.6673931421978133\n",
      "train_precision: tensor([0.6762, 0.7595, 0.7346, 0.6630], device='cuda:0')\n",
      "train_recall: tensor([0.6512, 0.8106, 0.7381, 0.4300], device='cuda:0')\n",
      "val_loss: 0.6565438817772601\n",
      "val_precision: tensor([0.7375, 0.7717, 0.7385, 0.6058], device='cuda:0')\n",
      "val_recall: tensor([0.6085, 0.8459, 0.8045, 0.5418], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 27 time:  43.00658380200184\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.6662183043502626\n",
      "train_precision: tensor([0.6761, 0.7613, 0.7343, 0.6632], device='cuda:0')\n",
      "train_recall: tensor([0.6512, 0.8122, 0.7378, 0.4333], device='cuda:0')\n",
      "val_loss: 0.6446739590830273\n",
      "val_precision: tensor([0.7400, 0.7671, 0.7461, 0.6094], device='cuda:0')\n",
      "val_recall: tensor([0.6056, 0.8545, 0.7979, 0.5983], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 28 time:  43.016976435006654\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.6634463914803096\n",
      "train_precision: tensor([0.6780, 0.7604, 0.7365, 0.6691], device='cuda:0')\n",
      "train_recall: tensor([0.6511, 0.8131, 0.7406, 0.4333], device='cuda:0')\n",
      "val_loss: 0.6536079342994425\n",
      "val_precision: tensor([0.7297, 0.7718, 0.7494, 0.6001], device='cuda:0')\n",
      "val_recall: tensor([0.6210, 0.8424, 0.7962, 0.5710], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 29 time:  43.063270382001065\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.6638704208391053\n",
      "train_precision: tensor([0.6794, 0.7617, 0.7355, 0.6662], device='cuda:0')\n",
      "train_recall: tensor([0.6515, 0.8132, 0.7407, 0.4416], device='cuda:0')\n",
      "val_loss: 0.6383376051154401\n",
      "val_precision: tensor([0.7328, 0.7734, 0.7540, 0.5972], device='cuda:0')\n",
      "val_recall: tensor([0.6279, 0.8504, 0.7900, 0.5710], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 30 time:  44.430029956994986\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 0.6646764714093435\n",
      "train_precision: tensor([0.6786, 0.7598, 0.7378, 0.6607], device='cuda:0')\n",
      "train_recall: tensor([0.6520, 0.8116, 0.7413, 0.4381], device='cuda:0')\n",
      "val_loss: 0.6506367497973972\n",
      "val_precision: tensor([0.7365, 0.7596, 0.7606, 0.5719], device='cuda:0')\n",
      "val_recall: tensor([0.6186, 0.8615, 0.7795, 0.5774], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 31 time:  44.4193090589979\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 0.6625691934710457\n",
      "train_precision: tensor([0.6772, 0.7613, 0.7367, 0.6714], device='cuda:0')\n",
      "train_recall: tensor([0.6528, 0.8108, 0.7400, 0.4459], device='cuda:0')\n",
      "val_loss: 0.6567175434695349\n",
      "val_precision: tensor([0.7453, 0.7569, 0.7466, 0.5972], device='cuda:0')\n",
      "val_recall: tensor([0.5950, 0.8618, 0.7966, 0.5751], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 32 time:  44.313329506003356\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 0.6607756224061762\n",
      "train_precision: tensor([0.6806, 0.7622, 0.7372, 0.6692], device='cuda:0')\n",
      "train_recall: tensor([0.6527, 0.8124, 0.7430, 0.4511], device='cuda:0')\n",
      "val_loss: 0.6616978674299188\n",
      "val_precision: tensor([0.7475, 0.7652, 0.7489, 0.5634], device='cuda:0')\n",
      "val_recall: tensor([0.6039, 0.8591, 0.7965, 0.5956], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 33 time:  44.280327840999234\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 34\n",
      "train_loss: 0.6619399467394466\n",
      "train_precision: tensor([0.6811, 0.7614, 0.7375, 0.6638], device='cuda:0')\n",
      "train_recall: tensor([0.6555, 0.8130, 0.7389, 0.4518], device='cuda:0')\n",
      "val_loss: 0.6521853261523777\n",
      "val_precision: tensor([0.7395, 0.7695, 0.7483, 0.5903], device='cuda:0')\n",
      "val_recall: tensor([0.6095, 0.8476, 0.8036, 0.5919], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 34 time:  44.21917850099999\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 35\n",
      "train_loss: 0.6603624535458429\n",
      "train_precision: tensor([0.6804, 0.7624, 0.7371, 0.6680], device='cuda:0')\n",
      "train_recall: tensor([0.6551, 0.8131, 0.7393, 0.4518], device='cuda:0')\n",
      "val_loss: 0.6586719684302806\n",
      "val_precision: tensor([0.7536, 0.7622, 0.7412, 0.5713], device='cuda:0')\n",
      "val_recall: tensor([0.5874, 0.8602, 0.8065, 0.5936], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 35 time:  44.3473203120011\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 36\n",
      "train_loss: 0.6564656388901529\n",
      "train_precision: tensor([0.6843, 0.7640, 0.7395, 0.6767], device='cuda:0')\n",
      "train_recall: tensor([0.6545, 0.8163, 0.7456, 0.4521], device='cuda:0')\n",
      "val_loss: 0.644863869332605\n",
      "val_precision: tensor([0.7342, 0.7744, 0.7530, 0.5881], device='cuda:0')\n",
      "val_recall: tensor([0.6248, 0.8477, 0.7934, 0.5912], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 36 time:  44.39514974899794\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 37\n",
      "train_loss: 0.656626710437593\n",
      "train_precision: tensor([0.6830, 0.7633, 0.7383, 0.6774], device='cuda:0')\n",
      "train_recall: tensor([0.6547, 0.8133, 0.7442, 0.4590], device='cuda:0')\n",
      "val_loss: 0.6510996138883962\n",
      "val_precision: tensor([0.7426, 0.7651, 0.7550, 0.5915], device='cuda:0')\n",
      "val_recall: tensor([0.6137, 0.8582, 0.7950, 0.5842], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 37 time:  44.80737791499996\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 38\n",
      "train_loss: 0.6557332789614088\n",
      "train_precision: tensor([0.6860, 0.7644, 0.7391, 0.6753], device='cuda:0')\n",
      "train_recall: tensor([0.6578, 0.8155, 0.7444, 0.4519], device='cuda:0')\n",
      "val_loss: 0.6493710325823889\n",
      "val_precision: tensor([0.7448, 0.7666, 0.7506, 0.5943], device='cuda:0')\n",
      "val_recall: tensor([0.6102, 0.8557, 0.7993, 0.5919], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 38 time:  44.2886465929987\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 39\n",
      "train_loss: 0.6562604914108913\n",
      "train_precision: tensor([0.6841, 0.7654, 0.7392, 0.6691], device='cuda:0')\n",
      "train_recall: tensor([0.6568, 0.8144, 0.7448, 0.4560], device='cuda:0')\n",
      "val_loss: 0.6498417451977729\n",
      "val_precision: tensor([0.7384, 0.7683, 0.7550, 0.5830], device='cuda:0')\n",
      "val_recall: tensor([0.6177, 0.8527, 0.7935, 0.5987], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 39 time:  44.22042183599842\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 40\n",
      "train_loss: 0.6546183563414074\n",
      "train_precision: tensor([0.6839, 0.7662, 0.7391, 0.6763], device='cuda:0')\n",
      "train_recall: tensor([0.6572, 0.8164, 0.7432, 0.4592], device='cuda:0')\n",
      "val_loss: 0.6468094814982679\n",
      "val_precision: tensor([0.7360, 0.7762, 0.7510, 0.5962], device='cuda:0')\n",
      "val_recall: tensor([0.6222, 0.8482, 0.7973, 0.5970], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "Early stopping at epoch 40 with best validation loss 0.6383376051154401\n",
      "training_checkpoints/vit_normalized_stem_patch_config_stempatch_nopadding2_8_patch2024-05-26 13:51:39.630794.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet50\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "from vit.vit import VisionTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'vit_normalized_stem_patch_config_stempatch_nopadding2_8_patch{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=2), MedianBlur(blur_limit=2), GaussianBlur(blur_limit=2),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=4, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        wandb.log({'f1_score': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "        wandb.log({'f1_score_val': (main_metrics_recall + main_metrics_precision )/ 2}, step=self.step)\n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 128\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = VisionTransformer(image_size=32, \n",
    "                          in_channels=3, \n",
    "                          num_classes=4, \n",
    "                          dropout_rate=0.2,\n",
    "                          embedding_dim=64,\n",
    "                          patch_size=8,\n",
    "                          num_layers=3,\n",
    "                          num_heads=2,\n",
    "                          use_linear_patch=False,\n",
    "                          use_conv_stem=True,\n",
    "                          hidden_dims = [32, 32],\n",
    "                          use_conv_patch=False)\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243822c-efb9-4979-8b18-e26772b6aed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
