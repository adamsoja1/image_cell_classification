{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b14d39-3de2-4b4c-93d7-f65a87c82dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240423_010455-jirsx6pv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/jirsx6pv' target=\"_blank\">resnet18_256_weighted_2024-04-23 01:04:54.949442</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/jirsx6pv' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/jirsx6pv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 1.621198643673034\n",
      "train_precision: tensor([0.5584, 0.6920, 0.6504, 0.7460], device='cuda:0')\n",
      "train_recall: tensor([0.5541, 0.7652, 0.6476, 0.0466], device='cuda:0')\n",
      "val_loss: 1.495637300444974\n",
      "val_precision: tensor([0.5957, 0.6973, 0.7319, 0.5083], device='cuda:0')\n",
      "val_recall: tensor([0.6138, 0.8182, 0.6261, 0.2074], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  0.33076351446666197\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 1.4836405788149152\n",
      "train_precision: tensor([0.6020, 0.7234, 0.6862, 0.7808], device='cuda:0')\n",
      "train_recall: tensor([0.5938, 0.7885, 0.6902, 0.1382], device='cuda:0')\n",
      "val_loss: 1.4560136829813322\n",
      "val_precision: tensor([0.5830, 0.6943, 0.7953, 0.8163], device='cuda:0')\n",
      "val_recall: tensor([0.6834, 0.8403, 0.5472, 0.2394], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  0.33954149568332925\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 1.4125389455329804\n",
      "train_precision: tensor([0.6203, 0.7407, 0.7029, 0.7840], device='cuda:0')\n",
      "train_recall: tensor([0.6157, 0.7998, 0.7035, 0.2089], device='cuda:0')\n",
      "val_loss: 1.5603369216124217\n",
      "val_precision: tensor([0.6602, 0.7951, 0.5760, 0.7568], device='cuda:0')\n",
      "val_recall: tensor([0.4284, 0.7356, 0.8646, 0.1875], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  0.3195012633000033\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 1.3648484440076918\n",
      "train_precision: tensor([0.6369, 0.7494, 0.7131, 0.7849], device='cuda:0')\n",
      "train_recall: tensor([0.6277, 0.8051, 0.7175, 0.2659], device='cuda:0')\n",
      "val_loss: 1.3410211617747942\n",
      "val_precision: tensor([0.6179, 0.7356, 0.7794, 0.8783], device='cuda:0')\n",
      "val_recall: tensor([0.6935, 0.8459, 0.6214, 0.2673], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  0.3397375016999983\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 1.3262975887173698\n",
      "train_precision: tensor([0.6476, 0.7582, 0.7186, 0.7917], device='cuda:0')\n",
      "train_recall: tensor([0.6384, 0.8110, 0.7237, 0.2961], device='cuda:0')\n",
      "val_loss: 1.3276183976067437\n",
      "val_precision: tensor([0.6662, 0.6945, 0.7804, 0.7669], device='cuda:0')\n",
      "val_recall: tensor([0.6157, 0.8967, 0.6512, 0.3865], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  0.33827432025000237\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 1.2986287007729211\n",
      "train_precision: tensor([0.6574, 0.7620, 0.7289, 0.7846], device='cuda:0')\n",
      "train_recall: tensor([0.6475, 0.8166, 0.7314, 0.3133], device='cuda:0')\n",
      "val_loss: 1.356904650727908\n",
      "val_precision: tensor([0.5911, 0.8528, 0.7256, 0.6519], device='cuda:0')\n",
      "val_recall: tensor([0.7347, 0.7000, 0.7031, 0.4401], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  0.32020434399999737\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 1.2698436641976947\n",
      "train_precision: tensor([0.6649, 0.7705, 0.7336, 0.8001], device='cuda:0')\n",
      "train_recall: tensor([0.6573, 0.8195, 0.7375, 0.3390], device='cuda:0')\n",
      "val_loss: 1.3407149463891983\n",
      "val_precision: tensor([0.6889, 0.7158, 0.7396, 0.8493], device='cuda:0')\n",
      "val_recall: tensor([0.5960, 0.8670, 0.7344, 0.2599], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  0.31950851033333644\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 1.2436510636692955\n",
      "train_precision: tensor([0.6729, 0.7747, 0.7405, 0.8077], device='cuda:0')\n",
      "train_recall: tensor([0.6630, 0.8262, 0.7431, 0.3618], device='cuda:0')\n",
      "val_loss: 1.4618083693914943\n",
      "val_precision: tensor([0.6087, 0.8421, 0.6370, 0.6188], device='cuda:0')\n",
      "val_recall: tensor([0.6241, 0.6674, 0.7769, 0.3859], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 7 time:  0.3202141915000008\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 1.1577572412434078\n",
      "train_precision: tensor([0.6971, 0.7924, 0.7619, 0.8188], device='cuda:0')\n",
      "train_recall: tensor([0.6882, 0.8390, 0.7628, 0.4323], device='cuda:0')\n",
      "val_loss: 1.1797126099467277\n",
      "val_precision: tensor([0.6965, 0.8417, 0.7085, 0.8640], device='cuda:0')\n",
      "val_recall: tensor([0.6639, 0.7839, 0.8273, 0.4128], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 8 time:  0.33862037271667306\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 1.1316720599219912\n",
      "train_precision: tensor([0.7024, 0.7988, 0.7684, 0.8241], device='cuda:0')\n",
      "train_recall: tensor([0.6969, 0.8414, 0.7683, 0.4496], device='cuda:0')\n",
      "val_loss: 1.1503257277939054\n",
      "val_precision: tensor([0.7152, 0.7665, 0.7746, 0.8707], device='cuda:0')\n",
      "val_recall: tensor([0.6662, 0.8750, 0.7584, 0.4172], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 9 time:  0.33897821758332614\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 1.1212871332963308\n",
      "train_precision: tensor([0.7056, 0.8008, 0.7712, 0.8249], device='cuda:0')\n",
      "train_recall: tensor([0.7008, 0.8435, 0.7702, 0.4527], device='cuda:0')\n",
      "val_loss: 1.1131616840759913\n",
      "val_precision: tensor([0.7136, 0.8062, 0.7588, 0.8531], device='cuda:0')\n",
      "val_recall: tensor([0.6814, 0.8463, 0.7903, 0.4596], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 10 time:  0.3386226097666698\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 1.1065398732111567\n",
      "train_precision: tensor([0.7102, 0.8039, 0.7740, 0.8297], device='cuda:0')\n",
      "train_recall: tensor([0.7049, 0.8452, 0.7738, 0.4683], device='cuda:0')\n",
      "val_loss: 1.103065599501133\n",
      "val_precision: tensor([0.6976, 0.8153, 0.7804, 0.8410], device='cuda:0')\n",
      "val_recall: tensor([0.7232, 0.8395, 0.7625, 0.4754], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 11 time:  0.3388580001833361\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 1.0976491043965022\n",
      "train_precision: tensor([0.7098, 0.8054, 0.7763, 0.8239], device='cuda:0')\n",
      "train_recall: tensor([0.7063, 0.8457, 0.7746, 0.4707], device='cuda:0')\n",
      "val_loss: 1.1184180710050795\n",
      "val_precision: tensor([0.6873, 0.7979, 0.8023, 0.8579], device='cuda:0')\n",
      "val_recall: tensor([0.7378, 0.8506, 0.7272, 0.4633], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 12 time:  0.31925519763333343\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 1.086496195622853\n",
      "train_precision: tensor([0.7153, 0.8085, 0.7787, 0.8237], device='cuda:0')\n",
      "train_recall: tensor([0.7110, 0.8484, 0.7775, 0.4792], device='cuda:0')\n",
      "val_loss: 1.100016578535239\n",
      "val_precision: tensor([0.7047, 0.8160, 0.7728, 0.8402], device='cuda:0')\n",
      "val_recall: tensor([0.7119, 0.8401, 0.7756, 0.4761], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 13 time:  0.33910851403333403\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 1.075099692600114\n",
      "train_precision: tensor([0.7158, 0.8108, 0.7814, 0.8306], device='cuda:0')\n",
      "train_recall: tensor([0.7144, 0.8487, 0.7787, 0.4874], device='cuda:0')\n",
      "val_loss: 1.096599255171087\n",
      "val_precision: tensor([0.7053, 0.8086, 0.7809, 0.8321], device='cuda:0')\n",
      "val_recall: tensor([0.7140, 0.8468, 0.7673, 0.4805], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 14 time:  0.33954907638333226\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 1.0703129749212945\n",
      "train_precision: tensor([0.7173, 0.8117, 0.7817, 0.8286], device='cuda:0')\n",
      "train_recall: tensor([0.7135, 0.8504, 0.7802, 0.4924], device='cuda:0')\n",
      "val_loss: 1.0959872017304102\n",
      "val_precision: tensor([0.7109, 0.8034, 0.7788, 0.8569], device='cuda:0')\n",
      "val_recall: tensor([0.7057, 0.8549, 0.7695, 0.4737], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 15 time:  0.3407488863000026\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 1.060351280371348\n",
      "train_precision: tensor([0.7203, 0.8131, 0.7855, 0.8364], device='cuda:0')\n",
      "train_recall: tensor([0.7183, 0.8507, 0.7828, 0.5000], device='cuda:0')\n",
      "val_loss: 1.1082732881108919\n",
      "val_precision: tensor([0.7184, 0.8310, 0.7398, 0.8625], device='cuda:0')\n",
      "val_recall: tensor([0.6832, 0.8257, 0.8153, 0.4603], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 16 time:  0.31965064325000486\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 1.050871412243162\n",
      "train_precision: tensor([0.7221, 0.8157, 0.7872, 0.8336], device='cuda:0')\n",
      "train_recall: tensor([0.7218, 0.8519, 0.7839, 0.5025], device='cuda:0')\n",
      "val_loss: 1.0869412523176936\n",
      "val_precision: tensor([0.7163, 0.8232, 0.7661, 0.8401], device='cuda:0')\n",
      "val_recall: tensor([0.7049, 0.8351, 0.7989, 0.4936], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 17 time:  0.3382534056333346\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 1.0400458223762967\n",
      "train_precision: tensor([0.7259, 0.8168, 0.7908, 0.8350], device='cuda:0')\n",
      "train_recall: tensor([0.7251, 0.8548, 0.7860, 0.5062], device='cuda:0')\n",
      "val_loss: 1.0844149379266632\n",
      "val_precision: tensor([0.7072, 0.8132, 0.7855, 0.8540], device='cuda:0')\n",
      "val_recall: tensor([0.7245, 0.8483, 0.7663, 0.4865], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 18 time:  0.33992712523333163\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 1.0317474941412608\n",
      "train_precision: tensor([0.7276, 0.8181, 0.7927, 0.8431], device='cuda:0')\n",
      "train_recall: tensor([0.7279, 0.8552, 0.7873, 0.5149], device='cuda:0')\n",
      "val_loss: 1.1275112706753943\n",
      "val_precision: tensor([0.7405, 0.8048, 0.7347, 0.8591], device='cuda:0')\n",
      "val_recall: tensor([0.6433, 0.8516, 0.8231, 0.4535], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 19 time:  0.31968670168333424\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 1.0220166923744338\n",
      "train_precision: tensor([0.7316, 0.8197, 0.7941, 0.8340], device='cuda:0')\n",
      "train_recall: tensor([0.7300, 0.8567, 0.7904, 0.5156], device='cuda:0')\n",
      "val_loss: 1.1424328158299129\n",
      "val_precision: tensor([0.7197, 0.8468, 0.7150, 0.8263], device='cuda:0')\n",
      "val_recall: tensor([0.6677, 0.7992, 0.8369, 0.4788], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 20 time:  0.31940434358333886\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 1.0100655224351656\n",
      "train_precision: tensor([0.7335, 0.8222, 0.7951, 0.8361], device='cuda:0')\n",
      "train_recall: tensor([0.7311, 0.8588, 0.7918, 0.5278], device='cuda:0')\n",
      "val_loss: 1.1018490607539813\n",
      "val_precision: tensor([0.7206, 0.8358, 0.7478, 0.8170], device='cuda:0')\n",
      "val_recall: tensor([0.6892, 0.8241, 0.8199, 0.4990], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 21 time:  0.32036667301667116\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.9892663312809807\n",
      "train_precision: tensor([0.7390, 0.8256, 0.8022, 0.8425], device='cuda:0')\n",
      "train_recall: tensor([0.7378, 0.8622, 0.7969, 0.5395], device='cuda:0')\n",
      "val_loss: 1.0774091164271036\n",
      "val_precision: tensor([0.7199, 0.8246, 0.7747, 0.8245], device='cuda:0')\n",
      "val_recall: tensor([0.7140, 0.8421, 0.7945, 0.5061], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 22 time:  0.33872907276666714\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.9818182700446674\n",
      "train_precision: tensor([0.7416, 0.8277, 0.8031, 0.8466], device='cuda:0')\n",
      "train_recall: tensor([0.7402, 0.8640, 0.7986, 0.5385], device='cuda:0')\n",
      "val_loss: 1.0747444086604647\n",
      "val_precision: tensor([0.7214, 0.8216, 0.7783, 0.8216], device='cuda:0')\n",
      "val_recall: tensor([0.7158, 0.8464, 0.7900, 0.5131], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 23 time:  0.34008720500000134\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.9834697941229457\n",
      "train_precision: tensor([0.7414, 0.8272, 0.8030, 0.8455], device='cuda:0')\n",
      "train_recall: tensor([0.7400, 0.8624, 0.7991, 0.5434], device='cuda:0')\n",
      "val_loss: 1.0774639853172832\n",
      "val_precision: tensor([0.7253, 0.8255, 0.7674, 0.8385], device='cuda:0')\n",
      "val_recall: tensor([0.7048, 0.8426, 0.8046, 0.4946], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 24 time:  0.319676458933327\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.9807509689103989\n",
      "train_precision: tensor([0.7413, 0.8287, 0.8041, 0.8479], device='cuda:0')\n",
      "train_recall: tensor([0.7416, 0.8634, 0.7987, 0.5456], device='cuda:0')\n",
      "val_loss: 1.0790363808472951\n",
      "val_precision: tensor([0.7319, 0.8223, 0.7636, 0.8216], device='cuda:0')\n",
      "val_recall: tensor([0.6939, 0.8464, 0.8090, 0.5195], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 25 time:  0.31956230765000176\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.9764704558111372\n",
      "train_precision: tensor([0.7430, 0.8284, 0.8033, 0.8505], device='cuda:0')\n",
      "train_recall: tensor([0.7398, 0.8644, 0.8003, 0.5506], device='cuda:0')\n",
      "val_loss: 1.0795914004246394\n",
      "val_precision: tensor([0.7207, 0.8260, 0.7726, 0.8364], device='cuda:0')\n",
      "val_recall: tensor([0.7138, 0.8412, 0.7965, 0.5044], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 26 time:  0.31928335439999955\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.9768760266758146\n",
      "train_precision: tensor([0.7438, 0.8289, 0.8045, 0.8465], device='cuda:0')\n",
      "train_recall: tensor([0.7426, 0.8640, 0.7995, 0.5531], device='cuda:0')\n",
      "val_loss: 1.076313201420837\n",
      "val_precision: tensor([0.7213, 0.8244, 0.7758, 0.8301], device='cuda:0')\n",
      "val_recall: tensor([0.7155, 0.8431, 0.7941, 0.5131], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 27 time:  0.31923985406666966\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.9773025318980217\n",
      "train_precision: tensor([0.7432, 0.8291, 0.8050, 0.8478], device='cuda:0')\n",
      "train_recall: tensor([0.7422, 0.8641, 0.8004, 0.5514], device='cuda:0')\n",
      "val_loss: 1.0802557834320599\n",
      "val_precision: tensor([0.7215, 0.8354, 0.7609, 0.8374], device='cuda:0')\n",
      "val_recall: tensor([0.7092, 0.8284, 0.8100, 0.5098], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 28 time:  0.3190814168833337\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.9755555257201195\n",
      "train_precision: tensor([0.7441, 0.8296, 0.8038, 0.8439], device='cuda:0')\n",
      "train_recall: tensor([0.7431, 0.8646, 0.7987, 0.5524], device='cuda:0')\n",
      "val_loss: 1.0798033060299026\n",
      "val_precision: tensor([0.7187, 0.8327, 0.7680, 0.8413], device='cuda:0')\n",
      "val_recall: tensor([0.7156, 0.8324, 0.8022, 0.5067], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 29 time:  0.3186936765666663\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'resnet18_256_weighted_{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),]\n",
    ")\n",
    "\n",
    "\n",
    "weights = torch.tensor([2.0, 2.0, 2.0, 1.0])\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=2, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "num_classes = 4\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(model.fc.in_features, num_classes))\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch/60}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee5648-1bef-4988-86d8-89aba45d5d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
