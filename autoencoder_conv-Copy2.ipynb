{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02458ea-ae80-48ed-b9f3-b2747232bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        path = []\n",
    "        classes = []\n",
    "        for image_class in os.listdir('cells_final'):\n",
    "            for img in os.listdir(f'cells_final/{image_class}'):\n",
    "                path.append(f'cells_final/{image_class}/{img}')\n",
    "                classes.append(image_class)\n",
    "\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['path'] = path\n",
    "        dataset_final['class'] = classes\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"path\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        #image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset['class'].loc[idx]\n",
    "\n",
    "        if target.strip() == 'normal':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target.strip() == 'inflammatory':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target.strip() == 'tumor':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target.strip() == 'other':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0082330-1335-4321-a3a9-fb6463c20617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # [3, 32, 32] -> [16, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # [16, 16, 16] -> [32, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # [32, 8, 8] -> [64, 4, 4]\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, 128) , # Flatten and reduce to latent space\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 64 * 4 * 4) , # Expand back to match the flattened input size\n",
    "            nn.Unflatten(dim=1, unflattened_size=(64, 4, 4)),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # [64, 4, 4] -> [32, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),  # [32, 8, 8] -> [16, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),   # [16, 16, 16] -> [3, 32, 32]\n",
    "            nn.Sigmoid(),  # To ensure the output pixel values are between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "model = ConvAutoencoder()\n",
    "\n",
    "# Sample input\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "reconstructed_img = model(x)\n",
    "\n",
    "print(reconstructed_img.shape)  # Should output torch.Size([1, 3, 32, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e49822e-7d64-42a0-8568-19a61c89334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f8bd1-7fa3-42e4-9ec9-635772b8bb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "Epoch 0 Average Loss: 0.021730402668349837\n",
      "Saved new best model with loss 0.021730402668349837\n",
      "Epoch 0 time: 0.10827679341665923 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "Epoch 1 Average Loss: 0.006779211135213508\n",
      "Saved new best model with loss 0.006779211135213508\n",
      "Epoch 1 time: 0.10665459533332372 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "Epoch 2 Average Loss: 0.004764272828316807\n",
      "Saved new best model with loss 0.004764272828316807\n",
      "Epoch 2 time: 0.10788177176665764 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "Epoch 3 Average Loss: 0.003518439017505826\n",
      "Saved new best model with loss 0.003518439017505826\n",
      "Epoch 3 time: 0.10754923578333546 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "Epoch 4 Average Loss: 0.0028208050965699122\n",
      "Saved new best model with loss 0.0028208050965699122\n",
      "Epoch 4 time: 0.10711738325000321 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "Epoch 5 Average Loss: 0.002488949100217341\n",
      "Saved new best model with loss 0.002488949100217341\n",
      "Epoch 5 time: 0.10859462231666536 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "Epoch 6 Average Loss: 0.002198856123294191\n",
      "Saved new best model with loss 0.002198856123294191\n",
      "Epoch 6 time: 0.10745701718333293 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "Epoch 7 Average Loss: 0.0019821133296078954\n",
      "Saved new best model with loss 0.0019821133296078954\n",
      "Epoch 7 time: 0.10747525850000178 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "Epoch 8 Average Loss: 0.0018229156374122556\n",
      "Saved new best model with loss 0.0018229156374122556\n",
      "Epoch 8 time: 0.10708018908333845 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "Epoch 9 Average Loss: 0.0017305073515193439\n",
      "Saved new best model with loss 0.0017305073515193439\n",
      "Epoch 9 time: 0.1083218383999944 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "Epoch 10 Average Loss: 0.001627298914459779\n",
      "Saved new best model with loss 0.001627298914459779\n",
      "Epoch 10 time: 0.10869571951667846 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "Epoch 11 Average Loss: 0.001551420738044391\n",
      "Saved new best model with loss 0.001551420738044391\n",
      "Epoch 11 time: 0.10957308648333614 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "Epoch 12 Average Loss: 0.0015029197070122648\n",
      "Saved new best model with loss 0.0015029197070122648\n",
      "Epoch 12 time: 0.11132117818333427 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "Epoch 13 Average Loss: 0.001440734869806635\n",
      "Saved new best model with loss 0.001440734869806635\n",
      "Epoch 13 time: 0.10829471248334813 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "Epoch 14 Average Loss: 0.0013713872804625058\n",
      "Saved new best model with loss 0.0013713872804625058\n",
      "Epoch 14 time: 0.10813102211667076 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "Epoch 15 Average Loss: 0.0013249393883406331\n",
      "Saved new best model with loss 0.0013249393883406331\n",
      "Epoch 15 time: 0.10746396791666181 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "Epoch 16 Average Loss: 0.0012947196557529662\n",
      "Saved new best model with loss 0.0012947196557529662\n",
      "Epoch 16 time: 0.10778321853332878 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "Epoch 17 Average Loss: 0.0012556533497684683\n",
      "Saved new best model with loss 0.0012556533497684683\n",
      "Epoch 17 time: 0.1092934364333208 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "Epoch 18 Average Loss: 0.0012103876897048107\n",
      "Saved new best model with loss 0.0012103876897048107\n",
      "Epoch 18 time: 0.10946049373333153 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Initialize WandB\n",
    "run_name = f'conv_autoencoder_training_{datetime.datetime.now()}'\n",
    "\n",
    "# Configuration\n",
    "batch_size = 2048\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 200\n",
    "early_stop_patience = 15  # Number of epochs to wait for improvement\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "# DataLoader\n",
    "trainset = ImageDataset(data_path='train_data')\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "criterion = nn.MSELoss().to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Early Stopping\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    time_start = time.perf_counter()\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, _) in enumerate(trainloader):\n",
    "        inputs = inputs.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)  # Reconstruction loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(trainloader)\n",
    "    print(f'Epoch {epoch} Average Loss: {avg_loss}')\n",
    "    \n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), f'{run_path}.pth')\n",
    "        print(f'Saved new best model with loss {best_loss}')\n",
    "        patience_counter = 0  # Reset patience counter\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f'Early stopping at epoch {epoch} with best loss {best_loss}')\n",
    "        break\n",
    "    \n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'Epoch {epoch} time: {time_epoch/60} minutes')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'Loading model from {run_path}.pth')\n",
    "model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081ee83-45bc-4398-a7b1-0c444c5eba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{run_path}.pth'))\n",
    "features = []\n",
    "classes = []\n",
    "paths = []\n",
    "model.eval()\n",
    "trainset = ImageDataset(data_path='train_data')\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "model = model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    for idx in range(0, len(trainset)-1):\n",
    "        img, cls = trainset[idx]\n",
    "        classes.append(cls.cpu().detach().numpy())\n",
    "        feature = model.encoder(img.to('cuda').reshape(1, 3, 32, 32))\n",
    "        features.append(feature.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83477d2d-a936-46da-b622-94880b4c3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = np.argmax(np.array(classes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a12b6f-df9d-4747-bcee-04f543c94f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dfe3c-4f72-4bb0-b163-59a466ca86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [feature[0] for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfac9ec-f7a0-4aec-9847-717a25c60334",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516c03d-97c6-4929-9d6c-74237240cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap.umap_ as umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ea9ff-c13d-4a89-a083-555ee70e8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "arr = scaler.fit_transform(np.array(arr))\n",
    "\n",
    "tsne = TSNE(n_components=3, metric=\"euclidean\", n_jobs=-1, perplexity=3.0, early_exaggeration=30)\n",
    "tsne_embs = tsne.fit_transform(np.array(arr))\n",
    "df['tsne_x'] = tsne_embs[:, 0]\n",
    "df['tsne_y'] = tsne_embs[:, 1]\n",
    "df['tsne_z'] = tsne_embs[:, 2]\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_embs = pca.fit_transform(np.array(arr))\n",
    "df['pca_x'] = pca_embs[:, 0]\n",
    "df['pca_y'] = pca_embs[:, 1]\n",
    "df['pca_z'] = pca_embs[:, 2]\n",
    "\n",
    "# UMAP\n",
    "umap_reducer = umap.UMAP(n_components=3, metric=\"euclidean\", n_jobs=-1)\n",
    "umap_embs = umap_reducer.fit_transform(np.array(arr))\n",
    "df['umap_x'] = umap_embs[:, 0]\n",
    "df['umap_y'] = umap_embs[:, 1]\n",
    "df['umap_z'] = umap_embs[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aef978-bde9-4ff2-a59c-41438c5c62a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca805fc-3f37-4c7b-a2fd-3167125574e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = cls\n",
    "\n",
    "# Define figure size and number of subplots\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# t-SNE plot\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "sc = ax1.scatter(df['tsne_x'], df['tsne_y'], df['tsne_z'], c=df['class'], cmap='tab10', alpha=0.1)\n",
    "ax1.set_title('3D t-SNE')\n",
    "ax1.set_xlabel('tsne_x')\n",
    "ax1.set_ylabel('tsne_y')\n",
    "ax1.set_zlabel('tsne_z')\n",
    "plt.colorbar(sc, ax=ax1)\n",
    "\n",
    "# PCA plot\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "sc = ax2.scatter(df['pca_x'], df['pca_y'], df['pca_z'], c=df['class'], cmap='tab10', alpha=0.1)\n",
    "ax2.set_title('3D PCA')\n",
    "ax2.set_xlabel('pca_x')\n",
    "ax2.set_ylabel('pca_y')\n",
    "ax2.set_zlabel('pca_z')\n",
    "plt.colorbar(sc, ax=ax2)\n",
    "\n",
    "# UMAP plot\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "sc = ax3.scatter(df['umap_x'], df['umap_y'], df['umap_z'], c=df['class'], cmap='tab10', alpha=0.1)\n",
    "ax3.set_title('3D UMAP')\n",
    "ax3.set_xlabel('umap_x')\n",
    "ax3.set_ylabel('umap_y')\n",
    "ax3.set_zlabel('umap_z')\n",
    "plt.colorbar(sc, ax=ax3)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ad8d9-ae87-4023-8986-256abde46c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('res_red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cd62f-a8c8-474a-83cd-f60719b0da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define figure size and number of subplots\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 2D t-SNE plot\n",
    "ax1 = fig.add_subplot(131)\n",
    "sc = ax1.scatter(df['tsne_y'], df['tsne_z'], c=df['class'], cmap='tab10', alpha=0.5)\n",
    "ax1.set_title('2D t-SNE')\n",
    "ax1.set_xlabel('tsne_x')\n",
    "ax1.set_ylabel('tsne_y')\n",
    "plt.colorbar(sc, ax=ax1)\n",
    "\n",
    "# 2D PCA plot\n",
    "ax2 = fig.add_subplot(132)\n",
    "sc = ax2.scatter(df['pca_y'], df['pca_z'], c=df['class'], cmap='tab10', alpha=0.5)\n",
    "ax2.set_title('2D PCA')\n",
    "ax2.set_xlabel('pca_x')\n",
    "ax2.set_ylabel('pca_y')\n",
    "plt.colorbar(sc, ax=ax2)\n",
    "\n",
    "# 2D UMAP plot\n",
    "ax3 = fig.add_subplot(133)\n",
    "sc = ax3.scatter(df['umap_y'], df['umap_z'], c=df['class'], cmap='tab10', alpha=0.5)\n",
    "ax3.set_title('2D UMAP')\n",
    "ax3.set_xlabel('umap_x')\n",
    "ax3.set_ylabel('umap_y')\n",
    "plt.colorbar(sc, ax=ax3)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fc605-ca53-4775-b4d5-b94e4a915912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
