

    def __init__(
        self,
        image_size=224,
        patch_size=4,
        in_channels=3,
        embedding_dim=128,
        num_layers=3,
        num_heads=4,
        qkv_bias=True,
        mlp_ratio=4.0,
        use_revised_ffn=False,
        dropout_rate=0.3,
        attn_dropout_rate=0.3,
        use_conv_stem=True,
        use_conv_patch=False,
        use_linear_patch=False,
        use_conv_stem_original=True,
        use_stem_scaled_relu=False,
        hidden_dims=None,
        cls_head=False,
        num_classes=1000,
        representation_size=None,
    )





visual transformer1, only lr = 0.001, hidden_dims=[16, 16], image_size=32   ||| 20 epochs , batch=64
Testowy:

[[836 130   5  29]
 [117 675  12 196]
 [ 20  13  59   8]
 [ 69 207  17 707]]
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.66      0.68      0.67      1000
           2       0.63      0.59      0.61       100
           3       0.75      0.71      0.73      1000

    accuracy                           0.73      3100
   macro avg       0.71      0.70      0.71      3100
weighted avg       0.73      0.73      0.73      3100


visual transformer2, only lr=0.0001, , hidden_dims=[16, 16], image_size=32 ||| 20 epochs,  batch=64

[[853  82  18  47]
 [130 675  22 173]
 [  9  12  67  12]
 [ 67 150  14 769]]
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.73      0.68      0.70      1000
           2       0.55      0.67      0.61       100
           3       0.77      0.77      0.77      1000

    accuracy                           0.76      3100
   macro avg       0.72      0.74      0.73      3100
weighted avg       0.76      0.76      0.76      3100

visual transformer3, only lr=0.00005, , hidden_dims=[16, 16], image_size=32 ||| !! 30 epochs,  batch=16

[[852 102   8  38]
 [109 721   7 163]
 [  8  11  72   9]
 [ 65 167  13 755]]
              precision    recall  f1-score   support

           0       0.82      0.85      0.84      1000
           1       0.72      0.72      0.72      1000
           2       0.72      0.72      0.72       100
           3       0.78      0.76      0.77      1000

    accuracy                           0.77      3100
   macro avg       0.76      0.76      0.76      3100
weighted avg       0.77      0.77      0.77      3100


visual transformer 4,  only lr=0.0001, , hidden_dims=[32, 32], image_size=32 ||| !! 30 epochs,  batch=64


[[879  66  11  44]
 [129 634  17 220]
 [ 11   6  72  11]
 [ 65 112   7 816]]
              precision    recall  f1-score   support

           0       0.81      0.88      0.84      1000
           1       0.78      0.63      0.70      1000
           2       0.67      0.72      0.70       100
           3       0.75      0.82      0.78      1000

    accuracy                           0.77      3100
   macro avg       0.75      0.76      0.75      3100
weighted avg       0.77      0.77      0.77      3100




visual transformer 5
model = VisionTransformer(image_size=32, in_channels=4, num_classes=4, hidden_dims=[16, 16], dropout_rate=0.7)


                                            image_size=32 ||| !! 30 epochs,  batch=64


[[887  65  11  37]
 [190 560  44 206]
 [ 20   5  59  16]
 [101 113  23 763]]
              precision    recall  f1-score   support

           0       0.74      0.89      0.81      1000
           1       0.75      0.56      0.64      1000
           2       0.43      0.59      0.50       100
           3       0.75      0.76      0.75      1000

    accuracy                           0.73      3100
   macro avg       0.67      0.70      0.68      3100
weighted avg       0.74      0.73      0.73      3100





visual transformer 6 model = VisionTransformer(image_size=32, in_channels=4, num_classes=4, hidden_dims=[32, 32], dropout_rate=0.5) 
with augmentation           lr = 0.0001 epoch 30

transform = A.Compose([
    A.RandomResizedCrop(32, 32, scale=(0.9, 0.9)),
    A.OneOf([
        A.ElasticTransform(alpha=2, sigma=1),
        A.HorizontalFlip(),
        A.VerticalFlip(),
    ], p=0.8),
    A.Rotate(limit=90, p=0.5),
    A.Resize(32, 32)
])


[[898  52   4  46]
 [202 555  22 221]
 [ 20  11  60   9]
 [ 88 110  15 787]]
              precision    recall  f1-score   support

           0       0.74      0.90      0.81      1000
           1       0.76      0.56      0.64      1000
           2       0.59      0.60      0.60       100
           3       0.74      0.79      0.76      1000

    accuracy                           0.74      3100
   macro avg       0.71      0.71      0.70      3100
weighted avg       0.74      0.74      0.73      3100



visual transformer 7 model = VisionTransformer(image_size=32, in_channels=4, num_classes=4, hidden_dims=[64, 64], dropout_rate=0.5)
with augmentation          lr = 0.0001 epoch 50
transform = A.Compose([
    A.OneOf([
        A.HorizontalFlip(),
        A.VerticalFlip(),
    ], p=0.8),
    A.Rotate(limit=90, p=0.5),
    A.Resize(32, 32)
])

[[875  79  18  28]
 [124 728  14 134]
 [ 11   7  75   7]
 [ 53 133  23 791]]
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      1000
           1       0.77      0.73      0.75      1000
           2       0.58      0.75      0.65       100
           3       0.82      0.79      0.81      1000

    accuracy                           0.80      3100
   macro avg       0.75      0.79      0.76      3100
weighted avg       0.80      0.80      0.80      3100


visual transformer 8 model = VisionTransformer(image_size=32, in_channels=4, num_classes=4, hidden_dims=[128, 128], dropout_rate=0.6)
epochs 100 lr=0.0001

transform = A.Compose([
    A.OneOf([
        A.HorizontalFlip(),
        A.VerticalFlip(),
    ], p=1),
    A.Rotate(limit=90, p=0.5),
    A.Resize(32, 32)
])


[[882  65  24  29]
 [153 677  30 140]
 [ 11   5  75   9]
 [ 69 149  25 757]]
              precision    recall  f1-score   support

           0       0.79      0.88      0.83      1000
           1       0.76      0.68      0.71      1000
           2       0.49      0.75      0.59       100
           3       0.81      0.76      0.78      1000

    accuracy                           0.77      3100
   macro avg       0.71      0.77      0.73      3100
weighted avg       0.78      0.77      0.77      3100




visual transformer 9 model = VisionTransformer(image_size=32, in_channels=4, num_classes=4, hidden_dims=[16, 16], dropout_rate=0.6)
epoch 40, lr 0.0001




transform = A.Compose([
    A.OneOf([
        A.HorizontalFlip(),
        A.VerticalFlip(),
    ], p=0.8),
    A.Rotate(limit=90, p=0.5),
    A.Resize(32, 32)
])




resnet1 

model = resnet18()
model.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)

num_classes = 4
model.fc = nn.Linear(model.fc.in_features, num_classes)
batch_size = 16


ResNet(
  (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
...
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=4, bias=True)
)

                                                                                    batch = 64, 30 epochs, (32,32)

[[869  92   7  32]
 [123 747  10 120]
 [ 17  15  61   7]
 [ 88 231   6 675]]
              precision    recall  f1-score   support

           0       0.79      0.87      0.83      1000
           1       0.69      0.75      0.72      1000
           2       0.73      0.61      0.66       100
           3       0.81      0.68      0.74      1000

    accuracy                           0.76      3100
   macro avg       0.75      0.73      0.74      3100
weighted avg       0.76      0.76      0.76      3100


resnet2                                                                     batch= 64, 30 epochs, (32,32) dropout to fc layer 0.6


model = resnet18()
model.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)

num_classes = 4
model.fc = nn.Sequential(
    nn.Dropout(0.6),  
    nn.Linear(model.fc.in_features, num_classes)
)





[[816 106  10  68]
 [ 84 640  14 262]
 [  4  12  72  12]
 [ 39 133   9 819]]
              precision    recall  f1-score   support

           0       0.87      0.82      0.84      1000
           1       0.72      0.64      0.68      1000
           2       0.69      0.72      0.70       100
           3       0.71      0.82      0.76      1000

    accuracy                           0.76      3100
   macro avg       0.74      0.75      0.74      3100
weighted avg       0.76      0.76      0.76      3100

