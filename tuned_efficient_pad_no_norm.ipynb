{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb74ae06-2775-4bb7-841c-8e11a4b3e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015615731118230405\n",
    "batch_size = 239\n",
    "dropout_rate = 0.11448917722400666\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdce5c8-56c3-4c69-b604-58c13391dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        files = os.listdir(path)\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['filename'] = []\n",
    "        dataset_final['class'] = []\n",
    "        for filename in files:\n",
    "            dataset = pd.DataFrame()\n",
    "            if filename.endswith('.txt'):\n",
    "                files = get_images_list(f'{path}/{filename}')\n",
    "                dataset['filename'] = files\n",
    "                dataset['class'] = filename.split('_')[1][:-3]\n",
    "                dataset_final = pd.concat([dataset_final, dataset], ignore_index=True)\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"filename\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset[\"class\"].loc[idx]\n",
    "\n",
    "        if target == 'normal.':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target == 'inflamatory.':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target == 'tumor.':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target == 'other.':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "       \n",
    "     \n",
    "\n",
    "        \"\"\"To see transorms use:\n",
    "            image, target = trainset[15]\n",
    "            image = image.numpy()\n",
    "            image=np.swapaxes(image,0,1)\n",
    "            image=np.swapaxes(image,1,2)\n",
    "            plt.imshow(image)\"\"\"\n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c9ce6d-ff90-47af-9c56-b9fedb9fdef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1800: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1826: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1952: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2233)\n",
    "\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1a2930-151c-47fb-9dfa-049423ebc571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=4, dropout_rate=dropout_rate):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.base_model = models.efficientnet_b0(pretrained=False)\n",
    "        num_ftrs = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),  # Add dropout layer\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "model = EfficientNetB0(num_classes=4, dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abc075-67ea-4128-9aa2-bb4ee837775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8eb3155-df02-49ac-a6b2-6bbea2a732a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240805_011900-jiktgj6g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/jiktgj6g' target=\"_blank\">efficient_net_pad_no_norm2024-08-05 01:18:59.891076</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/jiktgj6g' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/jiktgj6g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.9416039775688205\n",
      "train_precision: tensor([0.5312, 0.6628, 0.6005, 0.2436], device='cuda:0')\n",
      "train_recall: tensor([0.5291, 0.7486, 0.5824, 0.0110], device='cuda:0')\n",
      "val_loss: 0.857025743611736\n",
      "val_precision: tensor([0.5674, 0.7251, 0.6401, 0.6753], device='cuda:0')\n",
      "val_recall: tensor([0.6058, 0.7208, 0.6571, 0.0791], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.854092754365605\n",
      "train_precision: tensor([0.5837, 0.6967, 0.6618, 0.6045], device='cuda:0')\n",
      "train_recall: tensor([0.5761, 0.7713, 0.6571, 0.0776], device='cuda:0')\n",
      "val_loss: 0.8525727257672987\n",
      "val_precision: tensor([0.6366, 0.6981, 0.5895, 0.8780], device='cuda:0')\n",
      "val_recall: tensor([0.3745, 0.8058, 0.7952, 0.0751], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.8261121309241145\n",
      "train_precision: tensor([0.5965, 0.7118, 0.6718, 0.5984], device='cuda:0')\n",
      "train_recall: tensor([0.5883, 0.7800, 0.6693, 0.1286], device='cuda:0')\n",
      "val_loss: 0.8070615128531975\n",
      "val_precision: tensor([0.6350, 0.7295, 0.6259, 0.8504], device='cuda:0')\n",
      "val_recall: tensor([0.4968, 0.7726, 0.7779, 0.1340], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.7909407304046682\n",
      "train_precision: tensor([0.6087, 0.7221, 0.6842, 0.6218], device='cuda:0')\n",
      "train_recall: tensor([0.5946, 0.7889, 0.6836, 0.1952], device='cuda:0')\n",
      "val_loss: 0.7589725702228941\n",
      "val_precision: tensor([0.6045, 0.7844, 0.6906, 0.6354], device='cuda:0')\n",
      "val_recall: tensor([0.6540, 0.7436, 0.7123, 0.2465], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.7511192929492776\n",
      "train_precision: tensor([0.6320, 0.7412, 0.6940, 0.6243], device='cuda:0')\n",
      "train_recall: tensor([0.6098, 0.8000, 0.7040, 0.2573], device='cuda:0')\n",
      "val_loss: 0.754248004812033\n",
      "val_precision: tensor([0.6699, 0.7870, 0.6297, 0.6695], device='cuda:0')\n",
      "val_recall: tensor([0.5542, 0.7468, 0.8081, 0.2694], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.7607332577429571\n",
      "train_precision: tensor([0.6287, 0.7359, 0.6931, 0.6259], device='cuda:0')\n",
      "train_recall: tensor([0.6060, 0.7986, 0.7019, 0.2390], device='cuda:0')\n",
      "val_loss: 0.7885894518287688\n",
      "val_precision: tensor([0.6435, 0.7471, 0.6365, 0.8812], device='cuda:0')\n",
      "val_recall: tensor([0.5629, 0.7551, 0.7601, 0.1798], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.7215197304464686\n",
      "train_precision: tensor([0.6505, 0.7548, 0.7078, 0.6259], device='cuda:0')\n",
      "train_recall: tensor([0.6282, 0.8083, 0.7188, 0.2999], device='cuda:0')\n",
      "val_loss: 0.7322680442135568\n",
      "val_precision: tensor([0.6796, 0.8114, 0.6295, 0.6349], device='cuda:0')\n",
      "val_recall: tensor([0.5328, 0.7529, 0.8391, 0.3502], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.7058943094347953\n",
      "train_precision: tensor([0.6554, 0.7593, 0.7132, 0.6351], device='cuda:0')\n",
      "train_recall: tensor([0.6346, 0.8099, 0.7233, 0.3235], device='cuda:0')\n",
      "val_loss: 0.6786958768268941\n",
      "val_precision: tensor([0.6952, 0.7606, 0.6986, 0.7707], device='cuda:0')\n",
      "val_recall: tensor([0.5833, 0.8360, 0.7811, 0.3360], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6972247568333109\n",
      "train_precision: tensor([0.6608, 0.7630, 0.7180, 0.6459], device='cuda:0')\n",
      "train_recall: tensor([0.6384, 0.8145, 0.7266, 0.3506], device='cuda:0')\n",
      "val_loss: 0.6652435594735367\n",
      "val_precision: tensor([0.7069, 0.7712, 0.6973, 0.8293], device='cuda:0')\n",
      "val_recall: tensor([0.5860, 0.8335, 0.8036, 0.3141], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6752967425395172\n",
      "train_precision: tensor([0.6717, 0.7735, 0.7267, 0.6517], device='cuda:0')\n",
      "train_recall: tensor([0.6506, 0.8206, 0.7350, 0.3846], device='cuda:0')\n",
      "val_loss: 0.6522150117653022\n",
      "val_precision: tensor([0.6912, 0.7883, 0.7203, 0.6901], device='cuda:0')\n",
      "val_recall: tensor([0.6394, 0.8177, 0.7736, 0.4387], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6622868298953845\n",
      "train_precision: tensor([0.6779, 0.7784, 0.7309, 0.6599], device='cuda:0')\n",
      "train_recall: tensor([0.6543, 0.8234, 0.7426, 0.4038], device='cuda:0')\n",
      "val_loss: 0.6902943566209911\n",
      "val_precision: tensor([0.6740, 0.8209, 0.6762, 0.6150], device='cuda:0')\n",
      "val_recall: tensor([0.6092, 0.7594, 0.8068, 0.4798], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6506874302072705\n",
      "train_precision: tensor([0.6816, 0.7820, 0.7377, 0.6564], device='cuda:0')\n",
      "train_recall: tensor([0.6601, 0.8260, 0.7454, 0.4251], device='cuda:0')\n",
      "val_loss: 0.6630172056237651\n",
      "val_precision: tensor([0.6545, 0.8281, 0.7166, 0.6618], device='cuda:0')\n",
      "val_recall: tensor([0.6683, 0.7605, 0.7835, 0.4455], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6556594460970567\n",
      "train_precision: tensor([0.6810, 0.7790, 0.7375, 0.6673], device='cuda:0')\n",
      "train_recall: tensor([0.6606, 0.8253, 0.7421, 0.4273], device='cuda:0')\n",
      "val_loss: 0.6651573577229841\n",
      "val_precision: tensor([0.6996, 0.7724, 0.7057, 0.7962], device='cuda:0')\n",
      "val_recall: tensor([0.6054, 0.8355, 0.7809, 0.3684], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6377807785326965\n",
      "train_precision: tensor([0.6874, 0.7859, 0.7437, 0.6766], device='cuda:0')\n",
      "train_recall: tensor([0.6666, 0.8316, 0.7474, 0.4540], device='cuda:0')\n",
      "val_loss: 0.630653762446784\n",
      "val_precision: tensor([0.7092, 0.8022, 0.7177, 0.7446], device='cuda:0')\n",
      "val_recall: tensor([0.6393, 0.8218, 0.8024, 0.4192], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6257630661212827\n",
      "train_precision: tensor([0.6950, 0.7924, 0.7480, 0.6730], device='cuda:0')\n",
      "train_recall: tensor([0.6728, 0.8340, 0.7554, 0.4684], device='cuda:0')\n",
      "val_loss: 0.6060375485549937\n",
      "val_precision: tensor([0.6900, 0.8078, 0.7595, 0.8037], device='cuda:0')\n",
      "val_recall: tensor([0.7072, 0.8271, 0.7582, 0.4259], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6246994782541697\n",
      "train_precision: tensor([0.6958, 0.7908, 0.7517, 0.6834], device='cuda:0')\n",
      "train_recall: tensor([0.6776, 0.8337, 0.7533, 0.4762], device='cuda:0')\n",
      "val_loss: 0.6183043384026987\n",
      "val_precision: tensor([0.6638, 0.8274, 0.7679, 0.7614], device='cuda:0')\n",
      "val_recall: tensor([0.7366, 0.7898, 0.7472, 0.4771], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6324965991950009\n",
      "train_precision: tensor([0.6936, 0.7842, 0.7505, 0.6811], device='cuda:0')\n",
      "train_recall: tensor([0.6733, 0.8319, 0.7514, 0.4573], device='cuda:0')\n",
      "val_loss: 0.6056291165283925\n",
      "val_precision: tensor([0.7236, 0.7769, 0.7560, 0.7215], device='cuda:0')\n",
      "val_recall: tensor([0.6560, 0.8646, 0.7627, 0.5165], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.615889600605535\n",
      "train_precision: tensor([0.6995, 0.7934, 0.7570, 0.6844], device='cuda:0')\n",
      "train_recall: tensor([0.6832, 0.8360, 0.7556, 0.4890], device='cuda:0')\n",
      "val_loss: 0.6276947581860686\n",
      "val_precision: tensor([0.7315, 0.7891, 0.7050, 0.6907], device='cuda:0')\n",
      "val_recall: tensor([0.5868, 0.8440, 0.8182, 0.4670], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6054947013252967\n",
      "train_precision: tensor([0.7040, 0.7967, 0.7611, 0.6939], device='cuda:0')\n",
      "train_recall: tensor([0.6866, 0.8382, 0.7606, 0.5079], device='cuda:0')\n",
      "val_loss: 0.6320729825471967\n",
      "val_precision: tensor([0.6684, 0.8024, 0.7592, 0.7741], device='cuda:0')\n",
      "val_recall: tensor([0.7164, 0.8018, 0.7362, 0.4593], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6066013102868243\n",
      "train_precision: tensor([0.7055, 0.7953, 0.7593, 0.6889], device='cuda:0')\n",
      "train_recall: tensor([0.6870, 0.8366, 0.7603, 0.5023], device='cuda:0')\n",
      "val_loss: 0.593522630902152\n",
      "val_precision: tensor([0.7304, 0.7693, 0.7745, 0.7502], device='cuda:0')\n",
      "val_recall: tensor([0.6673, 0.8788, 0.7560, 0.5088], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5982168571105656\n",
      "train_precision: tensor([0.7066, 0.7998, 0.7634, 0.6954], device='cuda:0')\n",
      "train_recall: tensor([0.6906, 0.8407, 0.7610, 0.5202], device='cuda:0')\n",
      "val_loss: 0.5913225627007263\n",
      "val_precision: tensor([0.7216, 0.7844, 0.7704, 0.8151], device='cuda:0')\n",
      "val_recall: tensor([0.6874, 0.8652, 0.7612, 0.4586], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6006541776246038\n",
      "train_precision: tensor([0.7053, 0.7991, 0.7631, 0.6972], device='cuda:0')\n",
      "train_recall: tensor([0.6916, 0.8387, 0.7618, 0.5001], device='cuda:0')\n",
      "val_loss: 0.5932494186521194\n",
      "val_precision: tensor([0.7157, 0.8188, 0.7411, 0.7698], device='cuda:0')\n",
      "val_recall: tensor([0.6845, 0.8122, 0.8067, 0.4865], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5864562348144603\n",
      "train_precision: tensor([0.7127, 0.8035, 0.7697, 0.7019], device='cuda:0')\n",
      "train_recall: tensor([0.6987, 0.8399, 0.7678, 0.5392], device='cuda:0')\n",
      "val_loss: 0.66472536232805\n",
      "val_precision: tensor([0.6289, 0.8420, 0.7669, 0.5511], device='cuda:0')\n",
      "val_recall: tensor([0.7544, 0.7402, 0.7088, 0.5357], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5900429681490472\n",
      "train_precision: tensor([0.7100, 0.7999, 0.7694, 0.7047], device='cuda:0')\n",
      "train_recall: tensor([0.6938, 0.8411, 0.7649, 0.5430], device='cuda:0')\n",
      "val_loss: 0.6021024805585338\n",
      "val_precision: tensor([0.7120, 0.8367, 0.7200, 0.7402], device='cuda:0')\n",
      "val_recall: tensor([0.6638, 0.7893, 0.8306, 0.5239], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6037455574423903\n",
      "train_precision: tensor([0.7060, 0.7941, 0.7664, 0.6804], device='cuda:0')\n",
      "train_recall: tensor([0.6932, 0.8385, 0.7608, 0.4734], device='cuda:0')\n",
      "val_loss: 0.5885156554416053\n",
      "val_precision: tensor([0.7196, 0.7993, 0.7710, 0.6727], device='cuda:0')\n",
      "val_recall: tensor([0.6914, 0.8513, 0.7626, 0.5724], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5826259768579375\n",
      "train_precision: tensor([0.7118, 0.8052, 0.7738, 0.6974], device='cuda:0')\n",
      "train_recall: tensor([0.7011, 0.8412, 0.7683, 0.5397], device='cuda:0')\n",
      "val_loss: 0.637333720768054\n",
      "val_precision: tensor([0.7358, 0.7495, 0.7419, 0.8215], device='cuda:0')\n",
      "val_recall: tensor([0.6235, 0.8728, 0.7735, 0.3734], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5811895831872412\n",
      "train_precision: tensor([0.7157, 0.8043, 0.7745, 0.6989], device='cuda:0')\n",
      "train_recall: tensor([0.7025, 0.8432, 0.7698, 0.5312], device='cuda:0')\n",
      "val_loss: 0.5649096306432714\n",
      "val_precision: tensor([0.7499, 0.8060, 0.7559, 0.7509], device='cuda:0')\n",
      "val_recall: tensor([0.6652, 0.8594, 0.8087, 0.5774], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.568465763423281\n",
      "train_precision: tensor([0.7191, 0.8100, 0.7790, 0.7097], device='cuda:0')\n",
      "train_recall: tensor([0.7078, 0.8449, 0.7739, 0.5622], device='cuda:0')\n",
      "val_loss: 0.573221171921399\n",
      "val_precision: tensor([0.7515, 0.8092, 0.7399, 0.7014], device='cuda:0')\n",
      "val_recall: tensor([0.6452, 0.8482, 0.8230, 0.5670], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.561890925031085\n",
      "train_precision: tensor([0.7231, 0.8126, 0.7812, 0.7059], device='cuda:0')\n",
      "train_recall: tensor([0.7129, 0.8459, 0.7750, 0.5722], device='cuda:0')\n",
      "val_loss: 0.5720925998193612\n",
      "val_precision: tensor([0.7216, 0.8080, 0.7691, 0.7618], device='cuda:0')\n",
      "val_recall: tensor([0.7062, 0.8455, 0.7745, 0.5168], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5634499588386633\n",
      "train_precision: tensor([0.7223, 0.8130, 0.7815, 0.6983], device='cuda:0')\n",
      "train_recall: tensor([0.7139, 0.8459, 0.7730, 0.5734], device='cuda:0')\n",
      "val_loss: 0.6009688398998636\n",
      "val_precision: tensor([0.7092, 0.7895, 0.7630, 0.8000], device='cuda:0')\n",
      "val_recall: tensor([0.6849, 0.8412, 0.7723, 0.4512], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5617755669043778\n",
      "train_precision: tensor([0.7231, 0.8111, 0.7821, 0.7120], device='cuda:0')\n",
      "train_recall: tensor([0.7133, 0.8455, 0.7742, 0.5786], device='cuda:0')\n",
      "val_loss: 0.5601615681858261\n",
      "val_precision: tensor([0.7429, 0.8133, 0.7599, 0.7525], device='cuda:0')\n",
      "val_recall: tensor([0.6900, 0.8473, 0.8027, 0.5508], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.552497578907066\n",
      "train_precision: tensor([0.7296, 0.8157, 0.7857, 0.7153], device='cuda:0')\n",
      "train_recall: tensor([0.7181, 0.8485, 0.7805, 0.5882], device='cuda:0')\n",
      "val_loss: 0.5564154826606493\n",
      "val_precision: tensor([0.7428, 0.8020, 0.7748, 0.7150], device='cuda:0')\n",
      "val_recall: tensor([0.6855, 0.8543, 0.7990, 0.5761], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5484741175996846\n",
      "train_precision: tensor([0.7289, 0.8161, 0.7859, 0.7101], device='cuda:0')\n",
      "train_recall: tensor([0.7171, 0.8476, 0.7807, 0.5978], device='cuda:0')\n",
      "val_loss: 0.5609357036611576\n",
      "val_precision: tensor([0.7100, 0.8196, 0.7878, 0.7902], device='cuda:0')\n",
      "val_recall: tensor([0.7407, 0.8299, 0.7726, 0.5034], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5528287580599377\n",
      "train_precision: tensor([0.7291, 0.8129, 0.7857, 0.7154], device='cuda:0')\n",
      "train_recall: tensor([0.7153, 0.8485, 0.7791, 0.5986], device='cuda:0')\n",
      "val_loss: 0.6772833864923586\n",
      "val_precision: tensor([0.6498, 0.8233, 0.7158, 0.6011], device='cuda:0')\n",
      "val_recall: tensor([0.6606, 0.7335, 0.7838, 0.5865], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.593630160187455\n",
      "train_precision: tensor([0.7110, 0.7979, 0.7673, 0.6995], device='cuda:0')\n",
      "train_recall: tensor([0.6936, 0.8404, 0.7641, 0.5280], device='cuda:0')\n",
      "val_loss: 0.6096535636198953\n",
      "val_precision: tensor([0.7165, 0.7891, 0.7573, 0.7499], device='cuda:0')\n",
      "val_recall: tensor([0.6697, 0.8435, 0.7807, 0.4916], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5860671627773459\n",
      "train_precision: tensor([0.7151, 0.8000, 0.7736, 0.6938], device='cuda:0')\n",
      "train_recall: tensor([0.7000, 0.8413, 0.7678, 0.5343], device='cuda:0')\n",
      "val_loss: 0.5668817945403756\n",
      "val_precision: tensor([0.7078, 0.8251, 0.7785, 0.7645], device='cuda:0')\n",
      "val_recall: tensor([0.7248, 0.8275, 0.7785, 0.5586], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5508911230076142\n",
      "train_precision: tensor([0.7285, 0.8149, 0.7873, 0.7183], device='cuda:0')\n",
      "train_recall: tensor([0.7162, 0.8502, 0.7800, 0.5957], device='cuda:0')\n",
      "val_loss: 0.5512785022122872\n",
      "val_precision: tensor([0.7279, 0.8229, 0.7796, 0.7428], device='cuda:0')\n",
      "val_recall: tensor([0.7226, 0.8340, 0.7927, 0.5727], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5615249168753491\n",
      "train_precision: tensor([0.7231, 0.8100, 0.7833, 0.7062], device='cuda:0')\n",
      "train_recall: tensor([0.7126, 0.8440, 0.7773, 0.5665], device='cuda:0')\n",
      "val_loss: 0.5562167521276622\n",
      "val_precision: tensor([0.7233, 0.8247, 0.7826, 0.6994], device='cuda:0')\n",
      "val_recall: tensor([0.7215, 0.8388, 0.7827, 0.5970], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5699734812451152\n",
      "train_precision: tensor([0.7203, 0.8049, 0.7794, 0.7024], device='cuda:0')\n",
      "train_recall: tensor([0.7054, 0.8453, 0.7724, 0.5590], device='cuda:0')\n",
      "val_loss: 0.5684326453221277\n",
      "val_precision: tensor([0.7222, 0.8331, 0.7630, 0.6700], device='cuda:0')\n",
      "val_recall: tensor([0.7117, 0.8150, 0.7975, 0.6104], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5401137430092384\n",
      "train_precision: tensor([0.7338, 0.8193, 0.7906, 0.7203], device='cuda:0')\n",
      "train_recall: tensor([0.7234, 0.8514, 0.7833, 0.6058], device='cuda:0')\n",
      "val_loss: 0.5571421816404619\n",
      "val_precision: tensor([0.7573, 0.8049, 0.7687, 0.7566], device='cuda:0')\n",
      "val_recall: tensor([0.6761, 0.8659, 0.8106, 0.5818], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.53489695799364\n",
      "train_precision: tensor([0.7356, 0.8212, 0.7932, 0.7258], device='cuda:0')\n",
      "train_recall: tensor([0.7260, 0.8519, 0.7858, 0.6176], device='cuda:0')\n",
      "val_loss: 0.6764281386692907\n",
      "val_precision: tensor([0.6500, 0.8365, 0.7449, 0.4239], device='cuda:0')\n",
      "val_recall: tensor([0.7110, 0.7349, 0.7423, 0.5562], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5318497617265937\n",
      "train_precision: tensor([0.7363, 0.8223, 0.7962, 0.7199], device='cuda:0')\n",
      "train_recall: tensor([0.7293, 0.8529, 0.7848, 0.6238], device='cuda:0')\n",
      "val_loss: 0.5511685121862382\n",
      "val_precision: tensor([0.7241, 0.8251, 0.7961, 0.7576], device='cuda:0')\n",
      "val_recall: tensor([0.7394, 0.8472, 0.7752, 0.5936], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5568435568366619\n",
      "train_precision: tensor([0.7256, 0.8118, 0.7854, 0.7064], device='cuda:0')\n",
      "train_recall: tensor([0.7162, 0.8463, 0.7769, 0.5752], device='cuda:0')\n",
      "val_loss: 0.5516596304474717\n",
      "val_precision: tensor([0.7177, 0.8192, 0.7923, 0.7885], device='cuda:0')\n",
      "val_recall: tensor([0.7362, 0.8384, 0.7777, 0.5461], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5386338076814263\n",
      "train_precision: tensor([0.7312, 0.8186, 0.7938, 0.7203], device='cuda:0')\n",
      "train_recall: tensor([0.7256, 0.8485, 0.7829, 0.6126], device='cuda:0')\n",
      "val_loss: 0.7226542147175635\n",
      "val_precision: tensor([0.6420, 0.7293, 0.7295, 0.7948], device='cuda:0')\n",
      "val_recall: tensor([0.6266, 0.8018, 0.7226, 0.2700], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5672423230262433\n",
      "train_precision: tensor([0.7174, 0.8066, 0.7842, 0.7116], device='cuda:0')\n",
      "train_recall: tensor([0.7101, 0.8399, 0.7734, 0.5877], device='cuda:0')\n",
      "val_loss: 0.6395794506826549\n",
      "val_precision: tensor([0.6717, 0.7898, 0.7531, 0.6926], device='cuda:0')\n",
      "val_recall: tensor([0.6860, 0.8103, 0.7401, 0.4848], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5930457141362255\n",
      "train_precision: tensor([0.7019, 0.7991, 0.7722, 0.6978], device='cuda:0')\n",
      "train_recall: tensor([0.6995, 0.8336, 0.7599, 0.5317], device='cuda:0')\n",
      "val_loss: 0.5873524481768435\n",
      "val_precision: tensor([0.7194, 0.8359, 0.7657, 0.7221], device='cuda:0')\n",
      "val_recall: tensor([0.7190, 0.8040, 0.8091, 0.5933], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.595022378064634\n",
      "train_precision: tensor([0.7070, 0.7975, 0.7695, 0.6779], device='cuda:0')\n",
      "train_recall: tensor([0.6974, 0.8359, 0.7607, 0.5209], device='cuda:0')\n",
      "val_loss: 0.5949829971234415\n",
      "val_precision: tensor([0.7287, 0.8109, 0.7388, 0.7107], device='cuda:0')\n",
      "val_recall: tensor([0.6563, 0.8257, 0.8164, 0.5418], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5614318552948079\n",
      "train_precision: tensor([0.7235, 0.8099, 0.7840, 0.7112], device='cuda:0')\n",
      "train_recall: tensor([0.7124, 0.8452, 0.7773, 0.5727], device='cuda:0')\n",
      "val_loss: 0.5478733180409269\n",
      "val_precision: tensor([0.7335, 0.8326, 0.7711, 0.7507], device='cuda:0')\n",
      "val_recall: tensor([0.7165, 0.8252, 0.8119, 0.5953], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5334470017799678\n",
      "train_precision: tensor([0.7363, 0.8218, 0.7950, 0.7161], device='cuda:0')\n",
      "train_recall: tensor([0.7277, 0.8497, 0.7882, 0.6185], device='cuda:0')\n",
      "val_loss: 0.547982300192581\n",
      "val_precision: tensor([0.7396, 0.8232, 0.7712, 0.6787], device='cuda:0')\n",
      "val_recall: tensor([0.6914, 0.8404, 0.8068, 0.6663], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5238015160412094\n",
      "train_precision: tensor([0.7403, 0.8244, 0.7963, 0.7277], device='cuda:0')\n",
      "train_recall: tensor([0.7295, 0.8531, 0.7894, 0.6444], device='cuda:0')\n",
      "val_loss: 0.5448351078546109\n",
      "val_precision: tensor([0.7392, 0.8309, 0.7708, 0.7383], device='cuda:0')\n",
      "val_recall: tensor([0.7114, 0.8376, 0.8113, 0.5670], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5234673134941148\n",
      "train_precision: tensor([0.7407, 0.8238, 0.7992, 0.7277], device='cuda:0')\n",
      "train_recall: tensor([0.7318, 0.8550, 0.7886, 0.6368], device='cuda:0')\n",
      "val_loss: 0.53751380548576\n",
      "val_precision: tensor([0.7299, 0.8139, 0.8052, 0.7335], device='cuda:0')\n",
      "val_recall: tensor([0.7295, 0.8534, 0.7777, 0.6310], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5541630503996063\n",
      "train_precision: tensor([0.7286, 0.8126, 0.7864, 0.7168], device='cuda:0')\n",
      "train_recall: tensor([0.7195, 0.8462, 0.7773, 0.5932], device='cuda:0')\n",
      "val_loss: 0.5896933529661109\n",
      "val_precision: tensor([0.7417, 0.8114, 0.7847, 0.5900], device='cuda:0')\n",
      "val_recall: tensor([0.6929, 0.8464, 0.7862, 0.7121], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5304841358749169\n",
      "train_precision: tensor([0.7359, 0.8209, 0.7955, 0.7270], device='cuda:0')\n",
      "train_recall: tensor([0.7283, 0.8504, 0.7858, 0.6307], device='cuda:0')\n",
      "val_loss: 0.5456223288657134\n",
      "val_precision: tensor([0.7360, 0.8082, 0.7933, 0.7319], device='cuda:0')\n",
      "val_recall: tensor([0.7147, 0.8586, 0.7799, 0.6104], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5798845363737346\n",
      "train_precision: tensor([0.7134, 0.8058, 0.7762, 0.6844], device='cuda:0')\n",
      "train_recall: tensor([0.7068, 0.8396, 0.7674, 0.5378], device='cuda:0')\n",
      "val_loss: 0.5748858698137066\n",
      "val_precision: tensor([0.7169, 0.8279, 0.7627, 0.7432], device='cuda:0')\n",
      "val_recall: tensor([0.7082, 0.8202, 0.8001, 0.5370], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.6395559815464084\n",
      "train_precision: tensor([0.6818, 0.7817, 0.7459, 0.6764], device='cuda:0')\n",
      "train_recall: tensor([0.6685, 0.8290, 0.7402, 0.4499], device='cuda:0')\n",
      "val_loss: 0.7214840593424485\n",
      "val_precision: tensor([0.7082, 0.8044, 0.7243, 0.7430], device='cuda:0')\n",
      "val_recall: tensor([0.6544, 0.8146, 0.7975, 0.4623], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.582788094198611\n",
      "train_precision: tensor([0.7148, 0.8023, 0.7722, 0.7112], device='cuda:0')\n",
      "train_recall: tensor([0.7015, 0.8408, 0.7687, 0.5336], device='cuda:0')\n",
      "val_loss: 0.5617658513660876\n",
      "val_precision: tensor([0.7491, 0.8116, 0.7633, 0.6830], device='cuda:0')\n",
      "val_recall: tensor([0.6778, 0.8475, 0.8113, 0.6013], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5539654008671226\n",
      "train_precision: tensor([0.7280, 0.8122, 0.7850, 0.7194], device='cuda:0')\n",
      "train_recall: tensor([0.7148, 0.8467, 0.7809, 0.5827], device='cuda:0')\n",
      "val_loss: 0.5862641722118299\n",
      "val_precision: tensor([0.7326, 0.8153, 0.7731, 0.7672], device='cuda:0')\n",
      "val_recall: tensor([0.7000, 0.8455, 0.7997, 0.5616], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5698017025153019\n",
      "train_precision: tensor([0.7182, 0.8052, 0.7791, 0.7115], device='cuda:0')\n",
      "train_recall: tensor([0.7084, 0.8419, 0.7715, 0.5537], device='cuda:0')\n",
      "val_loss: 0.6889943574685506\n",
      "val_precision: tensor([0.6820, 0.7490, 0.7308, 0.6276], device='cuda:0')\n",
      "val_recall: tensor([0.6108, 0.8410, 0.7425, 0.4114], device='cuda:0')\n",
      "Learning rate: 0.0015615731118230405\n",
      "train_loss: 0.5817153463772062\n",
      "train_precision: tensor([0.7128, 0.8034, 0.7702, 0.7096], device='cuda:0')\n",
      "train_recall: tensor([0.6987, 0.8393, 0.7691, 0.5434], device='cuda:0')\n",
      "val_loss: 0.573719988292363\n",
      "val_precision: tensor([0.7538, 0.8243, 0.7401, 0.7482], device='cuda:0')\n",
      "val_recall: tensor([0.6592, 0.8375, 0.8394, 0.5643], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.5214706583402313\n",
      "train_precision: tensor([0.7405, 0.8251, 0.7976, 0.7362], device='cuda:0')\n",
      "train_recall: tensor([0.7319, 0.8541, 0.7898, 0.6348], device='cuda:0')\n",
      "val_loss: 0.6099234416386007\n",
      "val_precision: tensor([0.7476, 0.8159, 0.7852, 0.7410], device='cuda:0')\n",
      "val_recall: tensor([0.7057, 0.8529, 0.8067, 0.6165], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.5111056230423581\n",
      "train_precision: tensor([0.7472, 0.8269, 0.8038, 0.7512], device='cuda:0')\n",
      "train_recall: tensor([0.7386, 0.8574, 0.7940, 0.6528], device='cuda:0')\n",
      "val_loss: 0.5643679223993282\n",
      "val_precision: tensor([0.7478, 0.8222, 0.7866, 0.7385], device='cuda:0')\n",
      "val_recall: tensor([0.7128, 0.8500, 0.8092, 0.6229], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.5057216025764605\n",
      "train_precision: tensor([0.7479, 0.8292, 0.8074, 0.7501], device='cuda:0')\n",
      "train_recall: tensor([0.7413, 0.8587, 0.7951, 0.6635], device='cuda:0')\n",
      "val_loss: 0.612816891985236\n",
      "val_precision: tensor([0.7513, 0.8147, 0.7946, 0.7324], device='cuda:0')\n",
      "val_recall: tensor([0.7121, 0.8571, 0.8052, 0.6357], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.49948024212717346\n",
      "train_precision: tensor([0.7504, 0.8312, 0.8089, 0.7533], device='cuda:0')\n",
      "train_recall: tensor([0.7433, 0.8594, 0.7978, 0.6719], device='cuda:0')\n",
      "val_loss: 0.7139777047800894\n",
      "val_precision: tensor([0.7413, 0.8282, 0.7940, 0.7406], device='cuda:0')\n",
      "val_recall: tensor([0.7275, 0.8403, 0.8080, 0.6394], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.49713962617122026\n",
      "train_precision: tensor([0.7519, 0.8331, 0.8095, 0.7475], device='cuda:0')\n",
      "train_recall: tensor([0.7452, 0.8592, 0.7995, 0.6727], device='cuda:0')\n",
      "val_loss: 0.527959736594882\n",
      "val_precision: tensor([0.7481, 0.8295, 0.7939, 0.7396], device='cuda:0')\n",
      "val_recall: tensor([0.7270, 0.8495, 0.8073, 0.6444], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.4901184585521431\n",
      "train_precision: tensor([0.7548, 0.8365, 0.8138, 0.7571], device='cuda:0')\n",
      "train_recall: tensor([0.7508, 0.8610, 0.8023, 0.6828], device='cuda:0')\n",
      "val_loss: 0.6074440396665909\n",
      "val_precision: tensor([0.7399, 0.8296, 0.8031, 0.7269], device='cuda:0')\n",
      "val_recall: tensor([0.7385, 0.8440, 0.7974, 0.6660], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.4886477134450524\n",
      "train_precision: tensor([0.7554, 0.8363, 0.8145, 0.7579], device='cuda:0')\n",
      "train_recall: tensor([0.7505, 0.8605, 0.8032, 0.6915], device='cuda:0')\n",
      "val_loss: 0.5985476248004894\n",
      "val_precision: tensor([0.7530, 0.8205, 0.7982, 0.7226], device='cuda:0')\n",
      "val_recall: tensor([0.7189, 0.8560, 0.8061, 0.6673], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.48472602212919674\n",
      "train_precision: tensor([0.7578, 0.8367, 0.8137, 0.7604], device='cuda:0')\n",
      "train_recall: tensor([0.7498, 0.8633, 0.8034, 0.6942], device='cuda:0')\n",
      "val_loss: 0.5399614795656402\n",
      "val_precision: tensor([0.7507, 0.8317, 0.7953, 0.7488], device='cuda:0')\n",
      "val_recall: tensor([0.7296, 0.8487, 0.8118, 0.6515], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.4816621006264437\n",
      "train_precision: tensor([0.7582, 0.8384, 0.8172, 0.7641], device='cuda:0')\n",
      "train_recall: tensor([0.7538, 0.8629, 0.8049, 0.7012], device='cuda:0')\n",
      "val_loss: 0.6132208706492587\n",
      "val_precision: tensor([0.7499, 0.8281, 0.7966, 0.7487], device='cuda:0')\n",
      "val_recall: tensor([0.7269, 0.8469, 0.8134, 0.6502], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.4783264479462111\n",
      "train_precision: tensor([0.7597, 0.8405, 0.8180, 0.7685], device='cuda:0')\n",
      "train_recall: tensor([0.7558, 0.8644, 0.8051, 0.7107], device='cuda:0')\n",
      "val_loss: 0.6173161948437518\n",
      "val_precision: tensor([0.7467, 0.8307, 0.8020, 0.7620], device='cuda:0')\n",
      "val_recall: tensor([0.7371, 0.8482, 0.8075, 0.6468], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.47562361950338616\n",
      "train_precision: tensor([0.7612, 0.8421, 0.8188, 0.7653], device='cuda:0')\n",
      "train_recall: tensor([0.7571, 0.8647, 0.8070, 0.7126], device='cuda:0')\n",
      "val_loss: 0.5501828253114779\n",
      "val_precision: tensor([0.7660, 0.8277, 0.7867, 0.7420], device='cuda:0')\n",
      "val_recall: tensor([0.7089, 0.8570, 0.8250, 0.6710], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.47342562960570594\n",
      "train_precision: tensor([0.7608, 0.8419, 0.8194, 0.7757], device='cuda:0')\n",
      "train_recall: tensor([0.7574, 0.8641, 0.8073, 0.7209], device='cuda:0')\n",
      "val_loss: 0.5885939150276579\n",
      "val_precision: tensor([0.7517, 0.8315, 0.7994, 0.7396], device='cuda:0')\n",
      "val_recall: tensor([0.7317, 0.8495, 0.8104, 0.6741], device='cuda:0')\n",
      "Learning rate: 0.00015615731118230408\n",
      "train_loss: 0.4710084545333871\n",
      "train_precision: tensor([0.7648, 0.8431, 0.8201, 0.7686], device='cuda:0')\n",
      "train_recall: tensor([0.7588, 0.8655, 0.8103, 0.7160], device='cuda:0')\n",
      "val_loss: 0.5632770097008641\n",
      "val_precision: tensor([0.7522, 0.8291, 0.8055, 0.7515], device='cuda:0')\n",
      "val_recall: tensor([0.7371, 0.8545, 0.8058, 0.6690], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "train_loss: 0.466162033984075\n",
      "train_precision: tensor([0.7623, 0.8445, 0.8248, 0.7805], device='cuda:0')\n",
      "train_recall: tensor([0.7633, 0.8668, 0.8070, 0.7322], device='cuda:0')\n",
      "val_loss: 0.6255719284165091\n",
      "val_precision: tensor([0.7488, 0.8309, 0.8093, 0.7386], device='cuda:0')\n",
      "val_recall: tensor([0.7423, 0.8501, 0.8042, 0.6791], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "train_loss: 0.46510791718893507\n",
      "train_precision: tensor([0.7657, 0.8438, 0.8241, 0.7759], device='cuda:0')\n",
      "train_recall: tensor([0.7614, 0.8669, 0.8108, 0.7320], device='cuda:0')\n",
      "val_loss: 0.6017222156642015\n",
      "val_precision: tensor([0.7512, 0.8318, 0.8056, 0.7462], device='cuda:0')\n",
      "val_recall: tensor([0.7399, 0.8503, 0.8077, 0.6731], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "train_loss: 0.4640402711670974\n",
      "train_precision: tensor([0.7656, 0.8435, 0.8245, 0.7776], device='cuda:0')\n",
      "train_recall: tensor([0.7610, 0.8671, 0.8114, 0.7302], device='cuda:0')\n",
      "val_loss: 0.7002299297504474\n",
      "val_precision: tensor([0.7570, 0.8290, 0.7979, 0.7572], device='cuda:0')\n",
      "val_recall: tensor([0.7268, 0.8512, 0.8178, 0.6677], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "train_loss: 0.46351428533820344\n",
      "train_precision: tensor([0.7677, 0.8451, 0.8247, 0.7677], device='cuda:0')\n",
      "train_recall: tensor([0.7640, 0.8671, 0.8112, 0.7300], device='cuda:0')\n",
      "val_loss: 0.6097200321409987\n",
      "val_precision: tensor([0.7588, 0.8324, 0.7948, 0.7487], device='cuda:0')\n",
      "val_recall: tensor([0.7265, 0.8502, 0.8198, 0.6710], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "train_loss: 0.4635337497686783\n",
      "train_precision: tensor([0.7680, 0.8457, 0.8238, 0.7794], device='cuda:0')\n",
      "train_recall: tensor([0.7632, 0.8668, 0.8135, 0.7294], device='cuda:0')\n",
      "val_loss: 0.6676526763741835\n",
      "val_precision: tensor([0.7552, 0.8341, 0.7956, 0.7501], device='cuda:0')\n",
      "val_recall: tensor([0.7293, 0.8472, 0.8190, 0.6700], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "train_loss: 0.4632554671523038\n",
      "train_precision: tensor([0.7663, 0.8438, 0.8248, 0.7783], device='cuda:0')\n",
      "train_recall: tensor([0.7624, 0.8674, 0.8103, 0.7369], device='cuda:0')\n",
      "val_loss: 0.5712687176280689\n",
      "val_precision: tensor([0.7512, 0.8378, 0.8012, 0.7437], device='cuda:0')\n",
      "val_recall: tensor([0.7402, 0.8449, 0.8133, 0.6771], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "train_loss: 0.4613678442755583\n",
      "train_precision: tensor([0.7691, 0.8449, 0.8241, 0.7803], device='cuda:0')\n",
      "train_recall: tensor([0.7628, 0.8680, 0.8131, 0.7341], device='cuda:0')\n",
      "val_loss: 0.5802299056800536\n",
      "val_precision: tensor([0.7545, 0.8361, 0.7995, 0.7534], device='cuda:0')\n",
      "val_recall: tensor([0.7365, 0.8476, 0.8159, 0.6747], device='cuda:0')\n",
      "Learning rate: 1.561573111823041e-05\n",
      "Early stopping at epoch 78 with best validation loss 0.527959736594882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_name = f'efficient_net_pad_no_norm{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "set_seed(2233)\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "        \n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate)\n",
    "my_model = my_model.to('cuda')\n",
    "early_stop_patience = 15\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(my_model.state_dict(), f\"{run_path}.pt\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d95ffee-8ed1-42d1-97f6-8d39b5e1b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[718 102 170  10]\n",
      " [ 84 872  40   4]\n",
      " [123  44 826   7]\n",
      " [ 13  10   9  68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74      1000\n",
      "           1       0.85      0.87      0.86      1000\n",
      "           2       0.79      0.83      0.81      1000\n",
      "           3       0.76      0.68      0.72       100\n",
      "\n",
      "    accuracy                           0.80      3100\n",
      "   macro avg       0.79      0.77      0.78      3100\n",
      "weighted avg       0.80      0.80      0.80      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data')\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00797f73-95e5-409b-ac69-13fcde55494c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
