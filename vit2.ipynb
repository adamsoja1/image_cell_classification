{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1e6451-4e5d-4de9-99f1-a3e22f42717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240714_223918-o58zi0di</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/o58zi0di' target=\"_blank\">VIT_2024-07-14 22:39:17.065331</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/o58zi0di' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/o58zi0di</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "train_loss: 1.088956790240038\n",
      "train_precision: tensor([0.4081, 0.4758, 0.4408, 0.0000], device='cuda:0')\n",
      "train_recall: tensor([0.3653, 0.5611, 0.4522, 0.0000], device='cuda:0')\n",
      "val_loss: 0.9357386310895284\n",
      "val_precision: tensor([0.6368, 0.6639, 0.5634, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.3398, 0.7739, 0.7891, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 0 time:  1.8627817309999954\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "train_loss: 1.0374562854568163\n",
      "train_precision: tensor([0.4509, 0.5056, 0.4765, 0.4792], device='cuda:0')\n",
      "train_recall: tensor([0.4158, 0.5589, 0.5108, 0.0033], device='cuda:0')\n",
      "val_loss: 1.021215814103683\n",
      "val_precision: tensor([0.5489, 0.8188, 0.4996, 0.3122], device='cuda:0')\n",
      "val_recall: tensor([0.3227, 0.5619, 0.8937, 0.1158], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 1 time:  1.4568302506333415\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "train_loss: 1.0165115782192775\n",
      "train_precision: tensor([0.4591, 0.5105, 0.4941, 0.5731], device='cuda:0')\n",
      "train_recall: tensor([0.4324, 0.5765, 0.5054, 0.0345], device='cuda:0')\n",
      "val_loss: 0.8099312671356731\n",
      "val_precision: tensor([0.6095, 0.7346, 0.6402, 0.5813], device='cuda:0')\n",
      "val_recall: tensor([0.4952, 0.7837, 0.7691, 0.1131], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 2 time:  1.4556648660166653\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "train_loss: 1.0037747396599679\n",
      "train_precision: tensor([0.4589, 0.5145, 0.5064, 0.5442], device='cuda:0')\n",
      "train_recall: tensor([0.4476, 0.5864, 0.4929, 0.0639], device='cuda:0')\n",
      "val_loss: 0.8017968313561545\n",
      "val_precision: tensor([0.5666, 0.7475, 0.7245, 0.5124], device='cuda:0')\n",
      "val_recall: tensor([0.6757, 0.7732, 0.6069, 0.1808], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 3 time:  1.458971198216659\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "train_loss: 0.994124382521425\n",
      "train_precision: tensor([0.4772, 0.5355, 0.4841, 0.5632], device='cuda:0')\n",
      "train_recall: tensor([0.4329, 0.5583, 0.5500, 0.0791], device='cuda:0')\n",
      "val_loss: 0.7924983950124846\n",
      "val_precision: tensor([0.6068, 0.7634, 0.6715, 0.6237], device='cuda:0')\n",
      "val_recall: tensor([0.5975, 0.7618, 0.7291, 0.1987], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 4 time:  1.4614818928666713\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "train_loss: 0.9859596093495687\n",
      "train_precision: tensor([0.4805, 0.5234, 0.4960, 0.5788], device='cuda:0')\n",
      "train_recall: tensor([0.4320, 0.5855, 0.5280, 0.1033], device='cuda:0')\n",
      "val_loss: 0.8379804954760605\n",
      "val_precision: tensor([0.6183, 0.7025, 0.6702, 0.6619], device='cuda:0')\n",
      "val_recall: tensor([0.5157, 0.8142, 0.7294, 0.1239], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 5 time:  1.458114044633324\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "train_loss: 0.9806946382636116\n",
      "train_precision: tensor([0.4762, 0.5314, 0.5045, 0.5837], device='cuda:0')\n",
      "train_recall: tensor([0.4592, 0.5767, 0.5201, 0.1137], device='cuda:0')\n",
      "val_loss: 0.7903846414552794\n",
      "val_precision: tensor([0.6064, 0.7873, 0.6591, 0.6752], device='cuda:0')\n",
      "val_recall: tensor([0.6146, 0.7374, 0.7371, 0.2121], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 6 time:  1.4529687924333303\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "train_loss: 0.9742903038859367\n",
      "train_precision: tensor([0.4735, 0.5302, 0.5133, 0.5820], device='cuda:0')\n",
      "train_recall: tensor([0.4646, 0.5835, 0.5123, 0.1177], device='cuda:0')\n",
      "val_loss: 0.7903877348535591\n",
      "val_precision: tensor([0.6111, 0.6842, 0.7756, 0.6170], device='cuda:0')\n",
      "val_recall: tensor([0.6359, 0.8729, 0.5807, 0.2148], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 7 time:  1.4521997669833278\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "train_loss: 0.9703493976876849\n",
      "train_precision: tensor([0.4710, 0.5311, 0.5204, 0.6121], device='cuda:0')\n",
      "train_recall: tensor([0.4711, 0.5827, 0.5109, 0.1280], device='cuda:0')\n",
      "val_loss: 0.7464340876373979\n",
      "val_precision: tensor([0.6014, 0.7378, 0.7748, 0.5437], device='cuda:0')\n",
      "val_recall: tensor([0.6915, 0.8113, 0.6090, 0.3519], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 8 time:  1.4527150797166692\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "train_loss: 0.9650796069985345\n",
      "train_precision: tensor([0.4912, 0.5356, 0.5052, 0.5978], device='cuda:0')\n",
      "train_recall: tensor([0.4537, 0.5859, 0.5349, 0.1394], device='cuda:0')\n",
      "val_loss: 0.7608212071988317\n",
      "val_precision: tensor([0.6729, 0.7136, 0.7108, 0.5908], device='cuda:0')\n",
      "val_recall: tensor([0.5642, 0.8568, 0.7190, 0.2912], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 9 time:  1.4495860192666592\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "train_loss: 0.9630471921392849\n",
      "train_precision: tensor([0.4902, 0.5434, 0.5023, 0.6071], device='cuda:0')\n",
      "train_recall: tensor([0.4593, 0.5695, 0.5484, 0.1411], device='cuda:0')\n",
      "val_loss: 0.7109914996557766\n",
      "val_precision: tensor([0.6656, 0.7714, 0.6944, 0.6178], device='cuda:0')\n",
      "val_recall: tensor([0.5980, 0.8043, 0.7659, 0.3451], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 10 time:  1.4555893480000122\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "train_loss: 0.9569667445052238\n",
      "train_precision: tensor([0.4812, 0.5396, 0.5188, 0.6102], device='cuda:0')\n",
      "train_recall: tensor([0.4782, 0.5770, 0.5243, 0.1606], device='cuda:0')\n",
      "val_loss: 0.7642496849099795\n",
      "val_precision: tensor([0.6461, 0.7337, 0.7199, 0.7410], device='cuda:0')\n",
      "val_recall: tensor([0.5972, 0.8446, 0.7172, 0.2081], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 11 time:  1.4487601599833397\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "train_loss: 0.9536927446722985\n",
      "train_precision: tensor([0.4912, 0.5354, 0.5235, 0.6221], device='cuda:0')\n",
      "train_recall: tensor([0.4712, 0.5969, 0.5242, 0.1532], device='cuda:0')\n",
      "val_loss: 0.7403419829077191\n",
      "val_precision: tensor([0.6891, 0.7089, 0.7406, 0.6740], device='cuda:0')\n",
      "val_recall: tensor([0.5804, 0.8734, 0.7190, 0.3704], device='cuda:0')\n",
      "Learning rate: 0.001\n",
      "epoch 12 time:  1.452514748516675\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "train_loss: 0.9490288420802071\n",
      "train_precision: tensor([0.4935, 0.5307, 0.5272, 0.6273], device='cuda:0')\n",
      "train_recall: tensor([0.4691, 0.6060, 0.5170, 0.1688], device='cuda:0')\n",
      "val_loss: 0.715892385194699\n",
      "val_precision: tensor([0.6569, 0.7520, 0.7351, 0.5524], device='cuda:0')\n",
      "val_recall: tensor([0.6229, 0.8301, 0.7093, 0.4576], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 13 time:  1.4504175357166635\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "train_loss: 0.930032739681857\n",
      "train_precision: tensor([0.4812, 0.5829, 0.5264, 0.6678], device='cuda:0')\n",
      "train_recall: tensor([0.5257, 0.5494, 0.5449, 0.1984], device='cuda:0')\n",
      "val_loss: 0.6803152772287527\n",
      "val_precision: tensor([0.6806, 0.7636, 0.7512, 0.6571], device='cuda:0')\n",
      "val_recall: tensor([0.6490, 0.8451, 0.7310, 0.4380], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 14 time:  1.4543514292166795\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "train_loss: 0.9259524748438881\n",
      "train_precision: tensor([0.5436, 0.5942, 0.4753, 0.6748], device='cuda:0')\n",
      "train_recall: tensor([0.4351, 0.5333, 0.6521, 0.2027], device='cuda:0')\n",
      "val_loss: 0.6739583200878567\n",
      "val_precision: tensor([0.6822, 0.7599, 0.7546, 0.7001], device='cuda:0')\n",
      "val_recall: tensor([0.6495, 0.8505, 0.7304, 0.4253], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 15 time:  1.4536688222333396\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "train_loss: 0.9243703784687178\n",
      "train_precision: tensor([0.4750, 0.5727, 0.5489, 0.6752], device='cuda:0')\n",
      "train_recall: tensor([0.5512, 0.5602, 0.5103, 0.2139], device='cuda:0')\n",
      "val_loss: 0.6790043314297994\n",
      "val_precision: tensor([0.6894, 0.7589, 0.7469, 0.7048], device='cuda:0')\n",
      "val_recall: tensor([0.6320, 0.8536, 0.7449, 0.4316], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 16 time:  1.454025407650003\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "train_loss: 0.9221370119424094\n",
      "train_precision: tensor([0.4976, 0.5757, 0.5181, 0.6723], device='cuda:0')\n",
      "train_recall: tensor([0.5022, 0.5601, 0.5623, 0.2176], device='cuda:0')\n",
      "val_loss: 0.6742832611004511\n",
      "val_precision: tensor([0.6868, 0.7566, 0.7502, 0.6993], device='cuda:0')\n",
      "val_recall: tensor([0.6396, 0.8549, 0.7330, 0.4306], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 17 time:  1.462386851516673\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "train_loss: 0.9231500451053892\n",
      "train_precision: tensor([0.5587, 0.5225, 0.5144, 0.6763], device='cuda:0')\n",
      "train_recall: tensor([0.4134, 0.6400, 0.5673, 0.2186], device='cuda:0')\n",
      "val_loss: 0.6693364608618948\n",
      "val_precision: tensor([0.6879, 0.7702, 0.7490, 0.6242], device='cuda:0')\n",
      "val_recall: tensor([0.6429, 0.8433, 0.7441, 0.4815], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 18 time:  1.4625663258333286\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "train_loss: 0.9204350747522854\n",
      "train_precision: tensor([0.4993, 0.5439, 0.5485, 0.6719], device='cuda:0')\n",
      "train_recall: tensor([0.5027, 0.6030, 0.5223, 0.2160], device='cuda:0')\n",
      "val_loss: 0.6780427707566156\n",
      "val_precision: tensor([0.6842, 0.7607, 0.7598, 0.7064], device='cuda:0')\n",
      "val_recall: tensor([0.6540, 0.8546, 0.7296, 0.4269], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 19 time:  1.455908347283336\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "train_loss: 0.9188275980097907\n",
      "train_precision: tensor([0.4879, 0.6219, 0.5065, 0.6746], device='cuda:0')\n",
      "train_recall: tensor([0.5264, 0.5130, 0.5887, 0.2280], device='cuda:0')\n",
      "val_loss: 0.6775264066126612\n",
      "val_precision: tensor([0.7004, 0.7519, 0.7537, 0.6853], device='cuda:0')\n",
      "val_recall: tensor([0.6333, 0.8633, 0.7429, 0.4253], device='cuda:0')\n",
      "Learning rate: 0.0001\n",
      "epoch 20 time:  1.4573899391500011\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "train_loss: 0.9198014151482355\n",
      "train_precision: tensor([0.5033, 0.5798, 0.5176, 0.6743], device='cuda:0')\n",
      "train_recall: tensor([0.5053, 0.5556, 0.5726, 0.2130], device='cuda:0')\n",
      "val_loss: 0.6694310830699073\n",
      "val_precision: tensor([0.6977, 0.7581, 0.7498, 0.6885], device='cuda:0')\n",
      "val_recall: tensor([0.6339, 0.8601, 0.7444, 0.4421], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 21 time:  1.4568662996166646\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "train_loss: 0.9167245529237248\n",
      "train_precision: tensor([0.6712, 0.4976, 0.5112, 0.6891], device='cuda:0')\n",
      "train_recall: tensor([0.3461, 0.7047, 0.5806, 0.2219], device='cuda:0')\n",
      "val_loss: 0.6670381639566686\n",
      "val_precision: tensor([0.6933, 0.7640, 0.7522, 0.6850], device='cuda:0')\n",
      "val_recall: tensor([0.6434, 0.8552, 0.7434, 0.4407], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 22 time:  1.4701895893833352\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "train_loss: 0.91453950128385\n",
      "train_precision: tensor([0.4777, 0.5830, 0.5476, 0.6903], device='cuda:0')\n",
      "train_recall: tensor([0.5520, 0.5524, 0.5285, 0.2190], device='cuda:0')\n",
      "val_loss: 0.66939792326755\n",
      "val_precision: tensor([0.6988, 0.7591, 0.7533, 0.6805], device='cuda:0')\n",
      "val_recall: tensor([0.6367, 0.8604, 0.7457, 0.4468], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 23 time:  1.4654667333499978\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "train_loss: 0.917129413996424\n",
      "train_precision: tensor([0.5282, 0.5348, 0.5267, 0.6902], device='cuda:0')\n",
      "train_recall: tensor([0.4609, 0.6163, 0.5491, 0.2241], device='cuda:0')\n",
      "val_loss: 0.6654050582812892\n",
      "val_precision: tensor([0.6984, 0.7652, 0.7487, 0.6657], device='cuda:0')\n",
      "val_recall: tensor([0.6370, 0.8548, 0.7504, 0.4566], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 24 time:  1.4538486608333339\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "train_loss: 0.9161390529502006\n",
      "train_precision: tensor([0.4842, 0.6061, 0.5194, 0.6908], device='cuda:0')\n",
      "train_recall: tensor([0.5377, 0.5272, 0.5649, 0.2221], device='cuda:0')\n",
      "val_loss: 0.6673694096505642\n",
      "val_precision: tensor([0.7056, 0.7586, 0.7475, 0.6703], device='cuda:0')\n",
      "val_recall: tensor([0.6266, 0.8610, 0.7546, 0.4519], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 25 time:  1.479107874033328\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "train_loss: 0.9158642531150863\n",
      "train_precision: tensor([0.5274, 0.5422, 0.5253, 0.6820], device='cuda:0')\n",
      "train_recall: tensor([0.4613, 0.6117, 0.5590, 0.2253], device='cuda:0')\n",
      "val_loss: 0.664476462205251\n",
      "val_precision: tensor([0.7010, 0.7628, 0.7503, 0.6579], device='cuda:0')\n",
      "val_recall: tensor([0.6344, 0.8572, 0.7510, 0.4623], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 26 time:  1.469950877233335\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "train_loss: 0.9153359286132313\n",
      "train_precision: tensor([0.5304, 0.5324, 0.5336, 0.6900], device='cuda:0')\n",
      "train_recall: tensor([0.4599, 0.6262, 0.5461, 0.2293], device='cuda:0')\n",
      "val_loss: 0.665376101517015\n",
      "val_precision: tensor([0.7048, 0.7548, 0.7541, 0.6703], device='cuda:0')\n",
      "val_recall: tensor([0.6308, 0.8633, 0.7488, 0.4593], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 27 time:  1.4886326975000126\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "train_loss: 0.913840325815337\n",
      "train_precision: tensor([0.5017, 0.5256, 0.5797, 0.6853], device='cuda:0')\n",
      "train_recall: tensor([0.5029, 0.6412, 0.4897, 0.2241], device='cuda:0')\n",
      "val_loss: 0.6704895268711779\n",
      "val_precision: tensor([0.7018, 0.7524, 0.7581, 0.6688], device='cuda:0')\n",
      "val_recall: tensor([0.6341, 0.8671, 0.7395, 0.4582], device='cuda:0')\n",
      "Learning rate: 1e-05\n",
      "epoch 28 time:  1.4889935492666608\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "train_loss: 0.9153776810992331\n",
      "train_precision: tensor([0.4873, 0.6227, 0.5080, 0.6937], device='cuda:0')\n",
      "train_recall: tensor([0.5295, 0.5120, 0.5881, 0.2323], device='cuda:0')\n",
      "val_loss: 0.6670536458492279\n",
      "val_precision: tensor([0.7007, 0.7564, 0.7566, 0.6733], device='cuda:0')\n",
      "val_recall: tensor([0.6374, 0.8609, 0.7453, 0.4525], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 29 time:  1.480473696383342\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "train_loss: 0.9148388456730615\n",
      "train_precision: tensor([0.4599, 0.6072, 0.5640, 0.6833], device='cuda:0')\n",
      "train_recall: tensor([0.6015, 0.5283, 0.5012, 0.2286], device='cuda:0')\n",
      "val_loss: 0.6660436303251319\n",
      "val_precision: tensor([0.7037, 0.7561, 0.7536, 0.6631], device='cuda:0')\n",
      "val_recall: tensor([0.6319, 0.8626, 0.7479, 0.4566], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 30 time:  1.4737347526166862\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "train_loss: 0.9135209585939135\n",
      "train_precision: tensor([0.4933, 0.6455, 0.4977, 0.6751], device='cuda:0')\n",
      "train_recall: tensor([0.5212, 0.4997, 0.6148, 0.2306], device='cuda:0')\n",
      "val_loss: 0.666469302193986\n",
      "val_precision: tensor([0.7046, 0.7559, 0.7545, 0.6713], device='cuda:0')\n",
      "val_recall: tensor([0.6328, 0.8641, 0.7479, 0.4532], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 31 time:  1.447208362383329\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n",
      "train_loss: 0.9143975210331735\n",
      "train_precision: tensor([0.5046, 0.6521, 0.4862, 0.6748], device='cuda:0')\n",
      "train_recall: tensor([0.4988, 0.4913, 0.6438, 0.2303], device='cuda:0')\n",
      "val_loss: 0.6653465838068061\n",
      "val_precision: tensor([0.7007, 0.7627, 0.7491, 0.6613], device='cuda:0')\n",
      "val_recall: tensor([0.6334, 0.8566, 0.7521, 0.4556], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 32 time:  1.4396223487166633\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 33\n",
      "train_loss: 0.9152045757997603\n",
      "train_precision: tensor([0.4985, 0.6707, 0.4830, 0.6900], device='cuda:0')\n",
      "train_recall: tensor([0.5113, 0.4780, 0.6421, 0.2232], device='cuda:0')\n",
      "val_loss: 0.6671639799243874\n",
      "val_precision: tensor([0.6970, 0.7593, 0.7547, 0.6696], device='cuda:0')\n",
      "val_recall: tensor([0.6389, 0.8608, 0.7410, 0.4539], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 33 time:  1.4392828964000122\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 34\n",
      "train_loss: 0.9149733307106155\n",
      "train_precision: tensor([0.5160, 0.6364, 0.4833, 0.6913], device='cuda:0')\n",
      "train_recall: tensor([0.4881, 0.5014, 0.6442, 0.2291], device='cuda:0')\n",
      "val_loss: 0.6682353968421618\n",
      "val_precision: tensor([0.7029, 0.7519, 0.7591, 0.6678], device='cuda:0')\n",
      "val_recall: tensor([0.6334, 0.8679, 0.7409, 0.4582], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 34 time:  1.4398875114666831\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 35\n",
      "train_loss: 0.914033941144035\n",
      "train_precision: tensor([0.4898, 0.5665, 0.5452, 0.6752], device='cuda:0')\n",
      "train_recall: tensor([0.5293, 0.5785, 0.5257, 0.2283], device='cuda:0')\n",
      "val_loss: 0.6670416543881098\n",
      "val_precision: tensor([0.7067, 0.7553, 0.7513, 0.6667], device='cuda:0')\n",
      "val_recall: tensor([0.6270, 0.8643, 0.7512, 0.4572], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "epoch 35 time:  1.4397981166999974\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 36\n",
      "train_loss: 0.9159257683016006\n",
      "train_precision: tensor([0.4877, 0.5992, 0.5251, 0.6818], device='cuda:0')\n",
      "train_recall: tensor([0.5344, 0.5406, 0.5617, 0.2216], device='cuda:0')\n",
      "val_loss: 0.6671608267558946\n",
      "val_precision: tensor([0.7030, 0.7540, 0.7574, 0.6662], device='cuda:0')\n",
      "val_recall: tensor([0.6355, 0.8642, 0.7435, 0.4549], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "Early stopping at epoch 36 with best validation loss 0.664476462205251\n",
      "training_checkpoints/VIT_2024-07-14 22:39:17.065331.pth\n",
      "training_checkpoints/VIT_2024-07-14 22:39:17.065331.pth\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "from vit.vit import VisionTransformer\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "\n",
    "run_name = f'VIT_{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),]\n",
    ")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=2, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "\n",
    "model = VisionTransformer(image_size=32, in_channels=3, num_classes=4, hidden_dims=[128, 128], dropout_rate=0.6)\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch/60}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))\n",
    "print(f'{run_path}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2a1719-3ece-402d-af71-7a79ea310303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[651 135 204  10]\n",
      " [ 94 867  35   4]\n",
      " [149  81 763   7]\n",
      " [ 17  21  14  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68      1000\n",
      "           1       0.79      0.87      0.82      1000\n",
      "           2       0.75      0.76      0.76      1000\n",
      "           3       0.70      0.48      0.57       100\n",
      "\n",
      "    accuracy                           0.75      3100\n",
      "   macro avg       0.74      0.69      0.71      3100\n",
      "weighted avg       0.75      0.75      0.75      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data')\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ebfb0-e616-422f-ae2a-f4fec7672582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import ImageDataset\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Precision, Recall\n",
    "from torchvision.models import resnet18\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('high')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'dinov2_42x42_1024batch{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "import random\n",
    "random.seed(2233)\n",
    "torch.manual_seed(2233)\n",
    "\n",
    "#After /255 so in loading dataset there are no division by 255 just this normalization\n",
    "mean = [0.5005, 0.3526, 0.5494]\n",
    "std = [0.1493, 0.1340, 0.1123]\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.4, p=1), RandomContrast(limit=0.4, p=1)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.005, patience=2, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss},step=self.step)\n",
    "        wandb.log({'Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()},step=self.step)\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        wandb.log({'val_Normal recall': recall[0].item()},step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()},step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()},step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()},step=self.step)\n",
    "\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 256\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_lc')\n",
    "model.linear_head = nn.Linear(1920, 4)\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "my_model = my_model.to('cuda')\n",
    "\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}') \n",
    "    time_start = time.perf_counter()\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state_dict = my_model.state_dict()\n",
    "        torch.save(best_model_state_dict, f'{run_path}.pth')\n",
    "        \n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'epoch {epoch} time:  {time_epoch/60}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'{run_path}.pth')\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c86cf-ad88-4a44-a93b-07eaca5c7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data')\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
