{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3dc9e67-0431-40f2-b3bc-ce857f88bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 346\n",
    "learning_rate = 0.008723192040775533\n",
    "dropout_rate = 0.25019714252443587\n",
    "kernel_size = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5105a2-d608-456c-bd07-4fbca6a15b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        files = os.listdir(path)\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['filename'] = []\n",
    "        dataset_final['class'] = []\n",
    "        for filename in files:\n",
    "            dataset = pd.DataFrame()\n",
    "            if filename.endswith('.txt'):\n",
    "                files = get_images_list(f'{path}/{filename}')\n",
    "                dataset['filename'] = files\n",
    "                dataset['class'] = filename.split('_')[1][:-3]\n",
    "                dataset_final = pd.concat([dataset_final, dataset], ignore_index=True)\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"filename\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        #image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset[\"class\"].loc[idx]\n",
    "\n",
    "        if target == 'normal.':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target == 'inflamatory.':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target == 'tumor.':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target == 'other.':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "       \n",
    "     \n",
    "\n",
    "        \"\"\"To see transorms use:\n",
    "            image, target = trainset[15]\n",
    "            image = image.numpy()\n",
    "            image=np.swapaxes(image,0,1)\n",
    "            image=np.swapaxes(image,1,2)\n",
    "            plt.imshow(image)\"\"\"\n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c0dcac-1c09-4caf-b1ed-d357112031ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:2587: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2233)\n",
    "\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        OneOf([RandomBrightness(limit=0.0, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc76746-e31d-4264-86e1-0c4941c3208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11170884"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = ImageDataset(data_path='train_data', transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data')\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model setup\n",
    "model = resnet18()\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(kernel_size, kernel_size), stride=(1, 1), padding=(kernel_size // 2, kernel_size // 2), bias=False)\n",
    "num_classes = 4\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(model.fc.in_features, num_classes)\n",
    ")\n",
    "model = model.to('cuda')\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1220283-65c6-4476-a8e4-084f05a2f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240824_233226-4ggha4bu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/4ggha4bu' target=\"_blank\">resnet18 final_no_norm_no_pad_final2024-08-24 23:32:25.058778</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/4ggha4bu' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/4ggha4bu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.89498111648836\n",
      "train_precision: tensor([0.5561, 0.6850, 0.6403, 0.5339], device='cuda:0')\n",
      "train_recall: tensor([0.5512, 0.7510, 0.6429, 0.0443], device='cuda:0')\n",
      "val_loss: 1.1243722969003385\n",
      "val_precision: tensor([0.7096, 0.8286, 0.4217, 0.3741], device='cuda:0')\n",
      "val_recall: tensor([0.1064, 0.5489, 0.9439, 0.1832], device='cuda:0')\n",
      "Learning rate: 0.008723192040775533\n",
      "train_loss: 0.7712055732662552\n",
      "train_precision: tensor([0.6198, 0.7327, 0.6937, 0.5806], device='cuda:0')\n",
      "train_recall: tensor([0.6069, 0.7890, 0.6985, 0.2146], device='cuda:0')\n",
      "val_loss: 0.9055652509021402\n",
      "val_precision: tensor([0.5071, 0.7004, 0.8170, 0.6179], device='cuda:0')\n",
      "val_recall: tensor([0.7795, 0.7732, 0.3489, 0.1976], device='cuda:0')\n",
      "Learning rate: 0.008723192040775533\n",
      "train_loss: 0.7278499261576581\n",
      "train_precision: tensor([0.6420, 0.7491, 0.7103, 0.6124], device='cuda:0')\n",
      "train_recall: tensor([0.6264, 0.8013, 0.7157, 0.2882], device='cuda:0')\n",
      "val_loss: 0.7558585486831736\n",
      "val_precision: tensor([0.6506, 0.7162, 0.7253, 0.8711], device='cuda:0')\n",
      "val_recall: tensor([0.6187, 0.8419, 0.6953, 0.1320], device='cuda:0')\n",
      "Learning rate: 0.008723192040775533\n",
      "train_loss: 0.6961652576059535\n",
      "train_precision: tensor([0.6556, 0.7616, 0.7218, 0.6290], device='cuda:0')\n",
      "train_recall: tensor([0.6433, 0.8082, 0.7246, 0.3362], device='cuda:0')\n",
      "val_loss: 0.8094013307648205\n",
      "val_precision: tensor([0.6019, 0.7727, 0.6139, 0.5641], device='cuda:0')\n",
      "val_recall: tensor([0.5053, 0.7149, 0.7975, 0.2030], device='cuda:0')\n",
      "Learning rate: 0.008723192040775533\n",
      "train_loss: 0.6731457024956671\n",
      "train_precision: tensor([0.6655, 0.7705, 0.7343, 0.6641], device='cuda:0')\n",
      "train_recall: tensor([0.6548, 0.8158, 0.7344, 0.3794], device='cuda:0')\n",
      "val_loss: 1.5751961213484238\n",
      "val_precision: tensor([0.6246, 0.9221, 0.4000, 0.4766], device='cuda:0')\n",
      "val_recall: tensor([0.1930, 0.2859, 0.9752, 0.2054], device='cuda:0')\n",
      "Learning rate: 0.008723192040775533\n",
      "train_loss: 0.656919094003533\n",
      "train_precision: tensor([0.6743, 0.7767, 0.7425, 0.6630], device='cuda:0')\n",
      "train_recall: tensor([0.6636, 0.8182, 0.7425, 0.4128], device='cuda:0')\n",
      "val_loss: 0.9934345291794909\n",
      "val_precision: tensor([0.5816, 0.7940, 0.5363, 0.4982], device='cuda:0')\n",
      "val_recall: tensor([0.3899, 0.6609, 0.8467, 0.0919], device='cuda:0')\n",
      "Learning rate: 0.008723192040775533\n",
      "train_loss: 0.6428490973133204\n",
      "train_precision: tensor([0.6813, 0.7824, 0.7474, 0.6715], device='cuda:0')\n",
      "train_recall: tensor([0.6699, 0.8247, 0.7449, 0.4442], device='cuda:0')\n",
      "val_loss: 0.7857567732700248\n",
      "val_precision: tensor([0.6524, 0.6442, 0.8200, 0.6947], device='cuda:0')\n",
      "val_recall: tensor([0.6210, 0.8997, 0.5811, 0.2980], device='cuda:0')\n",
      "Learning rate: 0.008723192040775533\n",
      "train_loss: 0.6297555020657907\n",
      "train_precision: tensor([0.6906, 0.7869, 0.7545, 0.6706], device='cuda:0')\n",
      "train_recall: tensor([0.6762, 0.8284, 0.7537, 0.4638], device='cuda:0')\n",
      "val_loss: 0.7629802821392424\n",
      "val_precision: tensor([0.6478, 0.6354, 0.8467, 0.7218], device='cuda:0')\n",
      "val_recall: tensor([0.6064, 0.9207, 0.5585, 0.3983], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5734885682422374\n",
      "train_precision: tensor([0.7169, 0.8053, 0.7787, 0.7112], device='cuda:0')\n",
      "train_recall: tensor([0.7025, 0.8439, 0.7743, 0.5535], device='cuda:0')\n",
      "val_loss: 0.567928128139803\n",
      "val_precision: tensor([0.7256, 0.8135, 0.7721, 0.7109], device='cuda:0')\n",
      "val_recall: tensor([0.6973, 0.8386, 0.7938, 0.5687], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5585370240868002\n",
      "train_precision: tensor([0.7233, 0.8113, 0.7831, 0.7138], device='cuda:0')\n",
      "train_recall: tensor([0.7094, 0.8461, 0.7806, 0.5683], device='cuda:0')\n",
      "val_loss: 0.6591638508026073\n",
      "val_precision: tensor([0.7191, 0.8660, 0.6552, 0.6654], device='cuda:0')\n",
      "val_recall: tensor([0.5945, 0.7365, 0.8780, 0.5492], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5484702219517719\n",
      "train_precision: tensor([0.7295, 0.8152, 0.7886, 0.7182], device='cuda:0')\n",
      "train_recall: tensor([0.7140, 0.8497, 0.7861, 0.5890], device='cuda:0')\n",
      "val_loss: 0.5620931895931115\n",
      "val_precision: tensor([0.7310, 0.8008, 0.7804, 0.7855], device='cuda:0')\n",
      "val_recall: tensor([0.6951, 0.8528, 0.7932, 0.5327], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5417552513584807\n",
      "train_precision: tensor([0.7319, 0.8179, 0.7921, 0.7283], device='cuda:0')\n",
      "train_recall: tensor([0.7197, 0.8512, 0.7866, 0.6043], device='cuda:0')\n",
      "val_loss: 0.5613523989580991\n",
      "val_precision: tensor([0.7141, 0.7977, 0.8038, 0.7598], device='cuda:0')\n",
      "val_recall: tensor([0.7208, 0.8584, 0.7560, 0.5613], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5343879010174394\n",
      "train_precision: tensor([0.7341, 0.8187, 0.7941, 0.7343], device='cuda:0')\n",
      "train_recall: tensor([0.7205, 0.8518, 0.7895, 0.6165], device='cuda:0')\n",
      "val_loss: 0.5683370994941126\n",
      "val_precision: tensor([0.7068, 0.8294, 0.7746, 0.7307], device='cuda:0')\n",
      "val_recall: tensor([0.7203, 0.8204, 0.7832, 0.5892], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5269829381299288\n",
      "train_precision: tensor([0.7377, 0.8221, 0.7983, 0.7313], device='cuda:0')\n",
      "train_recall: tensor([0.7264, 0.8543, 0.7915, 0.6193], device='cuda:0')\n",
      "val_loss: 0.5602508987603563\n",
      "val_precision: tensor([0.7062, 0.7971, 0.8175, 0.7232], device='cuda:0')\n",
      "val_recall: tensor([0.7310, 0.8614, 0.7359, 0.6071], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5197920336143598\n",
      "train_precision: tensor([0.7407, 0.8244, 0.8027, 0.7396], device='cuda:0')\n",
      "train_recall: tensor([0.7295, 0.8546, 0.7963, 0.6390], device='cuda:0')\n",
      "val_loss: 0.5681317652321041\n",
      "val_precision: tensor([0.7102, 0.7774, 0.8361, 0.7050], device='cuda:0')\n",
      "val_recall: tensor([0.7285, 0.8835, 0.7108, 0.6178], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5126165058013897\n",
      "train_precision: tensor([0.7430, 0.8281, 0.8054, 0.7429], device='cuda:0')\n",
      "train_recall: tensor([0.7360, 0.8566, 0.7961, 0.6426], device='cuda:0')\n",
      "val_loss: 0.5554288521911321\n",
      "val_precision: tensor([0.7545, 0.8179, 0.7544, 0.7156], device='cuda:0')\n",
      "val_recall: tensor([0.6614, 0.8483, 0.8291, 0.6253], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.5050786353059821\n",
      "train_precision: tensor([0.7459, 0.8311, 0.8076, 0.7499], device='cuda:0')\n",
      "train_recall: tensor([0.7384, 0.8589, 0.7979, 0.6642], device='cuda:0')\n",
      "val_loss: 0.5459135875719764\n",
      "val_precision: tensor([0.7296, 0.7993, 0.8082, 0.7651], device='cuda:0')\n",
      "val_recall: tensor([0.7196, 0.8658, 0.7706, 0.5912], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.49656714875724967\n",
      "train_precision: tensor([0.7487, 0.8336, 0.8117, 0.7570], device='cuda:0')\n",
      "train_recall: tensor([0.7444, 0.8612, 0.7988, 0.6706], device='cuda:0')\n",
      "val_loss: 0.6039473768253898\n",
      "val_precision: tensor([0.7485, 0.8480, 0.6963, 0.7496], device='cuda:0')\n",
      "val_recall: tensor([0.6147, 0.8083, 0.8706, 0.5633], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.48855431442675384\n",
      "train_precision: tensor([0.7541, 0.8367, 0.8146, 0.7589], device='cuda:0')\n",
      "train_recall: tensor([0.7470, 0.8634, 0.8039, 0.6882], device='cuda:0')\n",
      "val_loss: 0.5596761773811297\n",
      "val_precision: tensor([0.7301, 0.8563, 0.7521, 0.7141], device='cuda:0')\n",
      "val_recall: tensor([0.7120, 0.7985, 0.8278, 0.6542], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.47977402839875644\n",
      "train_precision: tensor([0.7576, 0.8404, 0.8183, 0.7731], device='cuda:0')\n",
      "train_recall: tensor([0.7511, 0.8654, 0.8086, 0.7013], device='cuda:0')\n",
      "val_loss: 0.5670648174785943\n",
      "val_precision: tensor([0.7035, 0.8501, 0.7781, 0.6759], device='cuda:0')\n",
      "val_recall: tensor([0.7409, 0.7968, 0.7899, 0.6384], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.4700597307244361\n",
      "train_precision: tensor([0.7621, 0.8441, 0.8231, 0.7637], device='cuda:0')\n",
      "train_recall: tensor([0.7587, 0.8682, 0.8090, 0.7092], device='cuda:0')\n",
      "val_loss: 0.6635674353730813\n",
      "val_precision: tensor([0.7350, 0.8723, 0.6547, 0.6339], device='cuda:0')\n",
      "val_recall: tensor([0.5989, 0.7309, 0.8874, 0.5818], device='cuda:0')\n",
      "Learning rate: 0.0008723192040775533\n",
      "train_loss: 0.4601952092371125\n",
      "train_precision: tensor([0.7666, 0.8464, 0.8255, 0.7782], device='cuda:0')\n",
      "train_recall: tensor([0.7604, 0.8709, 0.8139, 0.7260], device='cuda:0')\n",
      "val_loss: 0.5590295253621504\n",
      "val_precision: tensor([0.7379, 0.8440, 0.7515, 0.7692], device='cuda:0')\n",
      "val_recall: tensor([0.6917, 0.8216, 0.8344, 0.6061], device='cuda:0')\n",
      "Learning rate: 8.723192040775533e-05\n",
      "train_loss: 0.43648361531048774\n",
      "train_precision: tensor([0.7782, 0.8526, 0.8355, 0.8046], device='cuda:0')\n",
      "train_recall: tensor([0.7705, 0.8789, 0.8226, 0.7603], device='cuda:0')\n",
      "val_loss: 0.5354981827601958\n",
      "val_precision: tensor([0.7433, 0.8350, 0.7836, 0.7591], device='cuda:0')\n",
      "val_recall: tensor([0.7174, 0.8421, 0.8157, 0.6481], device='cuda:0')\n",
      "Learning rate: 8.723192040775533e-05\n",
      "train_loss: 0.4305946603777328\n",
      "train_precision: tensor([0.7813, 0.8595, 0.8375, 0.8086], device='cuda:0')\n",
      "train_recall: tensor([0.7777, 0.8798, 0.8261, 0.7657], device='cuda:0')\n",
      "val_loss: 0.5353259138400188\n",
      "val_precision: tensor([0.7498, 0.8295, 0.7870, 0.7534], device='cuda:0')\n",
      "val_recall: tensor([0.7137, 0.8521, 0.8129, 0.6636], device='cuda:0')\n",
      "Learning rate: 8.723192040775533e-05\n",
      "train_loss: 0.4255477769267348\n",
      "train_precision: tensor([0.7842, 0.8597, 0.8391, 0.8066], device='cuda:0')\n",
      "train_recall: tensor([0.7774, 0.8817, 0.8290, 0.7674], device='cuda:0')\n",
      "val_loss: 0.5371207170718618\n",
      "val_precision: tensor([0.7415, 0.8346, 0.7899, 0.7568], device='cuda:0')\n",
      "val_recall: tensor([0.7270, 0.8437, 0.8073, 0.6559], device='cuda:0')\n",
      "Learning rate: 8.723192040775533e-05\n",
      "train_loss: 0.4234895569882723\n",
      "train_precision: tensor([0.7827, 0.8604, 0.8413, 0.8110], device='cuda:0')\n",
      "train_recall: tensor([0.7793, 0.8815, 0.8275, 0.7812], device='cuda:0')\n",
      "val_loss: 0.5384584719991863\n",
      "val_precision: tensor([0.7375, 0.8399, 0.7880, 0.7563], device='cuda:0')\n",
      "val_recall: tensor([0.7302, 0.8367, 0.8090, 0.6582], device='cuda:0')\n",
      "Learning rate: 8.723192040775533e-05\n",
      "train_loss: 0.4216628465291575\n",
      "train_precision: tensor([0.7844, 0.8628, 0.8397, 0.8135], device='cuda:0')\n",
      "train_recall: tensor([0.7790, 0.8820, 0.8294, 0.7876], device='cuda:0')\n",
      "val_loss: 0.5386637717150571\n",
      "val_precision: tensor([0.7403, 0.8394, 0.7864, 0.7730], device='cuda:0')\n",
      "val_recall: tensor([0.7268, 0.8388, 0.8150, 0.6387], device='cuda:0')\n",
      "Learning rate: 8.723192040775533e-05\n",
      "train_loss: 0.4175088385452971\n",
      "train_precision: tensor([0.7865, 0.8622, 0.8428, 0.8167], device='cuda:0')\n",
      "train_recall: tensor([0.7823, 0.8841, 0.8291, 0.7864], device='cuda:0')\n",
      "val_loss: 0.5386587079991115\n",
      "val_precision: tensor([0.7418, 0.8421, 0.7844, 0.7457], device='cuda:0')\n",
      "val_recall: tensor([0.7251, 0.8367, 0.8149, 0.6714], device='cuda:0')\n",
      "Learning rate: 8.723192040775533e-05\n",
      "train_loss: 0.41529186801825935\n",
      "train_precision: tensor([0.7869, 0.8635, 0.8426, 0.8163], device='cuda:0')\n",
      "train_recall: tensor([0.7811, 0.8840, 0.8314, 0.7915], device='cuda:0')\n",
      "val_loss: 0.5519733433419846\n",
      "val_precision: tensor([0.7462, 0.8484, 0.7613, 0.7466], device='cuda:0')\n",
      "val_recall: tensor([0.7039, 0.8231, 0.8350, 0.6707], device='cuda:0')\n",
      "Learning rate: 8.723192040775534e-06\n",
      "train_loss: 0.4113758393051928\n",
      "train_precision: tensor([0.7907, 0.8644, 0.8462, 0.8202], device='cuda:0')\n",
      "train_recall: tensor([0.7849, 0.8862, 0.8338, 0.7928], device='cuda:0')\n",
      "val_loss: 0.5425327780764647\n",
      "val_precision: tensor([0.7478, 0.8378, 0.7818, 0.7470], device='cuda:0')\n",
      "val_recall: tensor([0.7177, 0.8401, 0.8182, 0.6801], device='cuda:0')\n",
      "Learning rate: 8.723192040775534e-06\n",
      "train_loss: 0.4108244185958316\n",
      "train_precision: tensor([0.7883, 0.8651, 0.8455, 0.8218], device='cuda:0')\n",
      "train_recall: tensor([0.7856, 0.8863, 0.8310, 0.7895], device='cuda:0')\n",
      "val_loss: 0.5406640499048911\n",
      "val_precision: tensor([0.7431, 0.8381, 0.7857, 0.7482], device='cuda:0')\n",
      "val_recall: tensor([0.7227, 0.8398, 0.8136, 0.6724], device='cuda:0')\n",
      "Learning rate: 8.723192040775534e-06\n",
      "train_loss: 0.4108694642542257\n",
      "train_precision: tensor([0.7892, 0.8650, 0.8441, 0.8187], device='cuda:0')\n",
      "train_recall: tensor([0.7842, 0.8847, 0.8333, 0.7896], device='cuda:0')\n",
      "val_loss: 0.5409615901525547\n",
      "val_precision: tensor([0.7462, 0.8324, 0.7899, 0.7477], device='cuda:0')\n",
      "val_recall: tensor([0.7206, 0.8476, 0.8098, 0.6795], device='cuda:0')\n",
      "Learning rate: 8.723192040775534e-06\n",
      "train_loss: 0.4114165788399424\n",
      "train_precision: tensor([0.7892, 0.8653, 0.8463, 0.8222], device='cuda:0')\n",
      "train_recall: tensor([0.7862, 0.8857, 0.8325, 0.7935], device='cuda:0')\n",
      "val_loss: 0.5408267279465994\n",
      "val_precision: tensor([0.7456, 0.8339, 0.7886, 0.7593], device='cuda:0')\n",
      "val_recall: tensor([0.7222, 0.8458, 0.8119, 0.6650], device='cuda:0')\n",
      "Learning rate: 8.723192040775534e-06\n",
      "train_loss: 0.4098596215823998\n",
      "train_precision: tensor([0.7896, 0.8653, 0.8455, 0.8140], device='cuda:0')\n",
      "train_recall: tensor([0.7850, 0.8851, 0.8331, 0.7948], device='cuda:0')\n",
      "val_loss: 0.5402410309412953\n",
      "val_precision: tensor([0.7444, 0.8348, 0.7888, 0.7549], device='cuda:0')\n",
      "val_recall: tensor([0.7231, 0.8437, 0.8113, 0.6751], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.4103470151935031\n",
      "train_precision: tensor([0.7900, 0.8663, 0.8455, 0.8231], device='cuda:0')\n",
      "train_recall: tensor([0.7857, 0.8874, 0.8325, 0.7945], device='cuda:0')\n",
      "val_loss: 0.5412329386236069\n",
      "val_precision: tensor([0.7445, 0.8323, 0.7919, 0.7571], device='cuda:0')\n",
      "val_recall: tensor([0.7243, 0.8476, 0.8081, 0.6684], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.40941312501203997\n",
      "train_precision: tensor([0.7898, 0.8653, 0.8461, 0.8212], device='cuda:0')\n",
      "train_recall: tensor([0.7853, 0.8861, 0.8335, 0.7939], device='cuda:0')\n",
      "val_loss: 0.5406560360938869\n",
      "val_precision: tensor([0.7438, 0.8359, 0.7885, 0.7607], device='cuda:0')\n",
      "val_recall: tensor([0.7247, 0.8430, 0.8119, 0.6657], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.4118232746247124\n",
      "train_precision: tensor([0.7885, 0.8648, 0.8449, 0.8230], device='cuda:0')\n",
      "train_recall: tensor([0.7841, 0.8853, 0.8333, 0.7864], device='cuda:0')\n",
      "val_loss: 0.5416171691390905\n",
      "val_precision: tensor([0.7428, 0.8358, 0.7892, 0.7571], device='cuda:0')\n",
      "val_recall: tensor([0.7256, 0.8423, 0.8106, 0.6687], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.4107814376001005\n",
      "train_precision: tensor([0.7904, 0.8660, 0.8456, 0.8231], device='cuda:0')\n",
      "train_recall: tensor([0.7851, 0.8860, 0.8340, 0.8012], device='cuda:0')\n",
      "val_loss: 0.5406959164008666\n",
      "val_precision: tensor([0.7397, 0.8403, 0.7889, 0.7528], device='cuda:0')\n",
      "val_recall: tensor([0.7290, 0.8370, 0.8120, 0.6717], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "train_loss: 0.41081244118163746\n",
      "train_precision: tensor([0.7889, 0.8653, 0.8461, 0.8259], device='cuda:0')\n",
      "train_recall: tensor([0.7858, 0.8860, 0.8326, 0.7928], device='cuda:0')\n",
      "val_loss: 0.5392143446184723\n",
      "val_precision: tensor([0.7400, 0.8354, 0.7942, 0.7614], device='cuda:0')\n",
      "val_recall: tensor([0.7315, 0.8443, 0.8049, 0.6650], device='cuda:0')\n",
      "Learning rate: 5e-06\n",
      "Early stopping at epoch 38 with best validation loss 0.5353259138400188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_name = f'resnet18 final_no_norm_no_pad_final{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "set_seed(2233)\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=4, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=num_classes, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla każdej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla każdej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie głównych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie głównych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "        \n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "set_seed(2233)\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate)\n",
    "my_model = my_model.to('cuda')\n",
    "early_stop_patience = 15\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(my_model.state_dict(), f\"{run_path}.pt\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ed3b8e-94f7-4113-a37c-486e41c4e299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[698 104 188  10]\n",
      " [ 93 864  38   5]\n",
      " [125  40 827   8]\n",
      " [ 17   6  12  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72      1000\n",
      "           1       0.85      0.86      0.86      1000\n",
      "           2       0.78      0.83      0.80      1000\n",
      "           3       0.74      0.65      0.69       100\n",
      "\n",
      "    accuracy                           0.79      3100\n",
      "   macro avg       0.78      0.76      0.77      3100\n",
      "weighted avg       0.79      0.79      0.79      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data')\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
