{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a2149a-879f-4083-8e8a-240906b0c679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madamsoja\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/adam/Desktop/cells_master_thesis/wandb/run-20240701_222156-snjvqd75</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamsoja/cells/runs/snjvqd75' target=\"_blank\">vit_after_tuning_reduced2024-07-01 22:21:55.236406</a></strong> to <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamsoja/cells' target=\"_blank\">https://wandb.ai/adamsoja/cells</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamsoja/cells/runs/snjvqd75' target=\"_blank\">https://wandb.ai/adamsoja/cells/runs/snjvqd75</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#batch_size: 279, learning_rate: 0.003483773601114058, dropout_rate: 0.2757656331185102]\n",
    "\n",
    "batch_size = 279\n",
    "learning_rate = 0.003483\n",
    "dropout_rate = 0.275765\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "from dataset import ImageDataset\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "import warnings\n",
    "import wandb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "#intecubic interpol\n",
    "\n",
    "run_name = f'vit_after_tuning_reduced{datetime.datetime.now()}'\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "wandb.init(project=\"cells\", \n",
    "           entity=\"adamsoja\",\n",
    "          name=run_name)\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(2233)\n",
    "mean = [0.5006, 0.3526, 0.5495]\n",
    "std = [0.1493, 0.1341, 0.1124]\n",
    "\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    GaussianBlur,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    ShiftScaleRotate,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=mean, std=std),\n",
    "        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=0.8)]),\n",
    "        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3),], p=0.7,),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = Compose(\n",
    "    [Normalize(mean=mean, std=std)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33520584-0b44-48d9-ade5-14c77479b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.1026889902430694\n",
      "train_precision: tensor([0.4063, 0.5570, 0.4708, 0.0234], device='cuda:0')\n",
      "train_recall: tensor([3.4846e-01, 7.5732e-01, 4.1443e-01, 5.7720e-04], device='cuda:0')\n",
      "val_loss: 0.9890052083766822\n",
      "val_precision: tensor([0.4744, 0.6140, 0.5976, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.4592, 0.8024, 0.4930, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 1.0192688527045313\n",
      "train_precision: tensor([0.4871, 0.5995, 0.5719, 0.0400], device='cuda:0')\n",
      "train_recall: tensor([4.7962e-01, 7.5743e-01, 4.8691e-01, 1.4430e-04], device='cuda:0')\n",
      "val_loss: 1.0339653992291653\n",
      "val_precision: tensor([0.4413, 0.5999, 0.6230, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.6323, 0.8084, 0.1992, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.9748528470466663\n",
      "train_precision: tensor([0.5255, 0.6247, 0.6037, 0.0588], device='cuda:0')\n",
      "train_recall: tensor([5.2092e-01, 7.5162e-01, 5.4655e-01, 1.4430e-04], device='cuda:0')\n",
      "val_loss: 0.8777752748041442\n",
      "val_precision: tensor([0.6160, 0.7314, 0.5722, 0.5269], device='cuda:0')\n",
      "val_recall: tensor([0.4514, 0.7219, 0.7866, 0.0296], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.9486112102285608\n",
      "train_precision: tensor([0.5437, 0.6379, 0.6228, 0.0833], device='cuda:0')\n",
      "train_recall: tensor([5.4453e-01, 7.4577e-01, 5.7838e-01, 5.7720e-04], device='cuda:0')\n",
      "val_loss: 0.946011990850622\n",
      "val_precision: tensor([0.5998, 0.7270, 0.5299, 0.1571], device='cuda:0')\n",
      "val_recall: tensor([0.4392, 0.6360, 0.7899, 0.0037], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.9314342515809195\n",
      "train_precision: tensor([0.5560, 0.6392, 0.6238, 0.3095], device='cuda:0')\n",
      "train_recall: tensor([0.5434, 0.7403, 0.6007, 0.0056], device='cuda:0')\n",
      "val_loss: 0.8723267771980979\n",
      "val_precision: tensor([0.6218, 0.6728, 0.6283, 0.0000], device='cuda:0')\n",
      "val_recall: tensor([0.4759, 0.8094, 0.7111, 0.0000], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.885324359481985\n",
      "train_precision: tensor([0.5732, 0.6709, 0.6413, 0.3081], device='cuda:0')\n",
      "train_recall: tensor([0.5617, 0.7591, 0.6321, 0.0088], device='cuda:0')\n",
      "val_loss: 0.8118980027509458\n",
      "val_precision: tensor([0.6314, 0.6912, 0.6603, 0.9694], device='cuda:0')\n",
      "val_recall: tensor([0.5273, 0.8256, 0.7047, 0.0320], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.87271845665845\n",
      "train_precision: tensor([0.5804, 0.6765, 0.6450, 0.4514], device='cuda:0')\n",
      "train_recall: tensor([0.5610, 0.7669, 0.6420, 0.0208], device='cuda:0')\n",
      "val_loss: 0.825042555548928\n",
      "val_precision: tensor([0.5976, 0.6955, 0.6946, 0.3325], device='cuda:0')\n",
      "val_recall: tensor([0.6034, 0.8210, 0.6122, 0.0946], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.840553662606648\n",
      "train_precision: tensor([0.5980, 0.6901, 0.6609, 0.4774], device='cuda:0')\n",
      "train_recall: tensor([0.5780, 0.7771, 0.6582, 0.0548], device='cuda:0')\n",
      "val_loss: 0.7809640592697895\n",
      "val_precision: tensor([0.6419, 0.7486, 0.6419, 0.7284], device='cuda:0')\n",
      "val_recall: tensor([0.5441, 0.7723, 0.7715, 0.1364], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.8465423076183765\n",
      "train_precision: tensor([0.5946, 0.6808, 0.6557, 0.5818], device='cuda:0')\n",
      "train_recall: tensor([0.5682, 0.7720, 0.6528, 0.0857], device='cuda:0')\n",
      "val_loss: 0.818147787361434\n",
      "val_precision: tensor([0.6000, 0.7364, 0.6452, 0.6230], device='cuda:0')\n",
      "val_recall: tensor([0.5958, 0.7176, 0.7145, 0.1552], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.8448340504200428\n",
      "train_precision: tensor([0.5925, 0.6821, 0.6589, 0.6260], device='cuda:0')\n",
      "train_recall: tensor([0.5746, 0.7682, 0.6514, 0.0971], device='cuda:0')\n",
      "val_loss: 0.7825542749780597\n",
      "val_precision: tensor([0.6280, 0.7305, 0.6731, 0.5640], device='cuda:0')\n",
      "val_recall: tensor([0.5671, 0.7795, 0.7352, 0.2121], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.8209467567406692\n",
      "train_precision: tensor([0.6047, 0.6938, 0.6682, 0.6072], device='cuda:0')\n",
      "train_recall: tensor([0.5846, 0.7772, 0.6626, 0.1287], device='cuda:0')\n",
      "val_loss: 0.7401988482836521\n",
      "val_precision: tensor([0.6285, 0.7515, 0.6944, 0.7995], device='cuda:0')\n",
      "val_recall: tensor([0.6256, 0.7972, 0.7053, 0.2242], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7990497980024908\n",
      "train_precision: tensor([0.6193, 0.7033, 0.6752, 0.6134], device='cuda:0')\n",
      "train_recall: tensor([0.5903, 0.7882, 0.6736, 0.1756], device='cuda:0')\n",
      "val_loss: 0.7879355509172786\n",
      "val_precision: tensor([0.6824, 0.7923, 0.5988, 0.7314], device='cuda:0')\n",
      "val_recall: tensor([0.5022, 0.7199, 0.8516, 0.2421], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7824788114467225\n",
      "train_precision: tensor([0.6296, 0.7098, 0.6817, 0.5950], device='cuda:0')\n",
      "train_recall: tensor([0.5977, 0.7904, 0.6826, 0.2124], device='cuda:0')\n",
      "val_loss: 0.7279673865347197\n",
      "val_precision: tensor([0.6926, 0.7281, 0.6796, 0.6466], device='cuda:0')\n",
      "val_recall: tensor([0.5226, 0.8416, 0.7723, 0.3438], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.8126920849471897\n",
      "train_precision: tensor([0.6136, 0.6925, 0.6711, 0.5888], device='cuda:0')\n",
      "train_recall: tensor([0.5862, 0.7815, 0.6633, 0.1641], device='cuda:0')\n",
      "val_loss: 0.7579219138080423\n",
      "val_precision: tensor([0.6868, 0.7602, 0.6357, 0.5267], device='cuda:0')\n",
      "val_recall: tensor([0.5127, 0.7703, 0.8121, 0.3293], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7810641658770574\n",
      "train_precision: tensor([0.6330, 0.7066, 0.6811, 0.5847], device='cuda:0')\n",
      "train_recall: tensor([0.5975, 0.7905, 0.6807, 0.2212], device='cuda:0')\n",
      "val_loss: 0.7459624588489533\n",
      "val_precision: tensor([0.7002, 0.7768, 0.6358, 0.6431], device='cuda:0')\n",
      "val_recall: tensor([0.5661, 0.7530, 0.8107, 0.3027], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7780295554693644\n",
      "train_precision: tensor([0.6371, 0.7091, 0.6851, 0.5986], device='cuda:0')\n",
      "train_recall: tensor([0.6012, 0.7924, 0.6862, 0.2225], device='cuda:0')\n",
      "val_loss: 0.7172114001982139\n",
      "val_precision: tensor([0.6618, 0.7638, 0.6956, 0.6644], device='cuda:0')\n",
      "val_recall: tensor([0.6103, 0.7924, 0.7587, 0.3293], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7602880970224157\n",
      "train_precision: tensor([0.6432, 0.7190, 0.6891, 0.6081], device='cuda:0')\n",
      "train_recall: tensor([0.6071, 0.7935, 0.6965, 0.2537], device='cuda:0')\n",
      "val_loss: 0.7538160873181892\n",
      "val_precision: tensor([0.6574, 0.7569, 0.6664, 0.5557], device='cuda:0')\n",
      "val_recall: tensor([0.5737, 0.7623, 0.7697, 0.3626], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7539183970395621\n",
      "train_precision: tensor([0.6456, 0.7211, 0.6934, 0.6066], device='cuda:0')\n",
      "train_recall: tensor([0.6123, 0.7961, 0.6964, 0.2632], device='cuda:0')\n",
      "val_loss: 0.6853082693887479\n",
      "val_precision: tensor([0.6932, 0.7647, 0.7090, 0.7101], device='cuda:0')\n",
      "val_recall: tensor([0.6226, 0.8162, 0.7726, 0.3175], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7419322547974525\n",
      "train_precision: tensor([0.6526, 0.7268, 0.7000, 0.6046], device='cuda:0')\n",
      "train_recall: tensor([0.6219, 0.8010, 0.7001, 0.2698], device='cuda:0')\n",
      "val_loss: 0.6895744328245972\n",
      "val_precision: tensor([0.6893, 0.7820, 0.6966, 0.7209], device='cuda:0')\n",
      "val_recall: tensor([0.6225, 0.7964, 0.7903, 0.3175], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.735530886789421\n",
      "train_precision: tensor([0.6551, 0.7310, 0.7015, 0.6177], device='cuda:0')\n",
      "train_recall: tensor([0.6238, 0.8025, 0.7046, 0.2821], device='cuda:0')\n",
      "val_loss: 0.679605883269599\n",
      "val_precision: tensor([0.6852, 0.8002, 0.6955, 0.6349], device='cuda:0')\n",
      "val_recall: tensor([0.6416, 0.7776, 0.7835, 0.4145], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7268215724400111\n",
      "train_precision: tensor([0.6582, 0.7366, 0.7043, 0.6156], device='cuda:0')\n",
      "train_recall: tensor([0.6286, 0.8032, 0.7087, 0.2970], device='cuda:0')\n",
      "val_loss: 0.6567021771813883\n",
      "val_precision: tensor([0.7062, 0.7552, 0.7340, 0.7234], device='cuda:0')\n",
      "val_recall: tensor([0.6242, 0.8568, 0.7564, 0.3707], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7229349041139924\n",
      "train_precision: tensor([0.6598, 0.7380, 0.7067, 0.6123], device='cuda:0')\n",
      "train_recall: tensor([0.6333, 0.8036, 0.7085, 0.2986], device='cuda:0')\n",
      "val_loss: 0.6518641265955838\n",
      "val_precision: tensor([0.7150, 0.7732, 0.7192, 0.7508], device='cuda:0')\n",
      "val_recall: tensor([0.6257, 0.8357, 0.7845, 0.4007], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7397879902418558\n",
      "train_precision: tensor([0.6521, 0.7277, 0.7041, 0.6177], device='cuda:0')\n",
      "train_recall: tensor([0.6277, 0.8009, 0.6988, 0.2746], device='cuda:0')\n",
      "val_loss: 0.6756753536787901\n",
      "val_precision: tensor([0.6866, 0.7681, 0.7218, 0.6817], device='cuda:0')\n",
      "val_recall: tensor([0.6495, 0.8133, 0.7491, 0.3909], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.729173745195587\n",
      "train_precision: tensor([0.6608, 0.7332, 0.7072, 0.6169], device='cuda:0')\n",
      "train_recall: tensor([0.6323, 0.8019, 0.7082, 0.2967], device='cuda:0')\n",
      "val_loss: 0.6421585151643464\n",
      "val_precision: tensor([0.7252, 0.7525, 0.7426, 0.7316], device='cuda:0')\n",
      "val_recall: tensor([0.6259, 0.8623, 0.7691, 0.4057], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7445236624061288\n",
      "train_precision: tensor([0.6492, 0.7268, 0.7032, 0.6250], device='cuda:0')\n",
      "train_recall: tensor([0.6253, 0.7970, 0.6995, 0.2857], device='cuda:0')\n",
      "val_loss: 0.7332003535646381\n",
      "val_precision: tensor([0.6726, 0.7875, 0.6715, 0.5705], device='cuda:0')\n",
      "val_recall: tensor([0.5852, 0.7676, 0.7918, 0.4347], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7342946937331906\n",
      "train_precision: tensor([0.6538, 0.7332, 0.7027, 0.6182], device='cuda:0')\n",
      "train_recall: tensor([0.6262, 0.8009, 0.7039, 0.2988], device='cuda:0')\n",
      "val_loss: 0.6668939553426974\n",
      "val_precision: tensor([0.7213, 0.7839, 0.6904, 0.6556], device='cuda:0')\n",
      "val_recall: tensor([0.5928, 0.8170, 0.8055, 0.4539], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7185053233976488\n",
      "train_precision: tensor([0.6603, 0.7396, 0.7079, 0.6225], device='cuda:0')\n",
      "train_recall: tensor([0.6314, 0.8039, 0.7111, 0.3255], device='cuda:0')\n",
      "val_loss: 0.6748574246059764\n",
      "val_precision: tensor([0.6224, 0.8214, 0.7582, 0.7340], device='cuda:0')\n",
      "val_recall: tensor([0.7456, 0.7562, 0.7030, 0.3966], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7320065315667685\n",
      "train_precision: tensor([0.6494, 0.7329, 0.7049, 0.6164], device='cuda:0')\n",
      "train_recall: tensor([0.6271, 0.7987, 0.7026, 0.2942], device='cuda:0')\n",
      "val_loss: 0.6550733102993531\n",
      "val_precision: tensor([0.7050, 0.7776, 0.7164, 0.7375], device='cuda:0')\n",
      "val_recall: tensor([0.6209, 0.8262, 0.7901, 0.3963], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.7080731157358591\n",
      "train_precision: tensor([0.6652, 0.7431, 0.7146, 0.6294], device='cuda:0')\n",
      "train_recall: tensor([0.6389, 0.8062, 0.7158, 0.3326], device='cuda:0')\n",
      "val_loss: 0.6918994144959884\n",
      "val_precision: tensor([0.6874, 0.8424, 0.6573, 0.6808], device='cuda:0')\n",
      "val_recall: tensor([0.6242, 0.7171, 0.8375, 0.4532], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6975517102650234\n",
      "train_precision: tensor([0.6716, 0.7497, 0.7185, 0.6328], device='cuda:0')\n",
      "train_recall: tensor([0.6474, 0.8092, 0.7199, 0.3473], device='cuda:0')\n",
      "val_loss: 0.6281683279709382\n",
      "val_precision: tensor([0.7485, 0.7615, 0.7272, 0.7205], device='cuda:0')\n",
      "val_recall: tensor([0.5957, 0.8674, 0.8003, 0.4653], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6932076937192446\n",
      "train_precision: tensor([0.6726, 0.7532, 0.7221, 0.6439], device='cuda:0')\n",
      "train_recall: tensor([0.6522, 0.8103, 0.7208, 0.3635], device='cuda:0')\n",
      "val_loss: 0.6206173381119063\n",
      "val_precision: tensor([0.6981, 0.7565, 0.7949, 0.7004], device='cuda:0')\n",
      "val_recall: tensor([0.6949, 0.8686, 0.7036, 0.4990], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6966746690211358\n",
      "train_precision: tensor([0.6722, 0.7478, 0.7207, 0.6513], device='cuda:0')\n",
      "train_recall: tensor([0.6455, 0.8111, 0.7210, 0.3550], device='cuda:0')\n",
      "val_loss: 0.6263689016753977\n",
      "val_precision: tensor([0.6738, 0.8099, 0.7600, 0.7166], device='cuda:0')\n",
      "val_recall: tensor([0.7150, 0.8107, 0.7367, 0.4912], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6878000226113703\n",
      "train_precision: tensor([0.6748, 0.7518, 0.7243, 0.6423], device='cuda:0')\n",
      "train_recall: tensor([0.6512, 0.8120, 0.7239, 0.3573], device='cuda:0')\n",
      "val_loss: 0.779093372957273\n",
      "val_precision: tensor([0.6902, 0.9005, 0.5706, 0.7175], device='cuda:0')\n",
      "val_recall: tensor([0.5281, 0.5989, 0.9221, 0.3848], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6833305872880019\n",
      "train_precision: tensor([0.6768, 0.7556, 0.7261, 0.6471], device='cuda:0')\n",
      "train_recall: tensor([0.6562, 0.8104, 0.7263, 0.3720], device='cuda:0')\n",
      "val_loss: 0.6256564131288818\n",
      "val_precision: tensor([0.7396, 0.7573, 0.7386, 0.7176], device='cuda:0')\n",
      "val_recall: tensor([0.6087, 0.8689, 0.7878, 0.4519], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6805944102151054\n",
      "train_precision: tensor([0.6799, 0.7548, 0.7267, 0.6438], device='cuda:0')\n",
      "train_recall: tensor([0.6549, 0.8148, 0.7264, 0.3719], device='cuda:0')\n",
      "val_loss: 0.6377992473768466\n",
      "val_precision: tensor([0.6999, 0.8386, 0.7067, 0.6224], device='cuda:0')\n",
      "val_recall: tensor([0.6650, 0.7657, 0.8148, 0.5222], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.676989009241005\n",
      "train_precision: tensor([0.6801, 0.7575, 0.7292, 0.6440], device='cuda:0')\n",
      "train_recall: tensor([0.6618, 0.8123, 0.7256, 0.3830], device='cuda:0')\n",
      "val_loss: 0.7450948253725515\n",
      "val_precision: tensor([0.6977, 0.8963, 0.5966, 0.7057], device='cuda:0')\n",
      "val_recall: tensor([0.6408, 0.5980, 0.8729, 0.3616], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6781023726834879\n",
      "train_precision: tensor([0.6802, 0.7571, 0.7290, 0.6505], device='cuda:0')\n",
      "train_recall: tensor([0.6583, 0.8145, 0.7266, 0.3873], device='cuda:0')\n",
      "val_loss: 0.6170457363128662\n",
      "val_precision: tensor([0.7133, 0.8014, 0.7337, 0.7786], device='cuda:0')\n",
      "val_recall: tensor([0.6658, 0.8264, 0.7930, 0.4263], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6719993803408238\n",
      "train_precision: tensor([0.6812, 0.7591, 0.7307, 0.6541], device='cuda:0')\n",
      "train_recall: tensor([0.6619, 0.8147, 0.7273, 0.3921], device='cuda:0')\n",
      "val_loss: 0.6092896649331757\n",
      "val_precision: tensor([0.7115, 0.7888, 0.7800, 0.5715], device='cuda:0')\n",
      "val_recall: tensor([0.6912, 0.8451, 0.7391, 0.6259], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6691753706374726\n",
      "train_precision: tensor([0.6855, 0.7601, 0.7344, 0.6423], device='cuda:0')\n",
      "train_recall: tensor([0.6653, 0.8160, 0.7299, 0.3983], device='cuda:0')\n",
      "val_loss: 0.6062504656387098\n",
      "val_precision: tensor([0.7046, 0.7902, 0.7724, 0.7920], device='cuda:0')\n",
      "val_recall: tensor([0.6960, 0.8485, 0.7623, 0.4077], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6681370824188381\n",
      "train_precision: tensor([0.6850, 0.7626, 0.7346, 0.6468], device='cuda:0')\n",
      "train_recall: tensor([0.6662, 0.8158, 0.7320, 0.3967], device='cuda:0')\n",
      "val_loss: 0.6405759523312251\n",
      "val_precision: tensor([0.7362, 0.7345, 0.7642, 0.7341], device='cuda:0')\n",
      "val_recall: tensor([0.6262, 0.8811, 0.7544, 0.4593], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6724810809284062\n",
      "train_precision: tensor([0.6838, 0.7585, 0.7330, 0.6450], device='cuda:0')\n",
      "train_recall: tensor([0.6628, 0.8152, 0.7298, 0.3890], device='cuda:0')\n",
      "val_loss: 0.6061575606013789\n",
      "val_precision: tensor([0.7149, 0.8151, 0.7352, 0.8032], device='cuda:0')\n",
      "val_recall: tensor([0.6755, 0.8115, 0.8153, 0.4054], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6618951967784337\n",
      "train_precision: tensor([0.6892, 0.7643, 0.7371, 0.6556], device='cuda:0')\n",
      "train_recall: tensor([0.6678, 0.8186, 0.7343, 0.4180], device='cuda:0')\n",
      "val_loss: 0.6179171028462324\n",
      "val_precision: tensor([0.6940, 0.7612, 0.8139, 0.7168], device='cuda:0')\n",
      "val_recall: tensor([0.7009, 0.8769, 0.7048, 0.5172], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6606064363733515\n",
      "train_precision: tensor([0.6878, 0.7636, 0.7386, 0.6576], device='cuda:0')\n",
      "train_recall: tensor([0.6688, 0.8184, 0.7330, 0.4176], device='cuda:0')\n",
      "val_loss: 0.6267098957842047\n",
      "val_precision: tensor([0.7550, 0.8100, 0.6820, 0.7451], device='cuda:0')\n",
      "val_recall: tensor([0.5895, 0.8153, 0.8521, 0.4724], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6565086560589927\n",
      "train_precision: tensor([0.6891, 0.7660, 0.7383, 0.6631], device='cuda:0')\n",
      "train_recall: tensor([0.6717, 0.8192, 0.7328, 0.4198], device='cuda:0')\n",
      "val_loss: 0.6605207748485334\n",
      "val_precision: tensor([0.6003, 0.9000, 0.8119, 0.5943], device='cuda:0')\n",
      "val_recall: tensor([0.8528, 0.6668, 0.6864, 0.5539], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6548038310044771\n",
      "train_precision: tensor([0.6902, 0.7649, 0.7403, 0.6629], device='cuda:0')\n",
      "train_recall: tensor([0.6713, 0.8201, 0.7343, 0.4203], device='cuda:0')\n",
      "val_loss: 0.5963901919848991\n",
      "val_precision: tensor([0.7581, 0.8102, 0.7184, 0.6557], device='cuda:0')\n",
      "val_recall: tensor([0.6327, 0.8212, 0.8336, 0.5997], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6521555774397664\n",
      "train_precision: tensor([0.6931, 0.7665, 0.7401, 0.6581], device='cuda:0')\n",
      "train_recall: tensor([0.6725, 0.8200, 0.7357, 0.4342], device='cuda:0')\n",
      "val_loss: 0.5817435754971071\n",
      "val_precision: tensor([0.6859, 0.8423, 0.7812, 0.7467], device='cuda:0')\n",
      "val_recall: tensor([0.7570, 0.7988, 0.7655, 0.5091], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6510980049511055\n",
      "train_precision: tensor([0.6935, 0.7682, 0.7419, 0.6615], device='cuda:0')\n",
      "train_recall: tensor([0.6740, 0.8210, 0.7376, 0.4303], device='cuda:0')\n",
      "val_loss: 0.6375797838424191\n",
      "val_precision: tensor([0.7758, 0.7243, 0.7559, 0.8322], device='cuda:0')\n",
      "val_recall: tensor([0.5941, 0.9088, 0.7860, 0.3306], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6485759498237016\n",
      "train_precision: tensor([0.6928, 0.7667, 0.7427, 0.6601], device='cuda:0')\n",
      "train_recall: tensor([0.6743, 0.8212, 0.7359, 0.4286], device='cuda:0')\n",
      "val_loss: 0.6029201556335796\n",
      "val_precision: tensor([0.7658, 0.8164, 0.6999, 0.8731], device='cuda:0')\n",
      "val_recall: tensor([0.6263, 0.8285, 0.8566, 0.3798], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6473942514363822\n",
      "train_precision: tensor([0.6937, 0.7689, 0.7427, 0.6536], device='cuda:0')\n",
      "train_recall: tensor([0.6761, 0.8190, 0.7388, 0.4277], device='cuda:0')\n",
      "val_loss: 0.6088624639944596\n",
      "val_precision: tensor([0.7650, 0.7761, 0.7163, 0.7599], device='cuda:0')\n",
      "val_recall: tensor([0.5892, 0.8660, 0.8258, 0.4636], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6452267954875897\n",
      "train_precision: tensor([0.6948, 0.7690, 0.7433, 0.6638], device='cuda:0')\n",
      "train_recall: tensor([0.6759, 0.8201, 0.7387, 0.4444], device='cuda:0')\n",
      "val_loss: 0.6197109723632986\n",
      "val_precision: tensor([0.8008, 0.7002, 0.7597, 0.8376], device='cuda:0')\n",
      "val_recall: tensor([0.5394, 0.9282, 0.7979, 0.4219], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6439404505026805\n",
      "train_precision: tensor([0.6955, 0.7707, 0.7434, 0.6698], device='cuda:0')\n",
      "train_recall: tensor([0.6775, 0.8210, 0.7387, 0.4478], device='cuda:0')\n",
      "val_loss: 0.582272161136974\n",
      "val_precision: tensor([0.6929, 0.8175, 0.7890, 0.7801], device='cuda:0')\n",
      "val_recall: tensor([0.7433, 0.8223, 0.7530, 0.5232], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6428125499517887\n",
      "train_precision: tensor([0.6950, 0.7710, 0.7458, 0.6624], device='cuda:0')\n",
      "train_recall: tensor([0.6799, 0.8203, 0.7387, 0.4457], device='cuda:0')\n",
      "val_loss: 0.6012554677598404\n",
      "val_precision: tensor([0.7965, 0.7424, 0.7372, 0.8480], device='cuda:0')\n",
      "val_recall: tensor([0.5726, 0.9051, 0.8207, 0.4131], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6405234062052393\n",
      "train_precision: tensor([0.6978, 0.7715, 0.7459, 0.6600], device='cuda:0')\n",
      "train_recall: tensor([0.6789, 0.8220, 0.7414, 0.4465], device='cuda:0')\n",
      "val_loss: 0.5803130887674562\n",
      "val_precision: tensor([0.7406, 0.8009, 0.7617, 0.6490], device='cuda:0')\n",
      "val_recall: tensor([0.6658, 0.8502, 0.7967, 0.6071], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6400902180702656\n",
      "train_precision: tensor([0.6968, 0.7729, 0.7471, 0.6728], device='cuda:0')\n",
      "train_recall: tensor([0.6801, 0.8228, 0.7412, 0.4517], device='cuda:0')\n",
      "val_loss: 0.654515234358383\n",
      "val_precision: tensor([0.7119, 0.8447, 0.7437, 0.7478], device='cuda:0')\n",
      "val_recall: tensor([0.7149, 0.7929, 0.8098, 0.5101], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6386610872559734\n",
      "train_precision: tensor([0.6969, 0.7717, 0.7490, 0.6698], device='cuda:0')\n",
      "train_recall: tensor([0.6802, 0.8226, 0.7413, 0.4569], device='cuda:0')\n",
      "val_loss: 0.5939714261076667\n",
      "val_precision: tensor([0.7060, 0.8202, 0.7626, 0.7937], device='cuda:0')\n",
      "val_recall: tensor([0.7119, 0.8230, 0.7868, 0.4495], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6374820821471029\n",
      "train_precision: tensor([0.6984, 0.7712, 0.7478, 0.6702], device='cuda:0')\n",
      "train_recall: tensor([0.6818, 0.8219, 0.7410, 0.4495], device='cuda:0')\n",
      "val_loss: 0.577748143582633\n",
      "val_precision: tensor([0.7049, 0.8486, 0.7569, 0.7531], device='cuda:0')\n",
      "val_recall: tensor([0.7389, 0.7911, 0.7960, 0.5114], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6365112111165926\n",
      "train_precision: tensor([0.6982, 0.7732, 0.7458, 0.6679], device='cuda:0')\n",
      "train_recall: tensor([0.6806, 0.8239, 0.7398, 0.4518], device='cuda:0')\n",
      "val_loss: 0.6588141472050638\n",
      "val_precision: tensor([0.7512, 0.8919, 0.6332, 0.6949], device='cuda:0')\n",
      "val_recall: tensor([0.6046, 0.7112, 0.9046, 0.4801], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.632931844677244\n",
      "train_precision: tensor([0.6998, 0.7742, 0.7490, 0.6691], device='cuda:0')\n",
      "train_recall: tensor([0.6820, 0.8256, 0.7426, 0.4525], device='cuda:0')\n",
      "val_loss: 1.0188354336854184\n",
      "val_precision: tensor([0.6978, 0.9841, 0.4863, 0.9685], device='cuda:0')\n",
      "val_recall: tensor([0.5656, 0.3043, 0.9515, 0.2276], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6316480273550207\n",
      "train_precision: tensor([0.6992, 0.7741, 0.7507, 0.6810], device='cuda:0')\n",
      "train_recall: tensor([0.6859, 0.8235, 0.7409, 0.4652], device='cuda:0')\n",
      "val_loss: 0.6734645694494248\n",
      "val_precision: tensor([0.7027, 0.6864, 0.8672, 0.6334], device='cuda:0')\n",
      "val_recall: tensor([0.6544, 0.9354, 0.6147, 0.6148], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6312437866415296\n",
      "train_precision: tensor([0.6990, 0.7752, 0.7493, 0.6749], device='cuda:0')\n",
      "train_recall: tensor([0.6828, 0.8257, 0.7410, 0.4665], device='cuda:0')\n",
      "val_loss: 0.6000319964054859\n",
      "val_precision: tensor([0.7982, 0.7951, 0.6910, 0.7877], device='cuda:0')\n",
      "val_recall: tensor([0.5664, 0.8479, 0.8714, 0.4960], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6303295120016321\n",
      "train_precision: tensor([0.6996, 0.7760, 0.7503, 0.6722], device='cuda:0')\n",
      "train_recall: tensor([0.6835, 0.8247, 0.7436, 0.4641], device='cuda:0')\n",
      "val_loss: 0.5964009514360716\n",
      "val_precision: tensor([0.7836, 0.7327, 0.7765, 0.6824], device='cuda:0')\n",
      "val_recall: tensor([0.6035, 0.9052, 0.7851, 0.5694], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6296327326978955\n",
      "train_precision: tensor([0.7021, 0.7747, 0.7507, 0.6807], device='cuda:0')\n",
      "train_recall: tensor([0.6836, 0.8265, 0.7435, 0.4706], device='cuda:0')\n",
      "val_loss: 0.6193960583571232\n",
      "val_precision: tensor([0.6661, 0.8812, 0.7371, 0.8077], device='cuda:0')\n",
      "val_recall: tensor([0.7504, 0.7082, 0.8244, 0.4145], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6305266319157241\n",
      "train_precision: tensor([0.7019, 0.7731, 0.7503, 0.6801], device='cuda:0')\n",
      "train_recall: tensor([0.6834, 0.8245, 0.7431, 0.4730], device='cuda:0')\n",
      "val_loss: 0.5771795938412349\n",
      "val_precision: tensor([0.6847, 0.8226, 0.8306, 0.5826], device='cuda:0')\n",
      "val_recall: tensor([0.7704, 0.8275, 0.7069, 0.6865], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6323218941301495\n",
      "train_precision: tensor([0.6992, 0.7743, 0.7489, 0.6648], device='cuda:0')\n",
      "train_recall: tensor([0.6824, 0.8233, 0.7430, 0.4567], device='cuda:0')\n",
      "val_loss: 0.6780064958514589\n",
      "val_precision: tensor([0.7067, 0.6761, 0.8896, 0.6129], device='cuda:0')\n",
      "val_recall: tensor([0.6658, 0.9357, 0.5928, 0.6599], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6258883172428453\n",
      "train_precision: tensor([0.7030, 0.7761, 0.7531, 0.6637], device='cuda:0')\n",
      "train_recall: tensor([0.6866, 0.8253, 0.7450, 0.4688], device='cuda:0')\n",
      "val_loss: 0.6005205922054522\n",
      "val_precision: tensor([0.7104, 0.8566, 0.7210, 0.8584], device='cuda:0')\n",
      "val_recall: tensor([0.7134, 0.7697, 0.8319, 0.3734], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6242085491682028\n",
      "train_precision: tensor([0.7018, 0.7746, 0.7545, 0.6745], device='cuda:0')\n",
      "train_recall: tensor([0.6859, 0.8251, 0.7446, 0.4760], device='cuda:0')\n",
      "val_loss: 0.6086409636519172\n",
      "val_precision: tensor([0.7814, 0.8323, 0.6793, 0.8432], device='cuda:0')\n",
      "val_recall: tensor([0.5914, 0.8193, 0.8867, 0.4508], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6243825071817869\n",
      "train_precision: tensor([0.7023, 0.7756, 0.7530, 0.6786], device='cuda:0')\n",
      "train_recall: tensor([0.6866, 0.8243, 0.7442, 0.4831], device='cuda:0')\n",
      "val_loss: 0.6128186518495733\n",
      "val_precision: tensor([0.7978, 0.8130, 0.6704, 0.8548], device='cuda:0')\n",
      "val_recall: tensor([0.5656, 0.8367, 0.8836, 0.3747], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6235587405693995\n",
      "train_precision: tensor([0.7046, 0.7780, 0.7528, 0.6789], device='cuda:0')\n",
      "train_recall: tensor([0.6880, 0.8256, 0.7470, 0.4753], device='cuda:0')\n",
      "val_loss: 0.6059777917283954\n",
      "val_precision: tensor([0.6991, 0.8870, 0.7264, 0.5625], device='cuda:0')\n",
      "val_recall: tensor([0.7050, 0.7275, 0.8361, 0.6771], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6238841027408452\n",
      "train_precision: tensor([0.7030, 0.7761, 0.7548, 0.6763], device='cuda:0')\n",
      "train_recall: tensor([0.6877, 0.8247, 0.7465, 0.4743], device='cuda:0')\n",
      "val_loss: 0.5704684818332846\n",
      "val_precision: tensor([0.7033, 0.8220, 0.7876, 0.7584], device='cuda:0')\n",
      "val_recall: tensor([0.7362, 0.8333, 0.7650, 0.5178], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6222863221323335\n",
      "train_precision: tensor([0.7052, 0.7797, 0.7510, 0.6729], device='cuda:0')\n",
      "train_recall: tensor([0.6868, 0.8268, 0.7469, 0.4792], device='cuda:0')\n",
      "val_loss: 0.6784380917296265\n",
      "val_precision: tensor([0.8483, 0.6606, 0.7560, 0.6741], device='cuda:0')\n",
      "val_recall: tensor([0.4523, 0.9457, 0.7934, 0.5781], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6203370280854114\n",
      "train_precision: tensor([0.7061, 0.7786, 0.7546, 0.6689], device='cuda:0')\n",
      "train_recall: tensor([0.6895, 0.8265, 0.7474, 0.4781], device='cuda:0')\n",
      "val_loss: 0.5867261716813752\n",
      "val_precision: tensor([0.7446, 0.7972, 0.7727, 0.5187], device='cuda:0')\n",
      "val_recall: tensor([0.6698, 0.8440, 0.7746, 0.7226], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6205507804046978\n",
      "train_precision: tensor([0.7055, 0.7791, 0.7541, 0.6789], device='cuda:0')\n",
      "train_recall: tensor([0.6889, 0.8279, 0.7459, 0.4879], device='cuda:0')\n",
      "val_loss: 0.6188183773647655\n",
      "val_precision: tensor([0.7852, 0.7693, 0.7821, 0.4131], device='cuda:0')\n",
      "val_recall: tensor([0.6067, 0.8864, 0.7667, 0.8047], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6187037516336936\n",
      "train_precision: tensor([0.7053, 0.7803, 0.7549, 0.6828], device='cuda:0')\n",
      "train_recall: tensor([0.6892, 0.8268, 0.7482, 0.4935], device='cuda:0')\n",
      "val_loss: 0.6022183054775903\n",
      "val_precision: tensor([0.8302, 0.7428, 0.7336, 0.6683], device='cuda:0')\n",
      "val_recall: tensor([0.5290, 0.9060, 0.8432, 0.6263], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6178271453876\n",
      "train_precision: tensor([0.7068, 0.7791, 0.7561, 0.6872], device='cuda:0')\n",
      "train_recall: tensor([0.6914, 0.8276, 0.7477, 0.4837], device='cuda:0')\n",
      "val_loss: 0.5790395789074175\n",
      "val_precision: tensor([0.7470, 0.8048, 0.7399, 0.8213], device='cuda:0')\n",
      "val_recall: tensor([0.6462, 0.8468, 0.8321, 0.4768], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6160685562468194\n",
      "train_precision: tensor([0.7069, 0.7788, 0.7568, 0.6787], device='cuda:0')\n",
      "train_recall: tensor([0.6895, 0.8279, 0.7491, 0.4870], device='cuda:0')\n",
      "val_loss: 0.6297601028825297\n",
      "val_precision: tensor([0.6946, 0.9059, 0.6880, 0.7836], device='cuda:0')\n",
      "val_recall: tensor([0.7184, 0.6846, 0.8616, 0.4512], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.614687224409797\n",
      "train_precision: tensor([0.7087, 0.7804, 0.7567, 0.6771], device='cuda:0')\n",
      "train_recall: tensor([0.6902, 0.8274, 0.7518, 0.4902], device='cuda:0')\n",
      "val_loss: 0.6353659583312092\n",
      "val_precision: tensor([0.8099, 0.7854, 0.6859, 0.9180], device='cuda:0')\n",
      "val_recall: tensor([0.5622, 0.8663, 0.8727, 0.2788], device='cuda:0')\n",
      "Learning rate: 0.003483\n",
      "train_loss: 0.6145497458321708\n",
      "train_precision: tensor([0.7088, 0.7819, 0.7574, 0.6880], device='cuda:0')\n",
      "train_recall: tensor([0.6927, 0.8296, 0.7496, 0.4964], device='cuda:0')\n",
      "val_loss: 0.5787445458498868\n",
      "val_precision: tensor([0.7406, 0.7508, 0.8157, 0.6922], device='cuda:0')\n",
      "val_recall: tensor([0.6751, 0.9048, 0.7286, 0.6232], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5817935979985571\n",
      "train_precision: tensor([0.7248, 0.7923, 0.7707, 0.7133], device='cuda:0')\n",
      "train_recall: tensor([0.7081, 0.8356, 0.7648, 0.5431], device='cuda:0')\n",
      "val_loss: 0.5262558872952606\n",
      "val_precision: tensor([0.7648, 0.8171, 0.7925, 0.7096], device='cuda:0')\n",
      "val_recall: tensor([0.7127, 0.8626, 0.8074, 0.6646], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5715908124849394\n",
      "train_precision: tensor([0.7290, 0.7973, 0.7746, 0.7162], device='cuda:0')\n",
      "train_recall: tensor([0.7120, 0.8385, 0.7691, 0.5658], device='cuda:0')\n",
      "val_loss: 0.5259306131890326\n",
      "val_precision: tensor([0.7448, 0.8322, 0.7989, 0.7450], device='cuda:0')\n",
      "val_recall: tensor([0.7406, 0.8481, 0.8004, 0.6316], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5673387389291417\n",
      "train_precision: tensor([0.7295, 0.7985, 0.7742, 0.7282], device='cuda:0')\n",
      "train_recall: tensor([0.7147, 0.8384, 0.7680, 0.5707], device='cuda:0')\n",
      "val_loss: 0.5196544066523061\n",
      "val_precision: tensor([0.7749, 0.8211, 0.7769, 0.7296], device='cuda:0')\n",
      "val_recall: tensor([0.6934, 0.8629, 0.8278, 0.6468], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5645995700127119\n",
      "train_precision: tensor([0.7319, 0.7994, 0.7781, 0.7297], device='cuda:0')\n",
      "train_recall: tensor([0.7166, 0.8392, 0.7714, 0.5801], device='cuda:0')\n",
      "val_loss: 0.5248482207457225\n",
      "val_precision: tensor([0.7638, 0.8321, 0.7791, 0.7511], device='cuda:0')\n",
      "val_recall: tensor([0.7111, 0.8500, 0.8279, 0.6370], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5615091900933873\n",
      "train_precision: tensor([0.7320, 0.8009, 0.7787, 0.7316], device='cuda:0')\n",
      "train_recall: tensor([0.7188, 0.8389, 0.7713, 0.5853], device='cuda:0')\n",
      "val_loss: 0.5154553106336882\n",
      "val_precision: tensor([0.7466, 0.8327, 0.8046, 0.7406], device='cuda:0')\n",
      "val_recall: tensor([0.7453, 0.8501, 0.7993, 0.6478], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5611384069764769\n",
      "train_precision: tensor([0.7321, 0.8003, 0.7792, 0.7230], device='cuda:0')\n",
      "train_recall: tensor([0.7181, 0.8399, 0.7702, 0.5869], device='cuda:0')\n",
      "val_loss: 0.5236468398209774\n",
      "val_precision: tensor([0.7530, 0.8329, 0.7966, 0.7354], device='cuda:0')\n",
      "val_recall: tensor([0.7339, 0.8481, 0.8107, 0.6569], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5581543690585471\n",
      "train_precision: tensor([0.7348, 0.8011, 0.7805, 0.7399], device='cuda:0')\n",
      "train_recall: tensor([0.7192, 0.8417, 0.7724, 0.5990], device='cuda:0')\n",
      "val_loss: 0.5212534320173842\n",
      "val_precision: tensor([0.7594, 0.8427, 0.7752, 0.7476], device='cuda:0')\n",
      "val_recall: tensor([0.7200, 0.8392, 0.8310, 0.6293], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5562776021369091\n",
      "train_precision: tensor([0.7359, 0.8017, 0.7814, 0.7237], device='cuda:0')\n",
      "train_recall: tensor([0.7199, 0.8420, 0.7735, 0.5899], device='cuda:0')\n",
      "val_loss: 0.5131401760108543\n",
      "val_precision: tensor([0.7677, 0.8210, 0.7968, 0.7216], device='cuda:0')\n",
      "val_recall: tensor([0.7185, 0.8661, 0.8102, 0.6667], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5573650309791812\n",
      "train_precision: tensor([0.7342, 0.8008, 0.7814, 0.7286], device='cuda:0')\n",
      "train_recall: tensor([0.7185, 0.8427, 0.7716, 0.5944], device='cuda:0')\n",
      "val_loss: 0.5137018727533745\n",
      "val_precision: tensor([0.7542, 0.8467, 0.7847, 0.7253], device='cuda:0')\n",
      "val_recall: tensor([0.7345, 0.8349, 0.8214, 0.6758], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5549535906934119\n",
      "train_precision: tensor([0.7370, 0.8017, 0.7822, 0.7250], device='cuda:0')\n",
      "train_recall: tensor([0.7201, 0.8423, 0.7743, 0.5984], device='cuda:0')\n",
      "val_loss: 0.5143426364118403\n",
      "val_precision: tensor([0.7517, 0.8416, 0.7944, 0.7096], device='cuda:0')\n",
      "val_recall: tensor([0.7391, 0.8402, 0.8121, 0.6838], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5548131074611242\n",
      "train_precision: tensor([0.7361, 0.8022, 0.7816, 0.7302], device='cuda:0')\n",
      "train_recall: tensor([0.7211, 0.8422, 0.7730, 0.5957], device='cuda:0')\n",
      "val_loss: 0.515014236984831\n",
      "val_precision: tensor([0.7762, 0.8222, 0.7800, 0.7406], device='cuda:0')\n",
      "val_recall: tensor([0.6956, 0.8654, 0.8289, 0.6576], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5524574835192073\n",
      "train_precision: tensor([0.7373, 0.8027, 0.7822, 0.7396], device='cuda:0')\n",
      "train_recall: tensor([0.7224, 0.8428, 0.7734, 0.6032], device='cuda:0')\n",
      "val_loss: 0.5163299580415089\n",
      "val_precision: tensor([0.7457, 0.8523, 0.7806, 0.7599], device='cuda:0')\n",
      "val_recall: tensor([0.7389, 0.8264, 0.8252, 0.6256], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5518398547327363\n",
      "train_precision: tensor([0.7381, 0.8020, 0.7829, 0.7351], device='cuda:0')\n",
      "train_recall: tensor([0.7213, 0.8419, 0.7759, 0.6030], device='cuda:0')\n",
      "val_loss: 0.5182454446048448\n",
      "val_precision: tensor([0.7359, 0.8588, 0.7858, 0.7710], device='cuda:0')\n",
      "val_recall: tensor([0.7543, 0.8186, 0.8187, 0.6168], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5515528205927316\n",
      "train_precision: tensor([0.7371, 0.8028, 0.7818, 0.7333], device='cuda:0')\n",
      "train_recall: tensor([0.7204, 0.8438, 0.7742, 0.5974], device='cuda:0')\n",
      "val_loss: 0.5157601731293129\n",
      "val_precision: tensor([0.7791, 0.7958, 0.8112, 0.7244], device='cuda:0')\n",
      "val_recall: tensor([0.7023, 0.8921, 0.7978, 0.6815], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5504518405183569\n",
      "train_precision: tensor([0.7382, 0.8041, 0.7826, 0.7407], device='cuda:0')\n",
      "train_recall: tensor([0.7225, 0.8430, 0.7748, 0.6124], device='cuda:0')\n",
      "val_loss: 0.5112883384480621\n",
      "val_precision: tensor([0.7514, 0.8434, 0.7934, 0.7517], device='cuda:0')\n",
      "val_recall: tensor([0.7407, 0.8409, 0.8176, 0.6515], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5502415975967011\n",
      "train_precision: tensor([0.7382, 0.8029, 0.7833, 0.7252], device='cuda:0')\n",
      "train_recall: tensor([0.7234, 0.8417, 0.7740, 0.6063], device='cuda:0')\n",
      "val_loss: 0.5124945132118283\n",
      "val_precision: tensor([0.7608, 0.8222, 0.8050, 0.7334], device='cuda:0')\n",
      "val_recall: tensor([0.7288, 0.8664, 0.8034, 0.6633], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5502354697360621\n",
      "train_precision: tensor([0.7382, 0.8028, 0.7838, 0.7350], device='cuda:0')\n",
      "train_recall: tensor([0.7239, 0.8439, 0.7732, 0.6010], device='cuda:0')\n",
      "val_loss: 0.5125657709258975\n",
      "val_precision: tensor([0.7652, 0.8307, 0.7902, 0.7440], device='cuda:0')\n",
      "val_recall: tensor([0.7202, 0.8572, 0.8205, 0.6606], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5483423485384359\n",
      "train_precision: tensor([0.7395, 0.8048, 0.7826, 0.7409], device='cuda:0')\n",
      "train_recall: tensor([0.7225, 0.8426, 0.7776, 0.6105], device='cuda:0')\n",
      "val_loss: 0.5091797710368128\n",
      "val_precision: tensor([0.7633, 0.8345, 0.7930, 0.7199], device='cuda:0')\n",
      "val_recall: tensor([0.7262, 0.8526, 0.8176, 0.6906], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5477856337250053\n",
      "train_precision: tensor([0.7393, 0.8046, 0.7857, 0.7358], device='cuda:0')\n",
      "train_recall: tensor([0.7253, 0.8450, 0.7748, 0.6076], device='cuda:0')\n",
      "val_loss: 0.5137991346644633\n",
      "val_precision: tensor([0.7745, 0.8005, 0.8138, 0.7146], device='cuda:0')\n",
      "val_recall: tensor([0.7097, 0.8864, 0.7972, 0.6923], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5482499877353767\n",
      "train_precision: tensor([0.7385, 0.8032, 0.7871, 0.7377], device='cuda:0')\n",
      "train_recall: tensor([0.7250, 0.8434, 0.7757, 0.6088], device='cuda:0')\n",
      "val_loss: 0.5208053659309041\n",
      "val_precision: tensor([0.7377, 0.8698, 0.7736, 0.7779], device='cuda:0')\n",
      "val_recall: tensor([0.7545, 0.8047, 0.8322, 0.5943], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5448960661888123\n",
      "train_precision: tensor([0.7395, 0.8047, 0.7852, 0.7415], device='cuda:0')\n",
      "train_recall: tensor([0.7237, 0.8438, 0.7771, 0.6169], device='cuda:0')\n",
      "val_loss: 0.516550705649636\n",
      "val_precision: tensor([0.7372, 0.8604, 0.7859, 0.7668], device='cuda:0')\n",
      "val_recall: tensor([0.7528, 0.8168, 0.8245, 0.6165], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.545726784870222\n",
      "train_precision: tensor([0.7396, 0.8047, 0.7858, 0.7305], device='cuda:0')\n",
      "train_recall: tensor([0.7238, 0.8444, 0.7762, 0.6137], device='cuda:0')\n",
      "val_loss: 0.5149556076887882\n",
      "val_precision: tensor([0.7512, 0.8479, 0.7884, 0.7612], device='cuda:0')\n",
      "val_recall: tensor([0.7419, 0.8354, 0.8226, 0.6374], device='cuda:0')\n",
      "Learning rate: 0.0003483\n",
      "train_loss: 0.5458891140176104\n",
      "train_precision: tensor([0.7416, 0.8047, 0.7840, 0.7405], device='cuda:0')\n",
      "train_recall: tensor([0.7246, 0.8444, 0.7766, 0.6147], device='cuda:0')\n",
      "val_loss: 0.5102876103285587\n",
      "val_precision: tensor([0.7579, 0.8350, 0.8015, 0.7080], device='cuda:0')\n",
      "val_recall: tensor([0.7358, 0.8536, 0.8079, 0.6997], device='cuda:0')\n",
      "Learning rate: 0.0003483\n"
     ]
    }
   ],
   "source": [
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.base_model = models.efficientnet_b0(pretrained=False)\n",
    "        num_ftrs = self.base_model.classifier[1].in_features\n",
    "        self.base_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "        \n",
    "trainset = ImageDataset(data_path='train_data', transform=transform, reduce=False)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "testset = ImageDataset(data_path='validation_data', transform=transform_test, reduce=False)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "model = EfficientNetB0()\n",
    "model = model.to('cuda')\n",
    "num_classes = 4\n",
    "# Custom model class\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.metric_precision = Precision(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.metric_recall = Recall(task=\"multiclass\", num_classes=4, average=None).to('cuda')\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        self.precision_per_epochs = []\n",
    "        self.recall_per_epochs = []\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode=\"min\", factor=0.1, patience=7, min_lr=5e-6, verbose=True)\n",
    "        self.step = 0\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train_one_epoch(self, trainloader):\n",
    "        self.step += 1\n",
    "        self.train()\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            self.metric_precision(preds, labels)\n",
    "            self.metric_recall(preds, labels)\n",
    "            self.train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        avg_loss = np.mean(self.train_loss)\n",
    "        self.train_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        self.precision_per_epochs.append(precision)\n",
    "        self.recall_per_epochs.append(recall)\n",
    "        print(f'train_loss: {avg_loss}')\n",
    "        print(f'train_precision: {precision}')\n",
    "        print(f'train_recall: {recall}')\n",
    "\n",
    "        wandb.log({'loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        # Logowanie precision dla kadej klasy\n",
    "        wandb.log({'Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        # Logowanie recall dla kadej klasy\n",
    "        wandb.log({'Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        # Obliczanie gwnych metryk\n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        # Logowanie gwnych metryk\n",
    "        wandb.log({'main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def evaluate(self, testloader):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(testloader):\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                _, labels = torch.max(labels, 1)\n",
    "                self.metric_precision(preds, labels)\n",
    "                self.metric_recall(preds, labels)\n",
    "                self.valid_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = np.mean(self.valid_loss)\n",
    "        self.scheduler.step(avg_loss)\n",
    "        self.valid_loss.clear()\n",
    "        precision = self.metric_precision.compute()\n",
    "        recall = self.metric_recall.compute()\n",
    "        print(f'val_loss: {avg_loss}')\n",
    "        print(f'val_precision: {precision}')\n",
    "        print(f'val_recall: {recall}')\n",
    "        self.metric_precision.reset()\n",
    "        self.metric_recall.reset()\n",
    "    \n",
    "        main_metrics_precision = (precision[0].item() + precision[1].item() + precision[2].item() + precision[3].item()) / 4\n",
    "        \n",
    "        main_metrics_recall = (recall[0].item() + recall[1].item() + recall[2].item() + recall[3].item()) / 4\n",
    "        \n",
    "        wandb.log({'val_loss': avg_loss}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal precision': precision[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory precision': precision[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor precision': precision[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other precision': precision[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_Normal recall': recall[0].item()}, step=self.step)\n",
    "        wandb.log({'val_Inflamatory recall': recall[1].item()}, step=self.step)\n",
    "        wandb.log({'val_Tumor recall': recall[2].item()}, step=self.step)\n",
    "        wandb.log({'val_Other recall': recall[3].item()}, step=self.step)\n",
    "        \n",
    "        wandb.log({'val_main_metrics_precision': main_metrics_precision}, step=self.step)\n",
    "        wandb.log({'val_main_metrics_recall': main_metrics_recall}, step=self.step)\n",
    "\n",
    "        precision_ = main_metrics_precision\n",
    "        recall_ = main_metrics_recall\n",
    "        \n",
    "        if (precision_ + recall_) > 0:\n",
    "            f1_score_val = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
    "        else:\n",
    "            f1_score_val = 0\n",
    "        \n",
    "        wandb.log({'f1_score_val': f1_score_val}, step=self.step)\n",
    "        \n",
    "        \n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            print(f\"Learning rate: {param_group['lr']}\")\n",
    "        return avg_loss\n",
    "\n",
    "my_model = MyModel(model=model, learning_rate=learning_rate)\n",
    "my_model = my_model.to('cuda')\n",
    "early_stop_patience = 15\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    my_model.train_one_epoch(trainloader)\n",
    "    val_loss = my_model.evaluate(testloader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} with best validation loss {best_val_loss}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a83fe3-cf98-44df-8284-b17540f6fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "my_model.load_state_dict(torch.load(f'{run_path}.pth'))\n",
    "\n",
    "def test_report(model, dataloader):\n",
    "    \"\"\"Prints confusion matrix for testing dataset\n",
    "    dataloader should be of batch_size=1.\"\"\"\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            output = model(data)\n",
    "            label = label.numpy()\n",
    "            output = output.numpy()\n",
    "            y_pred.append(np.argmax(output))\n",
    "            y_test.append(np.argmax(label))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "testset =ImageDataset(data_path='test_data', transform=transform_test, reduce=True)\n",
    "dataloader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_report(my_model.to('cpu'), dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "824d05e6-4cbe-4e78-9558-84fedd0341fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "        if reduce:\n",
    "            self.__remove_small_images()\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        files = os.listdir(path)\n",
    "        dataset_final = pd.DataFrame(columns=['filename', 'class', 'source'])\n",
    "        for filename in files:\n",
    "            if filename.endswith('.txt'):\n",
    "                dataset = pd.DataFrame()\n",
    "                files_list = get_images_list(f'{path}/{filename}')\n",
    "                dataset['filename'] = files_list\n",
    "                dataset['class'] = filename.split('_')[1][:-3]\n",
    "                sources = []\n",
    "                for file in files_list:\n",
    "                    if 'monusac' in file.lower():\n",
    "                        sources.append('monusac')\n",
    "                    elif 'pannuke' in file.lower():\n",
    "                        sources.append('pannuke')\n",
    "                    elif 'nucls' in file.lower():\n",
    "                        sources.append('nucls')\n",
    "                    else:\n",
    "                        sources.append('unknown')\n",
    "                dataset['source'] = sources\n",
    "                dataset_final = pd.concat([dataset_final, dataset], ignore_index=True)\n",
    "        print(dataset_final.head())  # Debug print to check the DataFrame\n",
    "        return dataset_final                \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __remove_small_images(self):\n",
    "        for i in range(len(self.dataset)-1):\n",
    "            image = cv2.imread(f'{self.dataset[\"filename\"].loc[i]}')\n",
    "            if image.shape[0] < 12 or image.shape[1] < 12:\n",
    "                self.dataset = self.dataset.drop(i)\n",
    "        self.dataset = self.dataset.reset_index()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"filename\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = self.transform(image=image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset[\"class\"].loc[idx]\n",
    "\n",
    "        if target == 'normal.':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target == 'inflamatory.':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target == 'tumor.':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target == 'other.':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))\n",
    "\n",
    "\n",
    "\n",
    "def create_datasets(data_path, transform, reduce=True):\n",
    "    dataset = ImageDataset(data_path=data_path, transform=transform, reduce=reduce)\n",
    "    sources = dataset.dataset['source'].unique()\n",
    "    dataloaders = {}\n",
    "    for source in sources:\n",
    "        source_dataset = dataset.dataset[dataset.dataset['source'] == source].reset_index(drop=True)\n",
    "        source_dataset = DatasetWrapper(source_dataset, transform=transform)\n",
    "        dataloaders[source] = DataLoader(source_dataset, batch_size=1, shuffle=True)\n",
    "    return dataloaders\n",
    "\n",
    "class DatasetWrapper(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"filename\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = self.transform(image=image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset[\"class\"].loc[idx]\n",
    "\n",
    "        if target == 'normal.':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target == 'inflamatory.':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target == 'tumor.':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target == 'other.':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ed4b0a-027d-49b9-a572-85978b2a4a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename         class   source\n",
      "0  cells_final/inflammatory/aug_29993_PanNuke_inf...  inflamatory.  pannuke\n",
      "1  cells_final/inflammatory/PanNuke_inflamatory_i...  inflamatory.  pannuke\n",
      "2  cells_final/inflammatory/aug_4528_PanNuke_infl...  inflamatory.  pannuke\n",
      "3  cells_final/inflammatory/PanNuke_inflamatory_i...  inflamatory.  pannuke\n",
      "4  cells_final/inflammatory/PanNuke_inflamatory_i...  inflamatory.  pannuke\n",
      "Confusion Matrix for pannuke:\n",
      "[[729  96 164  11]\n",
      " [ 73 390  29   8]\n",
      " [124  43 817  11]\n",
      " [  6   7   5  43]]\n",
      "Classification Report for pannuke:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75      1000\n",
      "           1       0.73      0.78      0.75       500\n",
      "           2       0.80      0.82      0.81       995\n",
      "           3       0.59      0.70      0.64        61\n",
      "\n",
      "    accuracy                           0.77      2556\n",
      "   macro avg       0.73      0.76      0.74      2556\n",
      "weighted avg       0.78      0.77      0.77      2556\n",
      "\n",
      "Confusion Matrix for monusac:\n",
      "[[  0   0   0   0]\n",
      " [ 10 475  14   1]\n",
      " [  0   0   0   0]\n",
      " [  0   2   0  22]]\n",
      "Classification Report for monusac:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.95      0.97       500\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.95       524\n",
      "   macro avg       0.49      0.47      0.48       524\n",
      "weighted avg       0.99      0.95      0.97       524\n",
      "\n",
      "Confusion Matrix for nucls:\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 0 4 0]\n",
      " [4 1 2 8]]\n",
      "Classification Report for nucls:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.67      0.80      0.73         5\n",
      "           3       1.00      0.53      0.70        15\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.42      0.33      0.36        20\n",
      "weighted avg       0.92      0.60      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "def test_report(model, dataloaders):\n",
    "    \"\"\"Prints confusion matrix and classification report for testing datasets per source.\"\"\"\n",
    "    for source, dataloader in dataloaders.items():\n",
    "        y_pred = []\n",
    "        y_test = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, label in dataloader:\n",
    "                output = model(data)\n",
    "                label = label.numpy()\n",
    "                output = output.numpy()\n",
    "                y_pred.append(np.argmax(output))\n",
    "                y_test.append(np.argmax(label))\n",
    "        print(f'Confusion Matrix for {source}:')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(f'Classification Report for {source}:')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example usage:\n",
    "test_dataloaders = create_datasets(data_path='test_data', transform=transform_test, reduce=False)\n",
    "test_report(my_model.to('cpu'), test_dataloaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6964b6d-6954-4e47-85e6-8e3c8bbcdf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename         class   source\n",
      "0  cells_final/inflammatory/aug_29993_PanNuke_inf...  inflamatory.  pannuke\n",
      "1  cells_final/inflammatory/PanNuke_inflamatory_i...  inflamatory.  pannuke\n",
      "2  cells_final/inflammatory/aug_4528_PanNuke_infl...  inflamatory.  pannuke\n",
      "3  cells_final/inflammatory/PanNuke_inflamatory_i...  inflamatory.  pannuke\n",
      "4  cells_final/inflammatory/PanNuke_inflamatory_i...  inflamatory.  pannuke\n",
      "Confusion Matrix for pannuke:\n",
      "[[612  85 141   7]\n",
      " [ 64 318  22   4]\n",
      " [104  35 758   6]\n",
      " [  2   2   4  11]]\n",
      "Classification Report for pannuke:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75       845\n",
      "           1       0.72      0.78      0.75       408\n",
      "           2       0.82      0.84      0.83       903\n",
      "           3       0.39      0.58      0.47        19\n",
      "\n",
      "    accuracy                           0.78      2175\n",
      "   macro avg       0.68      0.73      0.70      2175\n",
      "weighted avg       0.78      0.78      0.78      2175\n",
      "\n",
      "Confusion Matrix for monusac:\n",
      "[[  0   0   0   0]\n",
      " [ 10 456  14   1]\n",
      " [  0   0   0   0]\n",
      " [  0   2   0  22]]\n",
      "Classification Report for monusac:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.95      0.97       481\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.95       505\n",
      "   macro avg       0.49      0.47      0.48       505\n",
      "weighted avg       0.99      0.95      0.97       505\n",
      "\n",
      "Confusion Matrix for nucls:\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 0 4 0]\n",
      " [4 1 2 8]]\n",
      "Classification Report for nucls:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.67      0.80      0.73         5\n",
      "           3       1.00      0.53      0.70        15\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.42      0.33      0.36        20\n",
      "weighted avg       0.92      0.60      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "def test_report(model, dataloaders):\n",
    "    \"\"\"Prints confusion matrix and classification report for testing datasets per source.\"\"\"\n",
    "    for source, dataloader in dataloaders.items():\n",
    "        y_pred = []\n",
    "        y_test = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, label in dataloader:\n",
    "                output = model(data)\n",
    "                label = label.numpy()\n",
    "                output = output.numpy()\n",
    "                y_pred.append(np.argmax(output))\n",
    "                y_test.append(np.argmax(label))\n",
    "        print(f'Confusion Matrix for {source}:')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(f'Classification Report for {source}:')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example usage:\n",
    "test_dataloaders = create_datasets(data_path='test_data', transform=transform_test, reduce=True)\n",
    "test_report(my_model.to('cpu'), test_dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da244a4-cfd7-4424-9bb0-cf686ad027b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
