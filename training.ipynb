{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import ImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from model import  CNN_model\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils_cells import calculate_precision_recall_per_class, get_accuracies_per_class\n",
    "import sys\n",
    "from vit import VisionTransformer\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = VisionTransformer(image_size=32, in_channels=4, num_classes=4, hidden_dims=[16, 16])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = ImageDataset(data_path='train_data')\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                         shuffle=True, num_workers=5)\n",
    "\n",
    "\n",
    "testset =ImageDataset(data_path='validation_data')\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=5)\n",
    "\n",
    "model = model.to('cuda:0')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "recalls = []\n",
    "val_recalls = []\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "\n",
    "def multiclass_accuracy_per_class(outputs, labels, num_classes):\n",
    "    \"\"\"\n",
    "    Calculate per-class accuracy for a multiclass classification problem.\n",
    "\n",
    "    Args:\n",
    "    - predictions (torch.Tensor): Model predictions (logits).\n",
    "    - labels (torch.Tensor): Ground truth labels.\n",
    "    - num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "    - per_class_accuracy (list): List of per-class accuracies.\n",
    "    \"\"\"\n",
    "    outputs = outputs.data.cpu().numpy().argmax(axis=1)\n",
    "    labels = labels.data.cpu().numpy().argmax(axis=1)\n",
    "\n",
    "    confusion = confusion_matrix(labels, outputs)\n",
    "    per_class_accuracy = confusion.diagonal() / confusion.sum(axis=1)\n",
    "    return per_class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/envs/torch_cuda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/envs/torch_cuda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/envs/torch_cuda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/envs/torch_cuda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/envs/torch_cuda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_7444/229173756.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  per_class_accuracy = confusion.diagonal() / confusion.sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7647058823529411, 0.7037037037037037, nan, 0.75]\n",
      "[1.6737967914438503, 1.1679894179894181, nan]\n",
      "[2.4998837479655895, 1.7870370370370372, nan]\n",
      "[3.2035874516692933, 2.523879142300195, nan]\n",
      "[4.053587451669293, 3.2038791423001953, nan]\n",
      "[4.664698562780405, 3.912212475633529, nan]\n",
      "[5.3919712900531325, 4.787212475633529, nan]\n",
      "[6.044145203096611, 5.576686159844056, nan]\n",
      "[6.826753898748785, 6.2130497962076925, nan]\n",
      "[7.660087232082118, 6.832097415255312, nan]\n",
      "[8.500087232082118, 7.432097415255312, nan]\n",
      "[9.369652449473422, 8.074954558112454, nan]\n",
      "[10.202985782806756, 8.759165084428243, nan]\n",
      "[11.131557211378185, 9.304619629882788, nan]\n",
      "[12.031557211378185, 9.929619629882788, nan]\n",
      "[12.81416590703036, 10.694325512235729, nan]\n",
      "[13.56416590703036, 11.348171666081882, nan]\n",
      "[14.468927811792264, 11.877583430787764, nan]\n",
      "[15.37368971655417, 12.43313898634332, nan]\n",
      "[16.016546859411314, 13.03313898634332, nan]\n",
      "[16.891546859411314, 13.574805653009985, nan]\n",
      "[17.786283701516577, 14.003377081581414, nan]\n",
      "[18.374518995634226, 14.717662795867128, nan]\n",
      "[19.08880470991994, 15.30857188677622, nan]\n",
      "[19.699915821031052, 15.94015083414464, nan]\n",
      "[20.533249154364384, 16.679281268927248, nan]\n",
      "[21.311026932142163, 17.140819730465708, nan]\n",
      "[22.04786903740532, 17.930293414676235, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7444/229173756.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  per_class_accuracy = confusion.diagonal() / confusion.sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.69786903740532, 18.521202505585325, nan]\n",
      "[23.38207956372111, 19.229535838918657, nan]\n",
      "[24.34207956372111, 19.91374636523445, nan]\n",
      "[25.114806836448384, 20.478963756538796, nan]\n",
      "[26.01956874121029, 21.248194525769566, nan]\n",
      "[26.845655697732028, 21.900368438813043, nan]\n",
      "[27.66047051254684, 22.712868438813043, nan]\n",
      "[28.478652330728657, 23.331916057860663, nan]\n",
      "[29.261261026380833, 24.031916057860663, nan]\n",
      "[30.181261026380835, 24.76875816312382, nan]\n",
      "[31.02741487253468, 25.340186734552393, nan]\n",
      "[31.92741487253468, 25.89191087248343, nan]\n",
      "[32.87478329358731, 26.35344933402189, nan]\n",
      "[33.724783293587315, 27.090291439285046, nan]\n",
      "[34.619520135692575, 27.715291439285046, nan]\n",
      "[35.381424897597334, 28.15973588372949, nan]\n",
      "[36.048091564264, 28.65973588372949, nan]\n",
      "[36.890196827421896, 29.114281338274942, nan]\n",
      "[37.8401968274219, 29.638090862084468, nan]\n",
      "[38.554482541707614, 30.25713848113209, nan]\n",
      "[39.31638730361237, 30.85713848113209, nan]\n",
      "[40.08911457633965, 31.44804757204118, nan]\n",
      "[40.95275093997601, 31.921731782567495, nan]\n",
      "[41.61941760664268, 32.60354996438568, nan]\n",
      "[42.42894141616649, 33.436883297719014, nan]\n",
      "[43.292577779802855, 34.21466107549679, nan]\n",
      "[44.16214299719416, 34.83370869454441, nan]\n",
      "[45.03714299719416, 35.58370869454441, nan]\n",
      "[45.91214299719416, 36.26552687636259, nan]\n",
      "[46.80687983929942, 37.02743163826735, nan]\n",
      "[47.65687983929942, 37.636127290441266, nan]\n",
      "[48.33687983929942, 38.35834951266349, nan]\n",
      "[49.10158572165236, 39.042560038979275, nan]\n",
      "[49.85158572165236, 39.542560038979275, nan]\n",
      "[50.76067663074327, 40.08422670564594, nan]\n",
      "[51.60278189390117, 40.78422670564594, nan]\n",
      "[52.341912328683776, 41.38422670564594, nan]\n",
      "[53.151436138207586, 42.207756117410646, nan]\n",
      "[54.082470620966205, 42.985533895188425, nan]\n",
      "[54.95203583835751, 43.54108945074398, nan]\n",
      "[55.88953583835751, 44.19326336378746, nan]\n",
      "[56.603821552643225, 44.717072887596984, nan]\n",
      "[57.47338677003453, 45.357072887596985, nan]\n",
      "[58.3400534367012, 45.87707288759699, nan]\n",
      "[59.22894232559008, 46.65968158324916, nan]\n",
      "[59.95621505286281, 47.30968158324916, nan]\n",
      "[60.813357910005664, 47.96352773709531, nan]\n",
      "[61.46335791000566, 48.83852773709531, nan]\n",
      "[62.04230527842672, 49.57926847783605, nan]\n",
      "[62.820083056204496, 50.24593514450272, nan]\n",
      "[63.52596540914567, 50.895935144502715, nan]\n",
      "[64.13310826628853, 51.50704625561383, nan]\n",
      "[64.74421937739965, 52.15704625561383, nan]\n",
      "[65.52199715517742, 52.74325315216555, nan]\n",
      "[66.34017897335923, 53.46547537438777, nan]\n",
      "[67.16626592988096, 54.08452299343539, nan]\n",
      "[67.91626592988096, 54.73669690647887, nan]\n",
      "[68.61191810379401, 55.47353901174203, nan]\n",
      "[69.41191810379401, 56.09853901174203, nan]\n",
      "[70.29427104497047, 56.58002049322351, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7444/229173756.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  per_class_accuracy = confusion.diagonal() / confusion.sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71.07687974062264, 57.26752049322351, nan]\n",
      "[71.9435464072893, 57.707520493223505, nan]\n",
      "[72.5344554981984, 58.30752049322351, nan]\n",
      "[73.41680843937486, 58.8984295841326, nan]\n",
      "[74.2428953958966, 59.55060349717608, nan]\n",
      "[74.97973750115976, 60.31983426640684, nan]\n",
      "[75.61973750115976, 60.95619790277048, nan]\n",
      "[76.23084861227088, 61.73880659842265, nan]\n",
      "[77.02251527893755, 62.48880659842265, nan]\n",
      "[77.88918194560421, 63.29833040794646, nan]\n",
      "[78.56775337417564, 64.06023516985123, nan]\n",
      "[79.40108670750897, 64.83296244257849, nan]\n",
      "[80.24319197066686, 65.42387153348758, nan]\n",
      "[80.99319197066686, 66.16071363875075, nan]\n",
      "[81.87554491184332, 66.87499935303646, nan]\n",
      "[82.70163186836506, 67.44642792446503, nan]\n",
      "[83.40751422130623, 67.94642792446503, nan]\n",
      "[84.13828345207546, 68.66071363875074, nan]\n",
      "[84.83059114438315, 69.18245276918552, nan]\n",
      "[85.70559114438315, 69.86666329550131, nan]\n",
      "[86.39524631679694, 70.3428537716918, nan]\n",
      "[87.39524631679694, 70.9515494238657, nan]\n",
      "[88.22857965013027, 71.6357599501815, nan]\n",
      "[89.00635742790804, 72.0857599501815, nan]\n",
      "[89.82988683967275, 72.7328187737109, nan]\n",
      "[90.51738683967275, 73.2328187737109, nan]\n",
      "[91.33220165448756, 73.7328187737109, nan]\n",
      "[92.21681703910295, 74.19948544037757, nan]\n",
      "[92.93110275338866, 74.67567591656805, nan]\n",
      "[93.89264121492712, 75.20508768127394, nan]\n",
      "[94.83381768551536, 75.7765162527025, nan]\n",
      "[95.50048435218203, 76.25651625270251, nan]\n",
      "[96.31000816170584, 76.80651625270251, nan]\n",
      "[97.2047450038111, 77.54564668748512, nan]\n",
      "[97.91062735675227, 78.16103130286973, nan]\n",
      "[98.7439606900856, 78.68484082667925, nan]\n",
      "[99.42396069008561, 79.24484082667925, nan]\n",
      "[100.27011453623945, 79.84484082667925, nan]\n",
      "[101.07780684393175, 80.67817416001257, nan]\n",
      "[102.00637827250318, 81.44288004236552, nan]\n",
      "[102.80637827250318, 81.86393267394446, nan]\n",
      "[103.39461356662083, 82.47262832611837, nan]\n",
      "[104.1723913443986, 83.16012832611837, nan]\n",
      "[104.90572467773194, 83.8823505483406, nan]\n",
      "[105.40572467773194, 84.40235054834059, nan]\n",
      "[106.18350245550971, 84.95235054834059, nan]\n",
      "[106.94540721741447, 85.65235054834059, nan]\n",
      "[107.72801591306664, 86.10689600288605, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7444/229173756.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  per_class_accuracy = confusion.diagonal() / confusion.sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108.55410286958838, 86.67211339419039, nan]\n",
      "[109.26838858387408, 87.35632392050618, nan]\n",
      "[110.14838858387408, 87.93527128892724, nan]\n",
      "[110.91761935310485, 88.58233011245665, nan]\n",
      "[111.75095268643818, 89.12079165091818, nan]\n",
      "[112.61458905007454, 89.49579165091818, nan]\n",
      "[113.44792238340787, 90.1148392699658, nan]\n",
      "[114.24792238340787, 90.88756654269307, nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 35\u001b[0m training_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m     38\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    recall = []\n",
    "    precision = []\n",
    "\n",
    "    recall_val = []\n",
    "    precision_val = []\n",
    "\n",
    "    training_loss = []\n",
    "    start_time = time.time()\n",
    "    elapsed_time = 0\n",
    "    model.train() \n",
    "    total_per_class_accuracy = [0.0] * 4\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        inputs, labels = data\n",
    "        labels = torch.Tensor(labels)\n",
    "        \n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        per_class_accuracy = multiclass_accuracy_per_class(outputs, labels, 4)\n",
    "        total_per_class_accuracy = [acc + per_acc for acc, per_acc in zip(total_per_class_accuracy, per_class_accuracy)]\n",
    "        average_per_class_accuracy = [acc / len(trainloader) if not None else 0.0 for acc in total_per_class_accuracy]\n",
    "\n",
    "        print(total_per_class_accuracy)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        outputs = outputs.data.cpu().numpy().argmax(axis=1)\n",
    "        labels = labels.data.cpu().numpy().argmax(axis=1)\n",
    "\n",
    "        recall_per_class, precision_per_class = calculate_precision_recall_per_class(labels, outputs)\n",
    "        if (i + 1) % 1000 == 0 or i == len(trainloader) - 1:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            batches_done = i + 1\n",
    "            batches_total = len(trainloader)\n",
    "            batches_remaining = batches_total - batches_done\n",
    "            time_per_batch = elapsed_time / batches_done\n",
    "            estimated_time_remaining = time_per_batch * batches_remaining\n",
    "\n",
    "            # Convert times to minutes\n",
    "            elapsed_time_minutes = elapsed_time / 60\n",
    "            estimated_time_remaining_minutes = estimated_time_remaining / 60\n",
    "\n",
    "\n",
    "\n",
    "            # Print training progress and estimated time remaining on the same line\n",
    "            progress_message = f'Batch {i}/{len(trainloader)},Remaining: {estimated_time_remaining_minutes:.2f}min , loss {loss.item()}, class 1: {recall_per_class[0]}, class 2: {recall_per_class[1]}, class 3: {recall_per_class[2]}, class 4: {recall_per_class[3]}'\n",
    "            sys.stdout.write(\"\\r\" + progress_message)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "\n",
    "        recall.append(recall_per_class)\n",
    "        precision.append(precision_per_class)\n",
    "\n",
    "    average_per_class_accuracy = [acc / len(trainloader) for acc in total_per_class_accuracy]\n",
    "    for class_idx, acc in enumerate(average_per_class_accuracy):\n",
    "        print(f'Training Class {class_idx + 1} Accuracy: {acc * 100:.2f}%')\n",
    "            \n",
    " \n",
    "    model.eval()  \n",
    "    val_loss = []\n",
    "    total_per_class_accuracy = [0.0] * 4\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            labels = torch.Tensor(labels)\n",
    "            inputs = inputs.to('cuda:0')\n",
    "            labels = labels.to('cuda:0')\n",
    "\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            val_loss_crt = criterion(outputs, labels)\n",
    "\n",
    "            per_class_accuracy = multiclass_accuracy_per_class(outputs, labels, 4)\n",
    "            total_per_class_accuracy = [acc + per_acc for acc, per_acc in zip(total_per_class_accuracy, per_class_accuracy)]\n",
    "\n",
    "            val_loss.append(val_loss_crt.item())\n",
    "\n",
    "            outputs = outputs.data.cpu().numpy().argmax(axis=1)\n",
    "            labels = labels.data.cpu().numpy().argmax(axis=1)\n",
    "            \n",
    "            recall_per_class, precision_per_class = calculate_precision_recall_per_class(labels, outputs)\n",
    "            \n",
    "            recall_val.append(recall_per_class)\n",
    "            precision_val.append(precision_per_class)\n",
    "\n",
    "\n",
    "\n",
    "    recall = np.mean(np.array(recall), axis=0)\n",
    "    recall_val = np.mean(np.array(recall_val), axis=0)\n",
    "    \n",
    "    recalls.append(recall)\n",
    "    val_recalls.append(recall_val)\n",
    "    \n",
    "    losses.append(training_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Training loss: {np.mean(training_loss)} Validation Loss: {np.mean(val_loss)}')\n",
    "    print(f'Epoch {epoch + 1}, Training Class 1: {recall[0]}, Class 2: {recall[1]}, Class 3: {recall[2]}, Class 4: {recall[3]}')\n",
    "    print(f'Epoch {epoch + 1}, Validation Class 1: {recall_val[0]}, Class 2: {recall_val[1]}, Class 3: {recall_val[2]}, Class 4: {recall_val[3]}')\n",
    "    average_per_class_accuracy = [acc / len(testloader) for acc  in total_per_class_accuracy]\n",
    "\n",
    "    for class_idx, acc in enumerate(average_per_class_accuracy):\n",
    "        print(f'Validation Class {class_idx + 1} Accuracy: {acc * 100:.2f}%')\n",
    "        \n",
    "\n",
    "print('Finished Training')\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['loss'] = np.array(losses)\n",
    "df['val_loss'] = np.array(val_losses)\n",
    "df.to_csv('results_loss.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "df['recall'] = np.array(recalls)\n",
    "df['val_recall'] = np.array(val_recalls)\n",
    "\n",
    "df.to_csv('results.csv', index=False)\n",
    "\n",
    "torch.save(model.state_dict(),'model_vit1.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
