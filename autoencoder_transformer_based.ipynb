{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02458ea-ae80-48ed-b9f3-b2747232bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        path = []\n",
    "        classes = []\n",
    "        for image_class in os.listdir('cells_final'):\n",
    "            for img in os.listdir(f'cells_final/{image_class}'):\n",
    "                path.append(f'cells_final/{image_class}/{img}')\n",
    "                classes.append(image_class)\n",
    "\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['path'] = path\n",
    "        dataset_final['class'] = classes\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"path\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        #image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset['class'].loc[idx]\n",
    "\n",
    "        if target.strip() == 'normal':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target.strip() == 'inflammatory':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target.strip() == 'tumor':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target.strip() == 'other':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0082330-1335-4321-a3a9-fb6463c20617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels=3, patch_size=8, emb_size=256, img_size=32):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
    "        self.pos_embed = nn.Parameter(torch.randn((img_size // patch_size) ** 2 + 1, emb_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.proj(x)  # (B, emb_size, h, w)\n",
    "        x = rearrange(x, 'b e (h) (w) -> b (h w) e')\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embed\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, emb_size, depth, n_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.TransformerEncoderLayer(d_model=emb_size, nhead=n_heads, dim_feedforward=mlp_dim, dropout=dropout) for _ in range(depth)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, emb_size, depth, n_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.TransformerDecoderLayer(d_model=emb_size, nhead=n_heads, dim_feedforward=mlp_dim, dropout=dropout) for _ in range(depth)])\n",
    "        \n",
    "    def forward(self, tgt, memory):\n",
    "        for layer in self.layers:\n",
    "            tgt = layer(tgt, memory)\n",
    "        return tgt\n",
    "\n",
    "class VisionTransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=8, in_channels=3, emb_size=256, depth=10, n_heads=4, mlp_dim=1024, dropout=0.1):\n",
    "        super(VisionTransformerAutoencoder, self).__init__()\n",
    "        self.patch_embedding = PatchEmbedding(in_channels, patch_size, emb_size, img_size)\n",
    "        self.encoder = TransformerEncoder(emb_size, depth, n_heads, mlp_dim, dropout)\n",
    "        self.decoder = TransformerDecoder(emb_size, depth, n_heads, mlp_dim, dropout)\n",
    "        self.unpatchify = nn.ConvTranspose2d(emb_size, in_channels, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        patches = self.patch_embedding(x)\n",
    "        memory = self.encoder(patches) #this extract!\n",
    "\n",
    "        # Decoder\n",
    "        decoded_patches = self.decoder(patches, memory)\n",
    "        decoded_patches = decoded_patches[:, 1:, :]  \n",
    "        decoded_patches = rearrange(decoded_patches, 'b (h w) e -> b e h w', h=int(x.shape[-2] // self.patch_embedding.patch_size))\n",
    "\n",
    "        # Reconstruct image\n",
    "        reconstructed_img = self.unpatchify(decoded_patches)\n",
    "        return reconstructed_img\n",
    "\n",
    "# Example usage\n",
    "img_size = 32\n",
    "patch_size = 4\n",
    "in_channels = 3\n",
    "emb_size = 128\n",
    "depth = 5\n",
    "n_heads = 4\n",
    "mlp_dim = 128\n",
    "dropout = 0.0\n",
    "\n",
    "model = VisionTransformerAutoencoder(img_size, patch_size, in_channels, emb_size, depth, n_heads, mlp_dim, dropout)\n",
    "\n",
    "# Sample input\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "reconstructed_img = model(x)\n",
    "\n",
    "print(reconstructed_img.shape)  # Should output torch.Size([1, 3, 32, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e49822e-7d64-42a0-8568-19a61c89334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4f8bd1-7fa3-42e4-9ec9-635772b8bb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "Epoch 0 Average Loss: 0.6028989540665063\n",
      "Saved new best model with loss 0.6028989540665063\n",
      "Epoch 0 time: 1.60594351301667 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "Epoch 1 Average Loss: 0.5937266796335529\n",
      "Saved new best model with loss 0.5937266796335529\n",
      "Epoch 1 time: 1.6158317776333206 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "Epoch 2 Average Loss: 0.5931699441211058\n",
      "Saved new best model with loss 0.5931699441211058\n",
      "Epoch 2 time: 1.6028729696166617 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "Epoch 3 Average Loss: 0.5929557772556154\n",
      "Saved new best model with loss 0.5929557772556154\n",
      "Epoch 3 time: 1.5864048760500131 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "Epoch 4 Average Loss: 0.5929188313263871\n",
      "Saved new best model with loss 0.5929188313263871\n",
      "Epoch 4 time: 1.6152443586999956 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "Epoch 5 Average Loss: 0.5927559653721234\n",
      "Saved new best model with loss 0.5927559653721234\n",
      "Epoch 5 time: 1.6029080891666732 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "Epoch 6 Average Loss: 0.5926753246154722\n",
      "Saved new best model with loss 0.5926753246154722\n",
      "Epoch 6 time: 1.588629272399976 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "Epoch 7 Average Loss: 0.5926187786922203\n",
      "Saved new best model with loss 0.5926187786922203\n",
      "Epoch 7 time: 1.5745282263499878 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "Epoch 8 Average Loss: 0.5925569124150984\n",
      "Saved new best model with loss 0.5925569124150984\n",
      "Epoch 8 time: 1.5892869235166471 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "Epoch 9 Average Loss: 0.5925602092601285\n",
      "Epoch 9 time: 1.592310058983306 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "Epoch 10 Average Loss: 0.5925260111443674\n",
      "Saved new best model with loss 0.5925260111443674\n",
      "Epoch 10 time: 1.5855750208333423 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     35\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m     37\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/site-packages/torch/multiprocessing/reductions.py:495\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 495\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/multiprocessing/connection.py:502\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    500\u001b[0m     c \u001b[38;5;241m=\u001b[39m PipeClient(address)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mSocketClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(authkey, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthkey should be a byte string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cells/lib/python3.10/multiprocessing/connection.py:630\u001b[0m, in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m socket\u001b[38;5;241m.\u001b[39msocket( \u001b[38;5;28mgetattr\u001b[39m(socket, family) ) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[1;32m    629\u001b[0m     s\u001b[38;5;241m.\u001b[39msetblocking(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 630\u001b[0m     \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Connection(s\u001b[38;5;241m.\u001b[39mdetach())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Initialize WandB\n",
    "run_name = f'conv_autoencoder_training_{datetime.datetime.now()}'\n",
    "\n",
    "# Configuration\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "early_stop_patience = 15  # Number of epochs to wait for improvement\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "# DataLoader\n",
    "trainset = ImageDataset(data_path='train_data')\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Early Stopping\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    time_start = time.perf_counter()\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, _) in enumerate(trainloader):\n",
    "        inputs = inputs.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)  # Reconstruction loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(trainloader)\n",
    "    print(f'Epoch {epoch} Average Loss: {avg_loss}')\n",
    "    \n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), f'{run_path}.pth')\n",
    "        print(f'Saved new best model with loss {best_loss}')\n",
    "        patience_counter = 0  # Reset patience counter\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f'Early stopping at epoch {epoch} with best loss {best_loss}')\n",
    "        break\n",
    "    \n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'Epoch {epoch} time: {time_epoch/60} minutes')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'Loading model from {run_path}.pth')\n",
    "model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081ee83-45bc-4398-a7b1-0c444c5eba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{run_path}.pth'))\n",
    "features = []\n",
    "classes = []\n",
    "paths = []\n",
    "model.eval()\n",
    "trainset = ImageDataset(data_path='train_data')\n",
    "model = model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    for idx in range(0, len(trainset)-1):\n",
    "        img, cls = trainset[idx]\n",
    "        classes.append(cls.cpu().detach().numpy())\n",
    "        feature = model.encoder(img.to('cuda').reshape(1, 3, 32, 32))\n",
    "        features.append(feature.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f778a-45d3-48c4-b7a8-632ff41d527d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48727eb-595f-4ecd-a13a-4617322c68d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
